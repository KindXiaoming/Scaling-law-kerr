{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch: 0 | Loss: 0.4259971752205497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziming/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1639180852547/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Loss: 0.0010220951537800549\n",
      "Epoch: 200 | Loss: 0.000386381431285062\n",
      "Epoch: 300 | Loss: 0.00023559945611537054\n",
      "Epoch: 400 | Loss: 0.00017480753418804416\n",
      "Epoch: 500 | Loss: 0.00011149080926617789\n",
      "Epoch: 600 | Loss: 7.974568541872892e-05\n",
      "Epoch: 700 | Loss: 7.727414620086964e-05\n",
      "Epoch: 800 | Loss: 4.368148405515226e-05\n",
      "Epoch: 900 | Loss: 0.0009706463485943603\n",
      "Epoch: 1000 | Loss: 6.808741024383334e-05\n",
      "Epoch: 1100 | Loss: 1.9355143280954128e-05\n",
      "Epoch: 1200 | Loss: 2.009124764315332e-05\n",
      "Epoch: 1300 | Loss: 1.3622711271797847e-05\n",
      "Epoch: 1400 | Loss: 1.2209494131945523e-05\n",
      "Epoch: 1500 | Loss: 6.174126286794492e-05\n",
      "Epoch: 1600 | Loss: 8.706309322099841e-06\n",
      "Epoch: 1700 | Loss: 6.167571481685147e-05\n",
      "Epoch: 1800 | Loss: 1.1492488415443763e-05\n",
      "Epoch: 1900 | Loss: 5.185750414804818e-06\n",
      "Epoch: 2000 | Loss: 2.2512874759217465e-05\n",
      "Epoch: 2100 | Loss: 0.00013139354260093255\n",
      "Epoch: 2200 | Loss: 3.856046703693518e-06\n",
      "Epoch: 2300 | Loss: 0.00015176224129924857\n",
      "Epoch: 2400 | Loss: 4.509340360187743e-05\n",
      "Epoch: 2500 | Loss: 0.00015190884236274767\n",
      "Epoch: 2600 | Loss: 0.0005314765341864343\n",
      "Epoch: 2700 | Loss: 3.771269812872126e-06\n",
      "Epoch: 2800 | Loss: 1.6599602380865256e-05\n",
      "Epoch: 2900 | Loss: 2.0339718621258504e-05\n",
      "Epoch: 3000 | Loss: 3.5234362685801234e-06\n",
      "Epoch: 3100 | Loss: 3.049567051804735e-06\n",
      "Epoch: 3200 | Loss: 2.7215436684761965e-06\n",
      "Epoch: 3300 | Loss: 2.480009476297253e-06\n",
      "Epoch: 3400 | Loss: 2.299328335014512e-06\n",
      "Epoch: 3500 | Loss: 2.162620974203033e-06\n",
      "Epoch: 3600 | Loss: 2.058345043157617e-06\n",
      "Epoch: 3700 | Loss: 1.9783697153631526e-06\n",
      "Epoch: 3800 | Loss: 1.9168252245302935e-06\n",
      "Epoch: 3900 | Loss: 1.8693874577516992e-06\n",
      "Epoch: 4000 | Loss: 1.8328176461899746e-06\n",
      "Epoch: 4100 | Loss: 1.8046571718503953e-06\n",
      "Epoch: 4200 | Loss: 1.7830197307104613e-06\n",
      "Epoch: 4300 | Loss: 1.7664463352756038e-06\n",
      "Epoch: 4400 | Loss: 1.7554380402953986e-06\n",
      "Epoch: 4500 | Loss: 1.9703211089710385e-06\n",
      "Epoch: 4600 | Loss: 2.2455404178600827e-06\n",
      "Epoch: 4700 | Loss: 1.9249323818671047e-06\n",
      "Epoch: 4800 | Loss: 4.762389929797077e-05\n",
      "Epoch: 4900 | Loss: 1.8418772254621534e-06\n",
      "Epoch: 5000 | Loss: 1.7959005401464934e-06\n",
      "Epoch: 5100 | Loss: 8.18338349558437e-06\n",
      "Epoch: 5200 | Loss: 1.880505575596766e-06\n",
      "Epoch: 5300 | Loss: 5.1686091196081936e-05\n",
      "Epoch: 5400 | Loss: 1.8454370125598741e-06\n",
      "Epoch: 5500 | Loss: 6.684871715287223e-06\n",
      "Epoch: 5600 | Loss: 0.00035440324282977114\n",
      "Epoch: 5700 | Loss: 0.00017011982505354555\n",
      "Epoch: 5800 | Loss: 1.8579035848979048e-06\n",
      "Epoch: 5900 | Loss: 2.298609907859896e-06\n",
      "Epoch: 6000 | Loss: 1.976463419735188e-06\n",
      "Epoch: 6100 | Loss: 1.887442584809902e-06\n",
      "Epoch: 6200 | Loss: 1.8317947820193898e-06\n",
      "Epoch: 6300 | Loss: 1.7950034150738553e-06\n",
      "Epoch: 6400 | Loss: 1.770319378960947e-06\n",
      "Epoch: 6500 | Loss: 1.7536015836370543e-06\n",
      "Epoch: 6600 | Loss: 1.7422094524576043e-06\n",
      "Epoch: 6700 | Loss: 1.7344167997657838e-06\n",
      "Epoch: 6800 | Loss: 1.7290742915899217e-06\n",
      "Epoch: 6900 | Loss: 1.725406445173239e-06\n",
      "Epoch: 7000 | Loss: 1.7228851837682506e-06\n",
      "Epoch: 7100 | Loss: 1.7211487802406012e-06\n",
      "Epoch: 7200 | Loss: 1.7199486757236373e-06\n",
      "Epoch: 7300 | Loss: 1.7191139403274807e-06\n",
      "Epoch: 7400 | Loss: 1.7185271847143021e-06\n",
      "Epoch: 7500 | Loss: 1.720284156213413e-06\n",
      "Epoch: 7600 | Loss: 1.7515768594300758e-06\n",
      "Epoch: 7700 | Loss: 2.8404082681769904e-06\n",
      "Epoch: 7800 | Loss: 1.738968131666141e-06\n",
      "Epoch: 7900 | Loss: 1.8460746847710023e-06\n",
      "Epoch: 8000 | Loss: 1.72921806279534e-06\n",
      "Epoch: 8100 | Loss: 1.731885568450727e-06\n",
      "Epoch: 8200 | Loss: 2.012320700030781e-06\n",
      "Epoch: 8300 | Loss: 2.4760123595123267e-06\n",
      "Epoch: 8400 | Loss: 2.527876545147527e-06\n",
      "Epoch: 8500 | Loss: 1.7244871100715438e-06\n",
      "Epoch: 8600 | Loss: 2.129231788302607e-06\n",
      "Epoch: 8700 | Loss: 4.56352674061436e-06\n",
      "Epoch: 8800 | Loss: 3.285673700675547e-06\n",
      "Epoch: 8900 | Loss: 1.1383538215977793e-05\n",
      "Epoch: 9000 | Loss: 2.1025496974386148e-06\n",
      "Epoch: 9100 | Loss: 1.7325146716960454e-06\n",
      "Epoch: 9200 | Loss: 1.724247363205213e-06\n",
      "Epoch: 9300 | Loss: 1.7212681666934492e-06\n",
      "Epoch: 9400 | Loss: 1.7195042014896516e-06\n",
      "Epoch: 9500 | Loss: 1.7184499998090966e-06\n",
      "Epoch: 9600 | Loss: 1.7178119097053228e-06\n",
      "Epoch: 9700 | Loss: 1.7174180239632375e-06\n",
      "Epoch: 9800 | Loss: 1.7171673732676918e-06\n",
      "Epoch: 9900 | Loss: 1.717000732498575e-06\n",
      "Epoch: 10000 | Loss: 1.7168835766199582e-06\n",
      "Epoch: 10100 | Loss: 1.716795996444052e-06\n",
      "Epoch: 10200 | Loss: 1.7167266770075023e-06\n",
      "Epoch: 10300 | Loss: 1.7166692899516448e-06\n",
      "Epoch: 10400 | Loss: 1.7166203408454783e-06\n",
      "Epoch: 10500 | Loss: 1.7165779002593747e-06\n",
      "Epoch: 10600 | Loss: 1.763209154880399e-06\n",
      "Epoch: 10700 | Loss: 1.7177830958773416e-06\n",
      "Epoch: 10800 | Loss: 1.7254173801367899e-06\n",
      "Epoch: 10900 | Loss: 1.7171829308682286e-06\n",
      "Epoch: 11000 | Loss: 1.7167357362741944e-06\n",
      "Epoch: 11100 | Loss: 9.857370932458578e-06\n",
      "Epoch: 11200 | Loss: 1.7230284476294291e-06\n",
      "Epoch: 11300 | Loss: 1.7225178307657844e-06\n",
      "Epoch: 11400 | Loss: 2.731017576902827e-05\n",
      "Epoch: 11500 | Loss: 3.0808977437764713e-06\n",
      "Epoch: 11600 | Loss: 1.718450337511894e-06\n",
      "Epoch: 11700 | Loss: 1.784237672248965e-06\n",
      "Epoch: 11800 | Loss: 1.8577634086366203e-06\n",
      "Epoch: 11900 | Loss: 2.5798631486220866e-06\n",
      "Epoch: 12000 | Loss: 1.717554535692542e-06\n",
      "Epoch: 12100 | Loss: 1.7169769775907098e-06\n",
      "Epoch: 12200 | Loss: 1.7166932728448262e-06\n",
      "Epoch: 12300 | Loss: 1.7165489935965392e-06\n",
      "Epoch: 12400 | Loss: 1.7164736952115342e-06\n",
      "Epoch: 12500 | Loss: 1.7164326925978354e-06\n",
      "Epoch: 12600 | Loss: 1.7164087652203397e-06\n",
      "Epoch: 12700 | Loss: 1.7163934198903101e-06\n",
      "Epoch: 12800 | Loss: 1.7163825336628222e-06\n",
      "Epoch: 12900 | Loss: 1.7163741397706307e-06\n",
      "Epoch: 13000 | Loss: 1.7163673069688413e-06\n",
      "Epoch: 13100 | Loss: 1.716361584278932e-06\n",
      "Epoch: 13200 | Loss: 1.7163567350042174e-06\n",
      "Epoch: 13300 | Loss: 1.716352614702102e-06\n",
      "Epoch: 13400 | Loss: 1.7163491180566272e-06\n",
      "Epoch: 13500 | Loss: 1.8912664467704815e-06\n",
      "Epoch: 13600 | Loss: 1.716510633714988e-06\n",
      "Epoch: 13700 | Loss: 2.91533051762866e-06\n",
      "Epoch: 13800 | Loss: 1.7165615169975297e-06\n",
      "Epoch: 13900 | Loss: 1.7163816953931935e-06\n",
      "Epoch: 14000 | Loss: 1.7254972936460795e-06\n",
      "Epoch: 14100 | Loss: 1.7163513989945409e-06\n",
      "Epoch: 14200 | Loss: 1.7325856170323983e-06\n",
      "Epoch: 14300 | Loss: 1.7197503409702954e-06\n",
      "Epoch: 14400 | Loss: 1.7178429912901705e-06\n",
      "Epoch: 14500 | Loss: 1.8466789117447754e-06\n",
      "Epoch: 14600 | Loss: 1.7168841684031947e-06\n",
      "Epoch: 14700 | Loss: 2.251964357615882e-06\n",
      "Epoch: 14800 | Loss: 1.7390357954180012e-06\n",
      "Epoch: 14900 | Loss: 1.8273453162779637e-06\n",
      "time=182.5131480693817\n",
      "error=1.796935547795217e-06\n",
      "best loss=1.7163478296231775e-06\n",
      "best epoch=13443\n",
      "8\n",
      "Epoch: 0 | Loss: 0.01566976617537237\n",
      "Epoch: 100 | Loss: 3.755396011278203e-05\n",
      "Epoch: 200 | Loss: 1.3399634937088092e-05\n",
      "Epoch: 300 | Loss: 5.462523082484305e-06\n",
      "Epoch: 400 | Loss: 9.339150762643264e-05\n",
      "Epoch: 500 | Loss: 9.041069098894082e-06\n",
      "Epoch: 600 | Loss: 0.0002525029638820908\n",
      "Epoch: 700 | Loss: 0.00030405241095852044\n",
      "Epoch: 800 | Loss: 0.00019814627854588702\n",
      "Epoch: 900 | Loss: 1.5720878949677993e-05\n",
      "Epoch: 1000 | Loss: 1.1758740318834896e-05\n",
      "Epoch: 1100 | Loss: 2.843965188326078e-05\n",
      "Epoch: 1200 | Loss: 2.5895814562722248e-05\n",
      "Epoch: 1300 | Loss: 5.0184923324021386e-05\n",
      "Epoch: 1400 | Loss: 4.9234212439181694e-05\n",
      "Epoch: 1500 | Loss: 0.00011931218245598939\n",
      "Epoch: 1600 | Loss: 0.0003371294828569851\n",
      "Epoch: 1700 | Loss: 0.0003090405122916557\n",
      "Epoch: 1800 | Loss: 0.0028812781803500185\n",
      "Epoch: 1900 | Loss: 0.0003103358614096201\n",
      "Epoch: 2000 | Loss: 5.939745671017572e-05\n",
      "Epoch: 2100 | Loss: 0.00028118431728781914\n",
      "Epoch: 2200 | Loss: 0.0009091170562385952\n",
      "Epoch: 2300 | Loss: 0.000213865582144969\n",
      "Epoch: 2400 | Loss: 0.0007618803584617734\n",
      "Epoch: 2500 | Loss: 0.00024426397394756847\n",
      "Epoch: 2600 | Loss: 0.0001911848900729743\n",
      "Epoch: 2700 | Loss: 0.00023410369475204207\n",
      "Epoch: 2800 | Loss: 2.0584600394868233e-05\n",
      "Epoch: 2900 | Loss: 0.0009123170467859369\n",
      "Epoch: 3000 | Loss: 1.4277896523550282e-05\n",
      "Epoch: 3100 | Loss: 1.5262262789575027e-06\n",
      "Epoch: 3200 | Loss: 1.0196106208642713e-06\n",
      "Epoch: 3300 | Loss: 8.911886883301927e-07\n",
      "Epoch: 3400 | Loss: 8.452585013856808e-07\n",
      "Epoch: 3500 | Loss: 8.254868823501303e-07\n",
      "Epoch: 3600 | Loss: 8.15881746029464e-07\n",
      "Epoch: 3700 | Loss: 8.108176211968264e-07\n",
      "Epoch: 3800 | Loss: 8.079880396033325e-07\n",
      "Epoch: 3900 | Loss: 8.063331411947902e-07\n",
      "Epoch: 4000 | Loss: 8.05323870462935e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4100 | Loss: 8.046805051863278e-07\n",
      "Epoch: 4200 | Loss: 8.04249410179957e-07\n",
      "Epoch: 4300 | Loss: 8.03944179846939e-07\n",
      "Epoch: 4400 | Loss: 5.431925033881382e-06\n",
      "Epoch: 4500 | Loss: 2.2719580880842193e-05\n",
      "Epoch: 4600 | Loss: 4.328709105999184e-06\n",
      "Epoch: 4700 | Loss: 1.2327162753986988e-05\n",
      "Epoch: 4800 | Loss: 1.384682705861715e-05\n",
      "Epoch: 4900 | Loss: 1.0982632940010405e-05\n",
      "Epoch: 5000 | Loss: 1.7997373016639875e-05\n",
      "Epoch: 5100 | Loss: 5.8703505528442156e-05\n",
      "Epoch: 5200 | Loss: 1.0364242126549045e-05\n",
      "Epoch: 5300 | Loss: 3.838377778266144e-05\n",
      "Epoch: 5400 | Loss: 4.9050604269179134e-05\n",
      "Epoch: 5500 | Loss: 9.994343585778141e-05\n",
      "Epoch: 5600 | Loss: 0.00021070264648128577\n",
      "Epoch: 5700 | Loss: 3.2593641303844333e-06\n",
      "Epoch: 5800 | Loss: 2.1094044874405087e-05\n",
      "Epoch: 5900 | Loss: 6.978078530841336e-05\n",
      "Epoch: 6000 | Loss: 1.5894454951928005e-06\n",
      "Epoch: 6100 | Loss: 9.070898884011143e-07\n",
      "Epoch: 6200 | Loss: 8.466884870910911e-07\n",
      "Epoch: 6300 | Loss: 8.23929957452714e-07\n",
      "Epoch: 6400 | Loss: 8.140364841809415e-07\n",
      "Epoch: 6500 | Loss: 8.092790569073247e-07\n",
      "Epoch: 6600 | Loss: 8.068143363209278e-07\n",
      "Epoch: 6700 | Loss: 8.054613609466436e-07\n",
      "Epoch: 6800 | Loss: 8.046796637001173e-07\n",
      "Epoch: 6900 | Loss: 8.042030617607375e-07\n",
      "Epoch: 7000 | Loss: 8.038937171641318e-07\n",
      "Epoch: 7100 | Loss: 8.036780771615627e-07\n",
      "Epoch: 7200 | Loss: 8.035163204374088e-07\n",
      "Epoch: 7300 | Loss: 8.03386815296316e-07\n",
      "Epoch: 7400 | Loss: 8.032778535079462e-07\n",
      "Epoch: 7500 | Loss: 3.608865234889085e-06\n",
      "Epoch: 7600 | Loss: 8.83995518046947e-07\n",
      "Epoch: 7700 | Loss: 2.4700255931677033e-06\n",
      "Epoch: 7800 | Loss: 1.1284640686177095e-06\n",
      "Epoch: 7900 | Loss: 3.4153826498079568e-06\n",
      "Epoch: 8000 | Loss: 9.4627922482669e-06\n",
      "Epoch: 8100 | Loss: 6.68737503928407e-05\n",
      "Epoch: 8200 | Loss: 4.702930825667319e-06\n",
      "Epoch: 8300 | Loss: 1.9439485648034985e-06\n",
      "Epoch: 8400 | Loss: 3.2860303465414795e-06\n",
      "Epoch: 8500 | Loss: 1.3009131177194297e-06\n",
      "Epoch: 8600 | Loss: 2.6279842534352212e-06\n",
      "Epoch: 8700 | Loss: 3.4953464134643095e-05\n",
      "Epoch: 8800 | Loss: 0.0001412031149588733\n",
      "Epoch: 8900 | Loss: 1.1727924872012821e-06\n",
      "Epoch: 9000 | Loss: 1.0450580775394978e-06\n",
      "Epoch: 9100 | Loss: 8.348511641658569e-07\n",
      "Epoch: 9200 | Loss: 8.19080168175685e-07\n",
      "Epoch: 9300 | Loss: 8.116372120157369e-07\n",
      "Epoch: 9400 | Loss: 8.078071092371633e-07\n",
      "Epoch: 9500 | Loss: 8.057271250220427e-07\n",
      "Epoch: 9600 | Loss: 8.045551247417113e-07\n",
      "Epoch: 9700 | Loss: 8.03877133162495e-07\n",
      "Epoch: 9800 | Loss: 8.034764174213981e-07\n",
      "Epoch: 9900 | Loss: 8.032342839900281e-07\n",
      "Epoch: 10000 | Loss: 8.030837797750772e-07\n",
      "Epoch: 10100 | Loss: 8.029864842090994e-07\n",
      "Epoch: 10200 | Loss: 8.029201807058973e-07\n",
      "Epoch: 10300 | Loss: 8.028720155589782e-07\n",
      "Epoch: 10400 | Loss: 8.028345860530542e-07\n",
      "Epoch: 10500 | Loss: 4.360602293775243e-06\n",
      "Epoch: 10600 | Loss: 1.7730774662014992e-06\n",
      "Epoch: 10700 | Loss: 1.0770980138919656e-06\n",
      "Epoch: 10800 | Loss: 8.059937083169736e-07\n",
      "Epoch: 10900 | Loss: 1.933375940393463e-06\n",
      "Epoch: 11000 | Loss: 8.371475630212657e-07\n",
      "Epoch: 11100 | Loss: 2.8568395444247533e-05\n",
      "Epoch: 11200 | Loss: 2.9317840805777034e-05\n",
      "Epoch: 11300 | Loss: 8.64118503105539e-07\n",
      "Epoch: 11400 | Loss: 1.1112017956178494e-06\n",
      "Epoch: 11500 | Loss: 3.4521305145190634e-06\n",
      "Epoch: 11600 | Loss: 9.275440419339171e-07\n",
      "Epoch: 11700 | Loss: 9.132480098978913e-07\n",
      "Epoch: 11800 | Loss: 1.0109511450369542e-06\n",
      "Epoch: 11900 | Loss: 8.445186253688297e-07\n",
      "Epoch: 12000 | Loss: 8.328364077062e-07\n",
      "Epoch: 12100 | Loss: 8.070019190006193e-07\n",
      "Epoch: 12200 | Loss: 8.052462322825165e-07\n",
      "Epoch: 12300 | Loss: 8.042760169597877e-07\n",
      "Epoch: 12400 | Loss: 8.036772093635201e-07\n",
      "Epoch: 12500 | Loss: 8.033021085272144e-07\n",
      "Epoch: 12600 | Loss: 8.03065098210115e-07\n",
      "Epoch: 12700 | Loss: 8.029143291178112e-07\n",
      "Epoch: 12800 | Loss: 8.028175764966234e-07\n",
      "Epoch: 12900 | Loss: 8.02754566289592e-07\n",
      "Epoch: 13000 | Loss: 8.027125088546044e-07\n",
      "Epoch: 13100 | Loss: 8.026833663248697e-07\n",
      "Epoch: 13200 | Loss: 8.026621286697968e-07\n",
      "Epoch: 13300 | Loss: 8.026457088219641e-07\n",
      "Epoch: 13400 | Loss: 8.026322308921467e-07\n",
      "Epoch: 13500 | Loss: 5.395684149601624e-05\n",
      "Epoch: 13600 | Loss: 8.038063666034469e-07\n",
      "Epoch: 13700 | Loss: 2.1951804848327644e-06\n",
      "Epoch: 13800 | Loss: 3.417460607349279e-06\n",
      "Epoch: 13900 | Loss: 8.623820788810169e-07\n",
      "Epoch: 14000 | Loss: 1.6764792032179551e-06\n",
      "Epoch: 14100 | Loss: 8.650181276644054e-07\n",
      "Epoch: 14200 | Loss: 8.244825891043932e-07\n",
      "Epoch: 14300 | Loss: 3.7086731258065367e-06\n",
      "Epoch: 14400 | Loss: 8.139876553630004e-07\n",
      "Epoch: 14500 | Loss: 1.0115597033410422e-06\n",
      "Epoch: 14600 | Loss: 1.0575404610028168e-06\n",
      "Epoch: 14700 | Loss: 4.885671623687691e-06\n",
      "Epoch: 14800 | Loss: 3.4835112157316953e-06\n",
      "Epoch: 14900 | Loss: 2.010060921096143e-06\n",
      "time=186.20521903038025\n",
      "error=1.8817606582887685e-06\n",
      "best loss=8.026251293436296e-07\n",
      "best epoch=13461\n",
      "12\n",
      "Epoch: 0 | Loss: 0.0006019868390386592\n",
      "Epoch: 100 | Loss: 0.00020809884482231924\n",
      "Epoch: 200 | Loss: 2.9610733404214817e-05\n",
      "Epoch: 300 | Loss: 1.4554812074888063e-05\n",
      "Epoch: 400 | Loss: 9.351587583768314e-06\n",
      "Epoch: 500 | Loss: 0.00015153638206386958\n",
      "Epoch: 600 | Loss: 0.0004480082428671637\n",
      "Epoch: 700 | Loss: 0.0001221429037254755\n",
      "Epoch: 800 | Loss: 4.4700884216135216e-05\n",
      "Epoch: 900 | Loss: 7.239317552407727e-05\n",
      "Epoch: 1000 | Loss: 0.0020358108345967974\n",
      "Epoch: 1100 | Loss: 0.00021108861548665205\n",
      "Epoch: 1200 | Loss: 0.00014121497491773405\n",
      "Epoch: 1300 | Loss: 0.001032771781113977\n",
      "Epoch: 1400 | Loss: 0.00010102372305993019\n",
      "Epoch: 1500 | Loss: 0.0005475345566252589\n",
      "Epoch: 1600 | Loss: 0.001093813438449516\n",
      "Epoch: 1700 | Loss: 0.0006815129976028035\n",
      "Epoch: 1800 | Loss: 0.00039026380136841744\n",
      "Epoch: 1900 | Loss: 0.0017853964195062716\n",
      "Epoch: 2000 | Loss: 0.001547627497353914\n",
      "Epoch: 2100 | Loss: 0.0013683955692006052\n",
      "Epoch: 2200 | Loss: 7.74647659358784e-05\n",
      "Epoch: 2300 | Loss: 0.00036565918269294254\n",
      "Epoch: 2400 | Loss: 0.0002331425659906473\n",
      "Epoch: 2500 | Loss: 0.0010286351469310324\n",
      "Epoch: 2600 | Loss: 0.00012709817509705482\n",
      "Epoch: 2700 | Loss: 0.0010636844117840596\n",
      "Epoch: 2800 | Loss: 0.0014915400394352471\n",
      "Epoch: 2900 | Loss: 0.0011419245346912677\n",
      "Epoch: 3000 | Loss: 2.3136301090932626e-05\n",
      "Epoch: 3100 | Loss: 1.1383168415902712e-06\n",
      "Epoch: 3200 | Loss: 4.6684256175843355e-07\n",
      "Epoch: 3300 | Loss: 3.1442468460080405e-07\n",
      "Epoch: 3400 | Loss: 2.614506542456175e-07\n",
      "Epoch: 3500 | Loss: 2.3862571707142175e-07\n",
      "Epoch: 3600 | Loss: 2.2733667055729833e-07\n",
      "Epoch: 3700 | Loss: 2.211698910963519e-07\n",
      "Epoch: 3800 | Loss: 2.175343417672421e-07\n",
      "Epoch: 3900 | Loss: 2.1525945185420806e-07\n",
      "Epoch: 4000 | Loss: 2.1376878967295342e-07\n",
      "Epoch: 4100 | Loss: 2.127572624623464e-07\n",
      "Epoch: 4200 | Loss: 2.1205281672714194e-07\n",
      "Epoch: 4300 | Loss: 0.0004773799010702169\n",
      "Epoch: 4400 | Loss: 0.00011999293685923177\n",
      "Epoch: 4500 | Loss: 0.0009287540798504148\n",
      "Epoch: 4600 | Loss: 0.0002210588879437542\n",
      "Epoch: 4700 | Loss: 3.0070269415861008e-05\n",
      "Epoch: 4800 | Loss: 0.0003316319859160932\n",
      "Epoch: 4900 | Loss: 1.0299791060611489e-05\n",
      "Epoch: 5000 | Loss: 5.7580936955185436e-05\n",
      "Epoch: 5100 | Loss: 0.00012731438749653183\n",
      "Epoch: 5200 | Loss: 0.00034384190959153464\n",
      "Epoch: 5300 | Loss: 4.8817200055935295e-05\n",
      "Epoch: 5400 | Loss: 0.00014138723157040123\n",
      "Epoch: 5500 | Loss: 0.0001470163142778414\n",
      "Epoch: 5600 | Loss: 0.0008163035049178251\n",
      "Epoch: 5700 | Loss: 0.00014026437078729924\n",
      "Epoch: 5800 | Loss: 3.869235387006367e-05\n",
      "Epoch: 5900 | Loss: 0.00035244902657054515\n",
      "Epoch: 6000 | Loss: 3.1682822478677034e-06\n",
      "Epoch: 6100 | Loss: 5.830779404973767e-07\n",
      "Epoch: 6200 | Loss: 3.35909792347084e-07\n",
      "Epoch: 6300 | Loss: 2.6477652046284056e-07\n",
      "Epoch: 6400 | Loss: 2.3741010215466685e-07\n",
      "Epoch: 6500 | Loss: 2.251178941024598e-07\n",
      "Epoch: 6600 | Loss: 2.190021205161521e-07\n",
      "Epoch: 6700 | Loss: 2.157158776664935e-07\n",
      "Epoch: 6800 | Loss: 2.138347255605744e-07\n",
      "Epoch: 6900 | Loss: 2.1269781298945772e-07\n",
      "Epoch: 7000 | Loss: 2.119777820865321e-07\n",
      "Epoch: 7100 | Loss: 2.1150335393315896e-07\n",
      "Epoch: 7200 | Loss: 2.1118034454666018e-07\n",
      "Epoch: 7300 | Loss: 2.1095445834315056e-07\n",
      "Epoch: 7400 | Loss: 0.0002855083675418679\n",
      "Epoch: 7500 | Loss: 0.0001312467579227674\n",
      "Epoch: 7600 | Loss: 7.750876284757747e-05\n",
      "Epoch: 7700 | Loss: 0.00017037442833563708\n",
      "Epoch: 7800 | Loss: 2.941095754304831e-05\n",
      "Epoch: 7900 | Loss: 8.213317470136004e-05\n",
      "Epoch: 8000 | Loss: 5.80178220380054e-06\n",
      "Epoch: 8100 | Loss: 1.8877291648608708e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8200 | Loss: 9.629970496468567e-05\n",
      "Epoch: 8300 | Loss: 1.8454868980013448e-05\n",
      "Epoch: 8400 | Loss: 2.8862089737142287e-05\n",
      "Epoch: 8500 | Loss: 1.0970979602392632e-05\n",
      "Epoch: 8600 | Loss: 1.3135649321638516e-05\n",
      "Epoch: 8700 | Loss: 6.923559882707518e-05\n",
      "Epoch: 8800 | Loss: 8.823923598557221e-05\n",
      "Epoch: 8900 | Loss: 1.4992721697341946e-05\n",
      "Epoch: 9000 | Loss: 5.192376495151139e-07\n",
      "Epoch: 9100 | Loss: 2.8589069155289397e-07\n",
      "Epoch: 9200 | Loss: 2.501228791226428e-07\n",
      "Epoch: 9300 | Loss: 2.3327492373857177e-07\n",
      "Epoch: 9400 | Loss: 2.243075291684559e-07\n",
      "Epoch: 9500 | Loss: 2.192021465647161e-07\n",
      "Epoch: 9600 | Loss: 2.1614483840545996e-07\n",
      "Epoch: 9700 | Loss: 2.1423821696593872e-07\n",
      "Epoch: 9800 | Loss: 2.1300830305162008e-07\n",
      "Epoch: 9900 | Loss: 2.121919261465349e-07\n",
      "Epoch: 10000 | Loss: 2.1163688166828636e-07\n",
      "Epoch: 10100 | Loss: 2.1125196360273683e-07\n",
      "Epoch: 10200 | Loss: 2.10980721404477e-07\n",
      "Epoch: 10300 | Loss: 2.1078714744589474e-07\n",
      "Epoch: 10400 | Loss: 2.1064762488268923e-07\n",
      "Epoch: 10500 | Loss: 2.1425683221030887e-06\n",
      "Epoch: 10600 | Loss: 1.774462697107567e-06\n",
      "Epoch: 10700 | Loss: 4.320715205481874e-06\n",
      "Epoch: 10800 | Loss: 2.2194971384379246e-06\n",
      "Epoch: 10900 | Loss: 5.3918227111935494e-05\n",
      "Epoch: 11000 | Loss: 4.164443123562576e-06\n",
      "Epoch: 11100 | Loss: 6.982238936374294e-06\n",
      "Epoch: 11200 | Loss: 4.312454211592421e-06\n",
      "Epoch: 11300 | Loss: 2.550340482196306e-05\n",
      "Epoch: 11400 | Loss: 1.888301344013317e-06\n",
      "Epoch: 11500 | Loss: 1.2140200119939699e-06\n",
      "Epoch: 11600 | Loss: 4.918810553124552e-05\n",
      "Epoch: 11700 | Loss: 1.586695688802607e-06\n",
      "Epoch: 11800 | Loss: 5.797716288121466e-06\n",
      "Epoch: 11900 | Loss: 3.30573267635588e-05\n",
      "Epoch: 12000 | Loss: 2.4767174808071407e-07\n",
      "Epoch: 12100 | Loss: 2.2720100700541907e-07\n",
      "Epoch: 12200 | Loss: 2.2176986051033838e-07\n",
      "Epoch: 12300 | Loss: 2.182684710482712e-07\n",
      "Epoch: 12400 | Loss: 2.159346590478048e-07\n",
      "Epoch: 12500 | Loss: 2.1433943212824225e-07\n",
      "Epoch: 12600 | Loss: 2.1322592146829835e-07\n",
      "Epoch: 12700 | Loss: 2.1243480562456722e-07\n",
      "Epoch: 12800 | Loss: 2.1186439206536986e-07\n",
      "Epoch: 12900 | Loss: 2.1144812947804419e-07\n",
      "Epoch: 13000 | Loss: 2.1114145772173244e-07\n",
      "Epoch: 13100 | Loss: 2.1091389597501975e-07\n",
      "Epoch: 13200 | Loss: 2.107441722746185e-07\n",
      "Epoch: 13300 | Loss: 2.1061716538132936e-07\n",
      "Epoch: 13400 | Loss: 2.1052194846536692e-07\n",
      "Epoch: 13500 | Loss: 1.480282891483097e-05\n",
      "Epoch: 13600 | Loss: 2.1684861563843683e-07\n",
      "Epoch: 13700 | Loss: 1.3447064599611039e-05\n",
      "Epoch: 13800 | Loss: 1.1487558431750291e-05\n",
      "Epoch: 13900 | Loss: 5.836671591597599e-07\n",
      "Epoch: 14000 | Loss: 3.837941857833437e-06\n",
      "Epoch: 14100 | Loss: 1.340004707055069e-06\n",
      "Epoch: 14200 | Loss: 6.457748291193309e-06\n",
      "Epoch: 14300 | Loss: 3.2873595633266765e-06\n",
      "Epoch: 14400 | Loss: 2.022938791497438e-06\n",
      "Epoch: 14500 | Loss: 1.6012301644927182e-06\n",
      "Epoch: 14600 | Loss: 4.29795499259401e-06\n",
      "Epoch: 14700 | Loss: 1.0827052354149963e-05\n",
      "Epoch: 14800 | Loss: 1.1870008479624388e-05\n",
      "Epoch: 14900 | Loss: 5.794383704456979e-06\n",
      "time=190.51891803741455\n",
      "error=8.503982662777095e-07\n",
      "best loss=2.104944182695862e-07\n",
      "best epoch=13437\n",
      "16\n",
      "Epoch: 0 | Loss: 3.262754527502579e-05\n",
      "Epoch: 100 | Loss: 0.00038550322132565576\n",
      "Epoch: 200 | Loss: 9.339008715931988e-05\n",
      "Epoch: 300 | Loss: 0.00018172242454467802\n",
      "Epoch: 400 | Loss: 8.447242502952351e-05\n",
      "Epoch: 500 | Loss: 0.00020637951089913845\n",
      "Epoch: 600 | Loss: 0.0005184352036999505\n",
      "Epoch: 700 | Loss: 0.0003242230931278831\n",
      "Epoch: 800 | Loss: 0.0011312315211184916\n",
      "Epoch: 900 | Loss: 0.0007880049550101855\n",
      "Epoch: 1000 | Loss: 0.0006395834271676492\n",
      "Epoch: 1100 | Loss: 0.0010287939891956322\n",
      "Epoch: 1200 | Loss: 0.0007979128224844683\n",
      "Epoch: 1300 | Loss: 0.0018251653348457459\n",
      "Epoch: 1400 | Loss: 0.0004887561940502591\n",
      "Epoch: 1500 | Loss: 0.0012734153860034306\n",
      "Epoch: 1600 | Loss: 0.0014195320608299494\n",
      "Epoch: 1700 | Loss: 0.0009750583465153941\n",
      "Epoch: 1800 | Loss: 0.0014825154444259479\n",
      "Epoch: 1900 | Loss: 0.0006477962163068873\n",
      "Epoch: 2000 | Loss: 0.002037106641627059\n",
      "Epoch: 2100 | Loss: 0.00034991615433191663\n",
      "Epoch: 2200 | Loss: 0.004779479955363018\n",
      "Epoch: 2300 | Loss: 0.003365906245201338\n",
      "Epoch: 2400 | Loss: 0.0032022103421473014\n",
      "Epoch: 2500 | Loss: 0.005790864051934526\n",
      "Epoch: 2600 | Loss: 0.002297468729491749\n",
      "Epoch: 2700 | Loss: 0.000224238084009002\n",
      "Epoch: 2800 | Loss: 0.0032567223115639006\n",
      "Epoch: 2900 | Loss: 0.003898930310033035\n",
      "Epoch: 3000 | Loss: 4.855273841825633e-05\n",
      "Epoch: 3100 | Loss: 2.9217588788609347e-06\n",
      "Epoch: 3200 | Loss: 1.175660934421384e-06\n",
      "Epoch: 3300 | Loss: 6.372974729129114e-07\n",
      "Epoch: 3400 | Loss: 4.0606632363863286e-07\n",
      "Epoch: 3500 | Loss: 2.8758918210475007e-07\n",
      "Epoch: 3600 | Loss: 2.1976499282205872e-07\n",
      "Epoch: 3700 | Loss: 1.778450440379151e-07\n",
      "Epoch: 3800 | Loss: 1.5043219720428212e-07\n",
      "Epoch: 3900 | Loss: 1.3171356071516556e-07\n",
      "Epoch: 4000 | Loss: 1.1848796578970623e-07\n",
      "Epoch: 4100 | Loss: 1.0888300667879527e-07\n",
      "Epoch: 4200 | Loss: 1.0174868301224447e-07\n",
      "Epoch: 4300 | Loss: 0.0005142985870767062\n",
      "Epoch: 4400 | Loss: 6.637327070138916e-05\n",
      "Epoch: 4500 | Loss: 0.00037143488207502963\n",
      "Epoch: 4600 | Loss: 0.000848682470558424\n",
      "Epoch: 4700 | Loss: 0.0010892477582249843\n",
      "Epoch: 4800 | Loss: 0.0004577549419356444\n",
      "Epoch: 4900 | Loss: 5.799320761616887e-05\n",
      "Epoch: 5000 | Loss: 0.0005869362293253143\n",
      "Epoch: 5100 | Loss: 7.491909468089575e-05\n",
      "Epoch: 5200 | Loss: 0.00044841414877923465\n",
      "Epoch: 5300 | Loss: 0.0007729849202033427\n",
      "Epoch: 5400 | Loss: 0.0001235787251639215\n",
      "Epoch: 5500 | Loss: 0.0003546658830148908\n",
      "Epoch: 5600 | Loss: 0.0003696932203951331\n",
      "Epoch: 5700 | Loss: 0.00021587148703784204\n",
      "Epoch: 5800 | Loss: 0.000434121339615986\n",
      "Epoch: 5900 | Loss: 5.681260907645698e-05\n",
      "Epoch: 6000 | Loss: 4.214416962232547e-06\n",
      "Epoch: 6100 | Loss: 6.669957795276024e-07\n",
      "Epoch: 6200 | Loss: 3.1317255989180405e-07\n",
      "Epoch: 6300 | Loss: 1.973961168470547e-07\n",
      "Epoch: 6400 | Loss: 1.4607666790126148e-07\n",
      "Epoch: 6500 | Loss: 1.1969324602703896e-07\n",
      "Epoch: 6600 | Loss: 1.0474069294147463e-07\n",
      "Epoch: 6700 | Loss: 9.565375326335454e-08\n",
      "Epoch: 6800 | Loss: 8.983093145095789e-08\n",
      "Epoch: 6900 | Loss: 8.593960356688404e-08\n",
      "Epoch: 7000 | Loss: 8.324798749072193e-08\n",
      "Epoch: 7100 | Loss: 8.133171132402858e-08\n",
      "Epoch: 7200 | Loss: 7.993359973302002e-08\n",
      "Epoch: 7300 | Loss: 7.889200141129712e-08\n",
      "Epoch: 7400 | Loss: 1.1411827757523344e-05\n",
      "Epoch: 7500 | Loss: 0.0001303131127168471\n",
      "Epoch: 7600 | Loss: 0.0001754151437302522\n",
      "Epoch: 7700 | Loss: 4.51881372732955e-06\n",
      "Epoch: 7800 | Loss: 1.3324172667379388e-06\n",
      "Epoch: 7900 | Loss: 3.0063607648634947e-06\n",
      "Epoch: 8000 | Loss: 6.789603017112364e-05\n",
      "Epoch: 8100 | Loss: 0.00010291839314635025\n",
      "Epoch: 8200 | Loss: 0.0001520100367095926\n",
      "Epoch: 8300 | Loss: 2.7259545283387756e-05\n",
      "Epoch: 8400 | Loss: 1.3140734670276613e-05\n",
      "Epoch: 8500 | Loss: 1.4707253437756343e-05\n",
      "Epoch: 8600 | Loss: 7.710382977479246e-06\n",
      "Epoch: 8700 | Loss: 1.5580812782102662e-05\n",
      "Epoch: 8800 | Loss: 3.5970006684866964e-05\n",
      "Epoch: 8900 | Loss: 0.00044384974455904177\n",
      "Epoch: 9000 | Loss: 6.109961291155819e-07\n",
      "Epoch: 9100 | Loss: 2.0868987250134563e-07\n",
      "Epoch: 9200 | Loss: 1.4136511104135427e-07\n",
      "Epoch: 9300 | Loss: 1.127278164035034e-07\n",
      "Epoch: 9400 | Loss: 9.812946905903494e-08\n",
      "Epoch: 9500 | Loss: 8.99355219912806e-08\n",
      "Epoch: 9600 | Loss: 8.502850620907214e-08\n",
      "Epoch: 9700 | Loss: 8.194799801521378e-08\n",
      "Epoch: 9800 | Loss: 7.994227010981704e-08\n",
      "Epoch: 9900 | Loss: 7.859695947319036e-08\n",
      "Epoch: 10000 | Loss: 7.767154068938377e-08\n",
      "Epoch: 10100 | Loss: 7.702067846161097e-08\n",
      "Epoch: 10200 | Loss: 7.655370840194187e-08\n",
      "Epoch: 10300 | Loss: 7.621257801065006e-08\n",
      "Epoch: 10400 | Loss: 7.595930070466716e-08\n",
      "Epoch: 10500 | Loss: 3.7464487901695294e-06\n",
      "Epoch: 10600 | Loss: 1.7404189053917144e-06\n",
      "Epoch: 10700 | Loss: 5.363883926951075e-06\n",
      "Epoch: 10800 | Loss: 2.479773075006275e-06\n",
      "Epoch: 10900 | Loss: 2.314414408284152e-05\n",
      "Epoch: 11000 | Loss: 1.983459294223274e-05\n",
      "Epoch: 11100 | Loss: 5.192837885492818e-05\n",
      "Epoch: 11200 | Loss: 3.2665323334026884e-05\n",
      "Epoch: 11300 | Loss: 1.5613527817409833e-05\n",
      "Epoch: 11400 | Loss: 1.9816361501111026e-05\n",
      "Epoch: 11500 | Loss: 1.8380457040493796e-05\n",
      "Epoch: 11600 | Loss: 1.2826840384856812e-05\n",
      "Epoch: 11700 | Loss: 2.2919805087797903e-05\n",
      "Epoch: 11800 | Loss: 9.822317841653308e-06\n",
      "Epoch: 11900 | Loss: 9.145862209293831e-05\n",
      "Epoch: 12000 | Loss: 3.213983214680735e-07\n",
      "Epoch: 12100 | Loss: 1.107519615287903e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12200 | Loss: 9.772090500936497e-08\n",
      "Epoch: 12300 | Loss: 9.01656086668964e-08\n",
      "Epoch: 12400 | Loss: 8.547596437345277e-08\n",
      "Epoch: 12500 | Loss: 8.24276080371658e-08\n",
      "Epoch: 12600 | Loss: 8.037798667256492e-08\n",
      "Epoch: 12700 | Loss: 7.896351360784508e-08\n",
      "Epoch: 12800 | Loss: 7.7966689566435e-08\n",
      "Epoch: 12900 | Loss: 7.725177805675254e-08\n",
      "Epoch: 13000 | Loss: 7.6731231867309e-08\n",
      "Epoch: 13100 | Loss: 7.63470922562807e-08\n",
      "Epoch: 13200 | Loss: 7.606017243433218e-08\n",
      "Epoch: 13300 | Loss: 7.584351228673228e-08\n",
      "Epoch: 13400 | Loss: 7.567828536383305e-08\n",
      "Epoch: 13500 | Loss: 2.8968231461952494e-06\n",
      "Epoch: 13600 | Loss: 9.867528768968777e-08\n",
      "Epoch: 13700 | Loss: 7.577813532431653e-07\n",
      "Epoch: 13800 | Loss: 1.602355849727037e-07\n",
      "Epoch: 13900 | Loss: 1.0807892739057128e-07\n",
      "Epoch: 14000 | Loss: 5.711773077655456e-07\n",
      "Epoch: 14100 | Loss: 2.13988079659274e-06\n",
      "Epoch: 14200 | Loss: 1.482123443219925e-06\n",
      "Epoch: 14300 | Loss: 8.651477539758207e-06\n",
      "Epoch: 14400 | Loss: 9.590341101305214e-06\n",
      "Epoch: 14500 | Loss: 6.556094678306147e-06\n",
      "Epoch: 14600 | Loss: 8.230913881530089e-07\n",
      "Epoch: 14700 | Loss: 2.4857168007238046e-07\n",
      "Epoch: 14800 | Loss: 2.869591300157286e-06\n",
      "Epoch: 14900 | Loss: 9.856085165313346e-06\n",
      "time=199.29656386375427\n",
      "error=5.348199768064441e-06\n",
      "best loss=7.562525842785249e-08\n",
      "best epoch=13440\n",
      "20\n",
      "Epoch: 0 | Loss: 0.0001274524157956183\n",
      "Epoch: 100 | Loss: 0.000793398882100223\n",
      "Epoch: 200 | Loss: 0.00016776352997201996\n",
      "Epoch: 300 | Loss: 0.0002154332628463666\n",
      "Epoch: 400 | Loss: 0.0002343521536939631\n",
      "Epoch: 500 | Loss: 0.0006312814771853069\n",
      "Epoch: 600 | Loss: 0.0020310547796366877\n",
      "Epoch: 700 | Loss: 0.0004424010585313971\n",
      "Epoch: 800 | Loss: 0.0006519536056950066\n",
      "Epoch: 900 | Loss: 0.0010320817577902427\n",
      "Epoch: 1000 | Loss: 0.002717127968278852\n",
      "Epoch: 1100 | Loss: 0.0008209850386353425\n",
      "Epoch: 1200 | Loss: 0.0024367983240986706\n",
      "Epoch: 1300 | Loss: 0.0013916065528379862\n",
      "Epoch: 1400 | Loss: 0.0009170411616893765\n",
      "Epoch: 1500 | Loss: 8.29487710483992e-05\n",
      "Epoch: 1600 | Loss: 0.0009563749571844225\n",
      "Epoch: 1700 | Loss: 0.001923567224536492\n",
      "Epoch: 1800 | Loss: 0.004369476112440899\n",
      "Epoch: 1900 | Loss: 0.0006374687570484895\n",
      "Epoch: 2000 | Loss: 0.001349553339551679\n",
      "Epoch: 2100 | Loss: 0.001860774713232533\n",
      "Epoch: 2200 | Loss: 0.0006999237883738386\n",
      "Epoch: 2300 | Loss: 0.0008883612390711993\n",
      "Epoch: 2400 | Loss: 0.0034850196966356006\n",
      "Epoch: 2500 | Loss: 0.010230206345202778\n",
      "Epoch: 2600 | Loss: 0.0013243574897002168\n",
      "Epoch: 2700 | Loss: 0.0026622206688338814\n",
      "Epoch: 2800 | Loss: 0.0011316454261814032\n",
      "Epoch: 2900 | Loss: 0.0022469024928300735\n",
      "Epoch: 3000 | Loss: 3.356783561600662e-05\n",
      "Epoch: 3100 | Loss: 3.3181962902660765e-06\n",
      "Epoch: 3200 | Loss: 1.3199412845629041e-06\n",
      "Epoch: 3300 | Loss: 6.957093719291617e-07\n",
      "Epoch: 3400 | Loss: 4.2577605433998396e-07\n",
      "Epoch: 3500 | Loss: 2.872163636419658e-07\n",
      "Epoch: 3600 | Loss: 2.0787547573684765e-07\n",
      "Epoch: 3700 | Loss: 1.5882217335405878e-07\n",
      "Epoch: 3800 | Loss: 1.2670384802719873e-07\n",
      "Epoch: 3900 | Loss: 1.0470826697160079e-07\n",
      "Epoch: 4000 | Loss: 8.908813828484917e-08\n",
      "Epoch: 4100 | Loss: 7.765702006498705e-08\n",
      "Epoch: 4200 | Loss: 6.907702137307431e-08\n",
      "Epoch: 4300 | Loss: 1.2760386284115238e-05\n",
      "Epoch: 4400 | Loss: 3.536920043921107e-05\n",
      "Epoch: 4500 | Loss: 0.0008440209003600111\n",
      "Epoch: 4600 | Loss: 0.00044279347922048613\n",
      "Epoch: 4700 | Loss: 0.00011575372665781548\n",
      "Epoch: 4800 | Loss: 0.0008490938917185092\n",
      "Epoch: 4900 | Loss: 0.0033035163550501406\n",
      "Epoch: 5000 | Loss: 0.0003716149619479398\n",
      "Epoch: 5100 | Loss: 0.0003601194760752958\n",
      "Epoch: 5200 | Loss: 0.0013540741911485653\n",
      "Epoch: 5300 | Loss: 0.00022546414190748653\n",
      "Epoch: 5400 | Loss: 0.0013233573190024922\n",
      "Epoch: 5500 | Loss: 0.00022972718843719466\n",
      "Epoch: 5600 | Loss: 9.980465937010837e-05\n",
      "Epoch: 5700 | Loss: 0.0007336612636718048\n",
      "Epoch: 5800 | Loss: 0.0011464604143026328\n",
      "Epoch: 5900 | Loss: 0.0009219684128553062\n",
      "Epoch: 6000 | Loss: 1.2731044896804359e-05\n",
      "Epoch: 6100 | Loss: 8.588051640651557e-07\n",
      "Epoch: 6200 | Loss: 3.352367857321316e-07\n",
      "Epoch: 6300 | Loss: 1.8135521098235855e-07\n",
      "Epoch: 6400 | Loss: 1.1750629714567263e-07\n",
      "Epoch: 6500 | Loss: 8.579870527664827e-08\n",
      "Epoch: 6600 | Loss: 6.815929560352083e-08\n",
      "Epoch: 6700 | Loss: 5.7540306604000384e-08\n",
      "Epoch: 6800 | Loss: 5.076205156693981e-08\n",
      "Epoch: 6900 | Loss: 4.6233563810892836e-08\n",
      "Epoch: 7000 | Loss: 4.309470066675581e-08\n",
      "Epoch: 7100 | Loss: 4.085153234841453e-08\n",
      "Epoch: 7200 | Loss: 3.920635813432548e-08\n",
      "Epoch: 7300 | Loss: 3.7972467958998954e-08\n",
      "Epoch: 7400 | Loss: 3.798359429715889e-05\n",
      "Epoch: 7500 | Loss: 0.00018821397796510835\n",
      "Epoch: 7600 | Loss: 9.845116189611424e-05\n",
      "Epoch: 7700 | Loss: 4.645513137976038e-05\n",
      "Epoch: 7800 | Loss: 0.00014003780704432351\n",
      "Epoch: 7900 | Loss: 8.039733128943895e-05\n",
      "Epoch: 8000 | Loss: 5.817570896200718e-05\n",
      "Epoch: 8100 | Loss: 1.9893974853041553e-05\n",
      "Epoch: 8200 | Loss: 0.0002883157170183696\n",
      "Epoch: 8300 | Loss: 0.00011054078059901022\n",
      "Epoch: 8400 | Loss: 0.00015026023018421282\n",
      "Epoch: 8500 | Loss: 2.684795543028909e-05\n",
      "Epoch: 8600 | Loss: 1.2466881096061097e-05\n",
      "Epoch: 8700 | Loss: 7.86446060403002e-06\n",
      "Epoch: 8800 | Loss: 6.0892469837070365e-05\n",
      "Epoch: 8900 | Loss: 0.00010073665579811249\n",
      "Epoch: 9000 | Loss: 2.6767730003322273e-06\n",
      "Epoch: 9100 | Loss: 2.4522000561293076e-07\n",
      "Epoch: 9200 | Loss: 1.2494363779558185e-07\n",
      "Epoch: 9300 | Loss: 8.265796219610179e-08\n",
      "Epoch: 9400 | Loss: 6.262530128868597e-08\n",
      "Epoch: 9500 | Loss: 5.183464519624792e-08\n",
      "Epoch: 9600 | Loss: 4.552486954137369e-08\n",
      "Epoch: 9700 | Loss: 4.1616469508807306e-08\n",
      "Epoch: 9800 | Loss: 3.9089327658146164e-08\n",
      "Epoch: 9900 | Loss: 3.7399679105021396e-08\n",
      "Epoch: 10000 | Loss: 3.623895121068305e-08\n",
      "Epoch: 10100 | Loss: 3.542326952166088e-08\n",
      "Epoch: 10200 | Loss: 3.4838701404119266e-08\n",
      "Epoch: 10300 | Loss: 3.441237466192709e-08\n",
      "Epoch: 10400 | Loss: 3.409650107391562e-08\n",
      "Epoch: 10500 | Loss: 3.7869343097612534e-06\n",
      "Epoch: 10600 | Loss: 6.747546209560795e-05\n",
      "Epoch: 10700 | Loss: 6.9715225853259545e-06\n",
      "Epoch: 10800 | Loss: 3.5431856159025443e-06\n",
      "Epoch: 10900 | Loss: 2.750575910693197e-05\n",
      "Epoch: 11000 | Loss: 1.8578792612123285e-05\n",
      "Epoch: 11100 | Loss: 4.041655347215396e-05\n",
      "Epoch: 11200 | Loss: 2.331302798790736e-05\n",
      "Epoch: 11300 | Loss: 2.0957446546434855e-05\n",
      "Epoch: 11400 | Loss: 4.554402853040287e-05\n",
      "Epoch: 11500 | Loss: 2.535770832654979e-05\n",
      "Epoch: 11600 | Loss: 8.259789215396408e-05\n",
      "Epoch: 11700 | Loss: 1.3451701935048877e-05\n",
      "Epoch: 11800 | Loss: 6.774545203209002e-06\n",
      "Epoch: 11900 | Loss: 0.00016972224330896773\n",
      "Epoch: 12000 | Loss: 2.206274827258135e-06\n",
      "Epoch: 12100 | Loss: 8.79669616137218e-08\n",
      "Epoch: 12200 | Loss: 6.59903275820355e-08\n",
      "Epoch: 12300 | Loss: 5.452008946673677e-08\n",
      "Epoch: 12400 | Loss: 4.764976649607259e-08\n",
      "Epoch: 12500 | Loss: 4.327635115182279e-08\n",
      "Epoch: 12600 | Loss: 4.037136509509131e-08\n",
      "Epoch: 12700 | Loss: 3.838006993955798e-08\n",
      "Epoch: 12800 | Loss: 3.6981688265644554e-08\n",
      "Epoch: 12900 | Loss: 3.598070222918905e-08\n",
      "Epoch: 13000 | Loss: 3.525293160891075e-08\n",
      "Epoch: 13100 | Loss: 3.471686668683411e-08\n",
      "Epoch: 13200 | Loss: 3.431755956492184e-08\n",
      "Epoch: 13300 | Loss: 3.4017151544071786e-08\n",
      "Epoch: 13400 | Loss: 3.3789086827024275e-08\n",
      "Epoch: 13500 | Loss: 0.00011652548597792972\n",
      "Epoch: 13600 | Loss: 6.70517256706606e-06\n",
      "Epoch: 13700 | Loss: 6.830151360220846e-06\n",
      "Epoch: 13800 | Loss: 2.437404357396928e-06\n",
      "Epoch: 13900 | Loss: 2.2506983852554904e-05\n",
      "Epoch: 14000 | Loss: 1.2277284463075235e-05\n",
      "Epoch: 14100 | Loss: 8.290394112104438e-06\n",
      "Epoch: 14200 | Loss: 5.45072019982019e-06\n",
      "Epoch: 14300 | Loss: 1.0554163907438252e-06\n",
      "Epoch: 14400 | Loss: 3.20314569926961e-05\n",
      "Epoch: 14500 | Loss: 4.83100696588379e-06\n",
      "Epoch: 14600 | Loss: 7.75035034622839e-07\n",
      "Epoch: 14700 | Loss: 3.554924989924937e-05\n",
      "Epoch: 14800 | Loss: 3.908962896521008e-06\n",
      "Epoch: 14900 | Loss: 1.0980367699136928e-05\n",
      "time=224.83816003799438\n",
      "error=7.888721965813287e-06\n",
      "best loss=3.369927487475749e-08\n",
      "best epoch=13449\n",
      "24\n",
      "Epoch: 0 | Loss: 0.005414441514689973\n",
      "Epoch: 100 | Loss: 0.0014361699369244345\n",
      "Epoch: 200 | Loss: 0.0002521574777791531\n",
      "Epoch: 300 | Loss: 0.00010812025703998596\n",
      "Epoch: 400 | Loss: 0.0002538514922431912\n",
      "Epoch: 500 | Loss: 0.001805290936184619\n",
      "Epoch: 600 | Loss: 0.0010829717364857522\n",
      "Epoch: 700 | Loss: 0.002952507868851025\n",
      "Epoch: 800 | Loss: 0.0029602177069920593\n",
      "Epoch: 900 | Loss: 0.0011095436370326054\n",
      "Epoch: 1000 | Loss: 0.0005827331489727341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1100 | Loss: 0.0016361260469708342\n",
      "Epoch: 1200 | Loss: 0.0016125798471637775\n",
      "Epoch: 1300 | Loss: 0.007099096653478979\n",
      "Epoch: 1400 | Loss: 0.004428271638403084\n",
      "Epoch: 1500 | Loss: 0.007322874659899515\n",
      "Epoch: 1600 | Loss: 0.009574734039869035\n",
      "Epoch: 1700 | Loss: 0.0021633270443292\n",
      "Epoch: 1800 | Loss: 0.0013476564802953\n",
      "Epoch: 1900 | Loss: 0.0019321390914428518\n",
      "Epoch: 2000 | Loss: 0.0010453736935737926\n",
      "Epoch: 2100 | Loss: 0.006481335880219162\n",
      "Epoch: 2200 | Loss: 0.0010118841979962277\n",
      "Epoch: 2300 | Loss: 0.00566060726093852\n",
      "Epoch: 2400 | Loss: 0.00410929747733383\n",
      "Epoch: 2500 | Loss: 0.006761841055092565\n",
      "Epoch: 2600 | Loss: 0.0005948542757755408\n",
      "Epoch: 2700 | Loss: 0.002266275113422804\n",
      "Epoch: 2800 | Loss: 0.004887229172038927\n",
      "Epoch: 2900 | Loss: 0.0044328342088295145\n",
      "Epoch: 3000 | Loss: 0.00015421640197940304\n",
      "Epoch: 3100 | Loss: 4.828801303226221e-06\n",
      "Epoch: 3200 | Loss: 1.8810697556744684e-06\n",
      "Epoch: 3300 | Loss: 1.0382785602670663e-06\n",
      "Epoch: 3400 | Loss: 6.566274022112986e-07\n",
      "Epoch: 3500 | Loss: 4.482623978999882e-07\n",
      "Epoch: 3600 | Loss: 3.2193372091384677e-07\n",
      "Epoch: 3700 | Loss: 2.4001396768900406e-07\n",
      "Epoch: 3800 | Loss: 1.8436143230073166e-07\n",
      "Epoch: 3900 | Loss: 1.4524254848469036e-07\n",
      "Epoch: 4000 | Loss: 1.1700861833634045e-07\n",
      "Epoch: 4100 | Loss: 9.618459384737957e-08\n",
      "Epoch: 4200 | Loss: 0.00018624049864005934\n",
      "Epoch: 4300 | Loss: 4.372220758761856e-05\n",
      "Epoch: 4400 | Loss: 0.0022747145321072686\n",
      "Epoch: 4500 | Loss: 0.0005029277413904511\n",
      "Epoch: 4600 | Loss: 0.0021259261166702674\n",
      "Epoch: 4700 | Loss: 0.002026021965277395\n",
      "Epoch: 4800 | Loss: 0.0003515610490038584\n",
      "Epoch: 4900 | Loss: 0.0021350209176493797\n",
      "Epoch: 5000 | Loss: 0.00044748432588240597\n",
      "Epoch: 5100 | Loss: 0.0003368760470560166\n",
      "Epoch: 5200 | Loss: 0.00023849195686278998\n",
      "Epoch: 5300 | Loss: 0.00015822525907518292\n",
      "Epoch: 5400 | Loss: 0.002144747708108004\n",
      "Epoch: 5500 | Loss: 0.001399058078502164\n",
      "Epoch: 5600 | Loss: 0.0007965342142983705\n",
      "Epoch: 5700 | Loss: 0.00035875551439282065\n",
      "Epoch: 5800 | Loss: 0.004281071797810595\n",
      "Epoch: 5900 | Loss: 0.0006515425147428221\n",
      "Epoch: 6000 | Loss: 6.510936838626234e-06\n",
      "Epoch: 6100 | Loss: 8.119762984782653e-07\n",
      "Epoch: 6200 | Loss: 3.1896044920239887e-07\n",
      "Epoch: 6300 | Loss: 1.7026966651111141e-07\n",
      "Epoch: 6400 | Loss: 1.069555061185248e-07\n",
      "Epoch: 6500 | Loss: 7.458494056712867e-08\n",
      "Epoch: 6600 | Loss: 5.606178473070932e-08\n",
      "Epoch: 6700 | Loss: 4.462323928569673e-08\n",
      "Epoch: 6800 | Loss: 3.71589635991522e-08\n",
      "Epoch: 6900 | Loss: 3.2079169623573794e-08\n",
      "Epoch: 7000 | Loss: 2.85052371345097e-08\n",
      "Epoch: 7100 | Loss: 2.592141965646884e-08\n",
      "Epoch: 7200 | Loss: 2.9894548412826423e-07\n",
      "Epoch: 7300 | Loss: 1.4329988692595763e-05\n",
      "Epoch: 7400 | Loss: 5.427026705658033e-06\n",
      "Epoch: 7500 | Loss: 0.00015651985853652725\n",
      "Epoch: 7600 | Loss: 0.0007690780308467904\n",
      "Epoch: 7700 | Loss: 0.0005493474044300458\n",
      "Epoch: 7800 | Loss: 0.00015677789531750073\n",
      "Epoch: 7900 | Loss: 0.0001522348795653495\n",
      "Epoch: 8000 | Loss: 0.0006653317124525527\n",
      "Epoch: 8100 | Loss: 0.0001049822775149402\n",
      "Epoch: 8200 | Loss: 3.709992168571995e-05\n",
      "Epoch: 8300 | Loss: 0.0012873318388376847\n",
      "Epoch: 8400 | Loss: 0.00029849100219945347\n",
      "Epoch: 8500 | Loss: 3.959244521802928e-05\n",
      "Epoch: 8600 | Loss: 0.0003427409110978998\n",
      "Epoch: 8700 | Loss: 8.429185037798971e-05\n",
      "Epoch: 8800 | Loss: 0.0003798651913908932\n",
      "Epoch: 8900 | Loss: 0.0002019842123767111\n",
      "Epoch: 9000 | Loss: 1.353595585309306e-06\n",
      "Epoch: 9100 | Loss: 2.4931686603671917e-07\n",
      "Epoch: 9200 | Loss: 1.1898712893020588e-07\n",
      "Epoch: 9300 | Loss: 7.15968991469117e-08\n",
      "Epoch: 9400 | Loss: 4.946245963890451e-08\n",
      "Epoch: 9500 | Loss: 3.7621574547380776e-08\n",
      "Epoch: 9600 | Loss: 3.0705697809320814e-08\n",
      "Epoch: 9700 | Loss: 2.6409323310681463e-08\n",
      "Epoch: 9800 | Loss: 2.361548846688135e-08\n",
      "Epoch: 9900 | Loss: 2.173360243228991e-08\n",
      "Epoch: 10000 | Loss: 2.0429937302757496e-08\n",
      "Epoch: 10100 | Loss: 1.95058321036724e-08\n",
      "Epoch: 10200 | Loss: 1.883799020827123e-08\n",
      "Epoch: 10300 | Loss: 1.8347240430069573e-08\n",
      "Epoch: 10400 | Loss: 0.0001505995256087126\n",
      "Epoch: 10500 | Loss: 4.0656090372991966e-05\n",
      "Epoch: 10600 | Loss: 6.694249978601762e-06\n",
      "Epoch: 10700 | Loss: 8.838473792426678e-05\n",
      "Epoch: 10800 | Loss: 3.845779917116523e-05\n",
      "Epoch: 10900 | Loss: 8.957603316909942e-05\n",
      "Epoch: 11000 | Loss: 3.510510955147415e-05\n",
      "Epoch: 11100 | Loss: 2.0438456038971007e-05\n",
      "Epoch: 11200 | Loss: 4.8131877790084614e-05\n",
      "Epoch: 11300 | Loss: 0.00011431702466302841\n",
      "Epoch: 11400 | Loss: 1.3758383947787002e-05\n",
      "Epoch: 11500 | Loss: 7.459014574427185e-06\n",
      "Epoch: 11600 | Loss: 1.1586640839887092e-05\n",
      "Epoch: 11700 | Loss: 1.5859913574507743e-05\n",
      "Epoch: 11800 | Loss: 3.67705133061856e-05\n",
      "Epoch: 11900 | Loss: 1.2579551402841965e-05\n",
      "Epoch: 12000 | Loss: 3.0678734941350097e-07\n",
      "Epoch: 12100 | Loss: 9.927640658155663e-08\n",
      "Epoch: 12200 | Loss: 6.198896925390593e-08\n",
      "Epoch: 12300 | Loss: 4.464635810011993e-08\n",
      "Epoch: 12400 | Loss: 3.510950120438682e-08\n",
      "Epoch: 12500 | Loss: 2.9353403978271813e-08\n",
      "Epoch: 12600 | Loss: 2.5660874200048e-08\n",
      "Epoch: 12700 | Loss: 2.318817944467964e-08\n",
      "Epoch: 12800 | Loss: 2.1478731017522723e-08\n",
      "Epoch: 12900 | Loss: 2.0267561773647987e-08\n",
      "Epoch: 13000 | Loss: 1.9392558408758028e-08\n",
      "Epoch: 13100 | Loss: 1.8750344285695236e-08\n",
      "Epoch: 13200 | Loss: 1.82727687694888e-08\n",
      "Epoch: 13300 | Loss: 1.7913663055720222e-08\n",
      "Epoch: 13400 | Loss: 1.7641034003688183e-08\n",
      "Epoch: 13500 | Loss: 4.7625863277462406e-05\n",
      "Epoch: 13600 | Loss: 1.3423040604762334e-06\n",
      "Epoch: 13700 | Loss: 1.1513713522461743e-05\n",
      "Epoch: 13800 | Loss: 1.2714993843731198e-06\n",
      "Epoch: 13900 | Loss: 1.1783472574908936e-05\n",
      "Epoch: 14000 | Loss: 5.470826499258085e-06\n",
      "Epoch: 14100 | Loss: 1.5380900441785816e-05\n",
      "Epoch: 14200 | Loss: 1.4840412335615129e-05\n",
      "Epoch: 14300 | Loss: 5.444832947983037e-06\n",
      "Epoch: 14400 | Loss: 7.874134998526785e-06\n",
      "Epoch: 14500 | Loss: 4.445536772312249e-06\n",
      "Epoch: 14600 | Loss: 1.3895683030791585e-06\n",
      "Epoch: 14700 | Loss: 4.3038491267945575e-06\n",
      "Epoch: 14800 | Loss: 4.1400163123497e-06\n",
      "Epoch: 14900 | Loss: 3.781583827645702e-05\n",
      "time=247.05724692344666\n",
      "error=1.611857747116413e-05\n",
      "best loss=1.7571527775266567e-08\n",
      "best epoch=13432\n",
      "28\n",
      "Epoch: 0 | Loss: 0.0012710603051314879\n",
      "Epoch: 100 | Loss: 0.0028469086372912805\n",
      "Epoch: 200 | Loss: 0.0004965173397442661\n",
      "Epoch: 300 | Loss: 0.00022524025585215801\n",
      "Epoch: 400 | Loss: 0.0001508122379862865\n",
      "Epoch: 500 | Loss: 0.0006591184354583701\n",
      "Epoch: 600 | Loss: 0.001184493149520913\n",
      "Epoch: 700 | Loss: 0.001340198005065065\n",
      "Epoch: 800 | Loss: 0.0032602093742425784\n",
      "Epoch: 900 | Loss: 0.0019980322831182513\n",
      "Epoch: 1000 | Loss: 0.0022547366730901056\n",
      "Epoch: 1100 | Loss: 0.0034271821433279016\n",
      "Epoch: 1200 | Loss: 0.004202378351769217\n",
      "Epoch: 1300 | Loss: 0.004593822581507601\n",
      "Epoch: 1400 | Loss: 0.005457238646805512\n",
      "Epoch: 1500 | Loss: 0.004173008040278981\n",
      "Epoch: 1600 | Loss: 0.009779767140049926\n",
      "Epoch: 1700 | Loss: 0.002852541268072744\n",
      "Epoch: 1800 | Loss: 0.0025191825459254347\n",
      "Epoch: 1900 | Loss: 0.008999980381111366\n",
      "Epoch: 2000 | Loss: 0.00517924689101594\n",
      "Epoch: 2100 | Loss: 0.0043482350919534195\n",
      "Epoch: 2200 | Loss: 0.0037475844190052532\n",
      "Epoch: 2300 | Loss: 0.005986288403506223\n",
      "Epoch: 2400 | Loss: 0.004430390650790335\n",
      "Epoch: 2500 | Loss: 0.0031452347612293753\n",
      "Epoch: 2600 | Loss: 0.003516490610854698\n",
      "Epoch: 2700 | Loss: 0.004730828510887233\n",
      "Epoch: 2800 | Loss: 0.0040179268674041466\n",
      "Epoch: 2900 | Loss: 0.0014716185760694734\n",
      "Epoch: 3000 | Loss: 0.0020397024569937007\n",
      "Epoch: 3100 | Loss: 2.6746690044622866e-05\n",
      "Epoch: 3200 | Loss: 1.2166990284525196e-05\n",
      "Epoch: 3300 | Loss: 6.75185110035711e-06\n",
      "Epoch: 3400 | Loss: 4.05926228065765e-06\n",
      "Epoch: 3500 | Loss: 2.5976100104720972e-06\n",
      "Epoch: 3600 | Loss: 1.7708520688959462e-06\n",
      "Epoch: 3700 | Loss: 1.2801512624865085e-06\n",
      "Epoch: 3800 | Loss: 9.680964226237564e-07\n",
      "Epoch: 3900 | Loss: 7.562827868660207e-07\n",
      "Epoch: 4000 | Loss: 6.049507236609002e-07\n",
      "Epoch: 4100 | Loss: 0.00013862494116445437\n",
      "Epoch: 4200 | Loss: 1.1899992848078026e-06\n",
      "Epoch: 4300 | Loss: 7.971313200994428e-06\n",
      "Epoch: 4400 | Loss: 0.0007518093637635897\n",
      "Epoch: 4500 | Loss: 0.0005330703840364305\n",
      "Epoch: 4600 | Loss: 0.0021715805429888494\n",
      "Epoch: 4700 | Loss: 0.003115311681405091\n",
      "Epoch: 4800 | Loss: 0.0019943408038538574\n",
      "Epoch: 4900 | Loss: 0.0010435181816467825\n",
      "Epoch: 5000 | Loss: 0.001324018851551215\n",
      "Epoch: 5100 | Loss: 0.0012748214970560053\n",
      "Epoch: 5200 | Loss: 0.0011006077752462348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5300 | Loss: 0.00134900638798252\n",
      "Epoch: 5400 | Loss: 0.0012288311229292333\n",
      "Epoch: 5500 | Loss: 0.0004443030211220241\n",
      "Epoch: 5600 | Loss: 0.0008478754302084278\n",
      "Epoch: 5700 | Loss: 0.00013811060487840866\n",
      "Epoch: 5800 | Loss: 0.0013261572521379372\n",
      "Epoch: 5900 | Loss: 0.0010685750368671424\n",
      "Epoch: 6000 | Loss: 2.4440257835594705e-05\n",
      "Epoch: 6100 | Loss: 1.9593769438388122e-06\n",
      "Epoch: 6200 | Loss: 8.92453459728616e-07\n",
      "Epoch: 6300 | Loss: 5.440329212318864e-07\n",
      "Epoch: 6400 | Loss: 3.730824445413031e-07\n",
      "Epoch: 6500 | Loss: 2.712978476651794e-07\n",
      "Epoch: 6600 | Loss: 2.0349804978756195e-07\n",
      "Epoch: 6700 | Loss: 1.552920471649232e-07\n",
      "Epoch: 6800 | Loss: 1.1994774006227727e-07\n",
      "Epoch: 6900 | Loss: 9.385323333793584e-08\n",
      "Epoch: 7000 | Loss: 7.463782438292203e-08\n",
      "Epoch: 7100 | Loss: 6.047909271337684e-08\n",
      "Epoch: 7200 | Loss: 4.995667425402291e-08\n",
      "Epoch: 7300 | Loss: 1.8510378573524597e-05\n",
      "Epoch: 7400 | Loss: 0.00040383629974882285\n",
      "Epoch: 7500 | Loss: 0.0008373090121607414\n",
      "Epoch: 7600 | Loss: 0.0003755168743997248\n",
      "Epoch: 7700 | Loss: 0.0008378864347473596\n",
      "Epoch: 7800 | Loss: 6.327399828335743e-05\n",
      "Epoch: 7900 | Loss: 0.0005716442161430146\n",
      "Epoch: 8000 | Loss: 0.000645513213595397\n",
      "Epoch: 8100 | Loss: 6.061598451612435e-05\n",
      "Epoch: 8200 | Loss: 0.0002097792702685291\n",
      "Epoch: 8300 | Loss: 0.00025732462486046\n",
      "Epoch: 8400 | Loss: 0.0008288192918729907\n",
      "Epoch: 8500 | Loss: 5.829244259035517e-05\n",
      "Epoch: 8600 | Loss: 0.00029629721403776174\n",
      "Epoch: 8700 | Loss: 8.584451082593434e-05\n",
      "Epoch: 8800 | Loss: 0.00044732843679462194\n",
      "Epoch: 8900 | Loss: 0.0006957819723814464\n",
      "Epoch: 9000 | Loss: 6.032621402649603e-06\n",
      "Epoch: 9100 | Loss: 3.454463527323066e-07\n",
      "Epoch: 9200 | Loss: 1.573868565859623e-07\n",
      "Epoch: 9300 | Loss: 9.058007158914424e-08\n",
      "Epoch: 9400 | Loss: 5.9179956033422256e-08\n",
      "Epoch: 9500 | Loss: 4.214634760297218e-08\n",
      "Epoch: 9600 | Loss: 3.200678429718314e-08\n",
      "Epoch: 9700 | Loss: 2.556659080313095e-08\n",
      "Epoch: 9800 | Loss: 2.127668201589426e-08\n",
      "Epoch: 9900 | Loss: 1.8313693565361676e-08\n",
      "Epoch: 10000 | Loss: 1.620818483809776e-08\n",
      "Epoch: 10100 | Loss: 1.4677289393682174e-08\n",
      "Epoch: 10200 | Loss: 1.3542820552997043e-08\n",
      "Epoch: 10300 | Loss: 1.268840117690297e-08\n",
      "Epoch: 10400 | Loss: 1.0591924731038717e-05\n",
      "Epoch: 10500 | Loss: 1.9387575437687513e-05\n",
      "Epoch: 10600 | Loss: 7.311934201547175e-05\n",
      "Epoch: 10700 | Loss: 9.44199789816507e-05\n",
      "Epoch: 10800 | Loss: 9.683270879197895e-05\n",
      "Epoch: 10900 | Loss: 0.00011260659553459829\n",
      "Epoch: 11000 | Loss: 1.041274607137773e-05\n",
      "Epoch: 11100 | Loss: 4.289266070362417e-05\n",
      "Epoch: 11200 | Loss: 9.573259732445288e-05\n",
      "Epoch: 11300 | Loss: 1.0786322242569183e-05\n",
      "Epoch: 11400 | Loss: 1.9873347852630927e-05\n",
      "Epoch: 11500 | Loss: 9.537476754357499e-05\n",
      "Epoch: 11600 | Loss: 2.2784344935544697e-05\n",
      "Epoch: 11700 | Loss: 3.956673397607242e-05\n",
      "Epoch: 11800 | Loss: 5.137738157179072e-05\n",
      "Epoch: 11900 | Loss: 1.9247570378538946e-05\n",
      "Epoch: 12000 | Loss: 4.550705162779977e-06\n",
      "Epoch: 12100 | Loss: 1.1058211542621771e-07\n",
      "Epoch: 12200 | Loss: 6.150565835825939e-08\n",
      "Epoch: 12300 | Loss: 4.1355519418899005e-08\n",
      "Epoch: 12400 | Loss: 3.0378643967394674e-08\n",
      "Epoch: 12500 | Loss: 2.3806185683365344e-08\n",
      "Epoch: 12600 | Loss: 1.9617269796767695e-08\n",
      "Epoch: 12700 | Loss: 1.6824022008066413e-08\n",
      "Epoch: 12800 | Loss: 1.4896173317574594e-08\n",
      "Epoch: 12900 | Loss: 1.3529051796671847e-08\n",
      "Epoch: 13000 | Loss: 1.2538160445092819e-08\n",
      "Epoch: 13100 | Loss: 1.1806967970083925e-08\n",
      "Epoch: 13200 | Loss: 1.1259279466879586e-08\n",
      "Epoch: 13300 | Loss: 1.084381270255121e-08\n",
      "Epoch: 13400 | Loss: 9.2923198313135e-08\n",
      "Epoch: 13500 | Loss: 1.2148993887168515e-05\n",
      "Epoch: 13600 | Loss: 4.661638744091158e-06\n",
      "Epoch: 13700 | Loss: 5.937427172523975e-05\n",
      "Epoch: 13800 | Loss: 4.911472832070075e-06\n",
      "Epoch: 13900 | Loss: 4.5549876794955925e-06\n",
      "Epoch: 14000 | Loss: 2.3949014199022513e-05\n",
      "Epoch: 14100 | Loss: 3.1217653530164714e-05\n",
      "Epoch: 14200 | Loss: 1.9552439972319287e-05\n",
      "Epoch: 14300 | Loss: 3.7366191610303758e-06\n",
      "Epoch: 14400 | Loss: 1.4124200300737138e-05\n",
      "Epoch: 14500 | Loss: 4.4815203284679736e-05\n",
      "Epoch: 14600 | Loss: 3.04196551393634e-05\n",
      "Epoch: 14700 | Loss: 1.3671921264418361e-05\n",
      "Epoch: 14800 | Loss: 2.3986476687807222e-05\n",
      "Epoch: 14900 | Loss: 4.689275878552811e-06\n",
      "time=258.6552448272705\n",
      "error=6.900513720252532e-06\n",
      "best loss=1.0564115688567423e-08\n",
      "best epoch=13388\n",
      "32\n",
      "Epoch: 0 | Loss: 0.00031669519504513947\n",
      "Epoch: 100 | Loss: 0.005373154009595387\n",
      "Epoch: 200 | Loss: 0.0012422280285219137\n",
      "Epoch: 300 | Loss: 0.00037587736908989183\n",
      "Epoch: 400 | Loss: 0.0005470477151321737\n",
      "Epoch: 500 | Loss: 0.000587214290025831\n",
      "Epoch: 600 | Loss: 0.0023192478644198803\n",
      "Epoch: 700 | Loss: 0.002732995142944588\n",
      "Epoch: 800 | Loss: 0.0007545286748879885\n",
      "Epoch: 900 | Loss: 0.0026782376311850547\n",
      "Epoch: 1000 | Loss: 0.004343116758011185\n",
      "Epoch: 1100 | Loss: 0.005471187404186173\n",
      "Epoch: 1200 | Loss: 0.009674587916116062\n",
      "Epoch: 1300 | Loss: 0.0043334725114615134\n",
      "Epoch: 1400 | Loss: 0.013793536342657259\n",
      "Epoch: 1500 | Loss: 0.009201539220154292\n",
      "Epoch: 1600 | Loss: 0.0027201687553704565\n",
      "Epoch: 1700 | Loss: 0.006931494898835505\n",
      "Epoch: 1800 | Loss: 0.0026261453311394885\n",
      "Epoch: 1900 | Loss: 38326991.05279271\n",
      "Epoch: 2000 | Loss: 2087791.7721811063\n",
      "Epoch: 2100 | Loss: 900331.836628203\n",
      "Epoch: 2200 | Loss: 787482.8898074925\n",
      "Epoch: 2300 | Loss: 702062.9811954754\n",
      "Epoch: 2400 | Loss: 634215.8304881001\n",
      "Epoch: 2500 | Loss: 578586.041931878\n",
      "Epoch: 2600 | Loss: 531894.0106005023\n",
      "Epoch: 2700 | Loss: 491984.70727284334\n",
      "Epoch: 2800 | Loss: 457369.7553632315\n",
      "Epoch: 2900 | Loss: 426981.18853265524\n",
      "Epoch: 3000 | Loss: 400156.10332362406\n",
      "Epoch: 3100 | Loss: 387649.8774760367\n",
      "Epoch: 3200 | Loss: 375506.219685029\n",
      "Epoch: 3300 | Loss: 363714.1438593967\n",
      "Epoch: 3400 | Loss: 352266.48457218695\n",
      "Epoch: 3500 | Loss: 341155.6943573336\n",
      "Epoch: 3600 | Loss: 330373.9553784411\n",
      "Epoch: 3700 | Loss: 319913.26462472946\n",
      "Epoch: 3800 | Loss: 309765.499882172\n",
      "Epoch: 3900 | Loss: 299922.4731719539\n",
      "Epoch: 4000 | Loss: 290375.9764767522\n",
      "Epoch: 4100 | Loss: 281117.8224623695\n",
      "Epoch: 4200 | Loss: 272139.8812222772\n",
      "Epoch: 4300 | Loss: 263434.11308626534\n",
      "Epoch: 4400 | Loss: 254992.59719632103\n",
      "Epoch: 4500 | Loss: 246807.55551540875\n",
      "Epoch: 4600 | Loss: 238871.37257697847\n",
      "Epoch: 4700 | Loss: 231176.61090967542\n",
      "Epoch: 4800 | Loss: 223716.02223066642\n",
      "Epoch: 4900 | Loss: 216482.55703193805\n",
      "Epoch: 5000 | Loss: 209469.36887223175\n",
      "Epoch: 5100 | Loss: 202669.8169692708\n",
      "Epoch: 5200 | Loss: 196077.4624638125\n",
      "Epoch: 5300 | Loss: 189686.17052474138\n",
      "Epoch: 5400 | Loss: 183489.77958107684\n",
      "Epoch: 5500 | Loss: 177482.54848622068\n",
      "Epoch: 5600 | Loss: 171658.85322054726\n",
      "Epoch: 5700 | Loss: 166013.26089919507\n",
      "Epoch: 5800 | Loss: 160540.52675491688\n",
      "Epoch: 5900 | Loss: 155235.58082812277\n",
      "Epoch: 6000 | Loss: 150118.90766851127\n",
      "Epoch: 6100 | Loss: 147579.61609831467\n",
      "Epoch: 6200 | Loss: 145019.0079648135\n",
      "Epoch: 6300 | Loss: 142439.18235402694\n",
      "Epoch: 6400 | Loss: 139842.7089110829\n",
      "Epoch: 6500 | Loss: 137232.19616985405\n",
      "Epoch: 6600 | Loss: 134610.28808755547\n",
      "Epoch: 6700 | Loss: 131979.65977414855\n",
      "Epoch: 6800 | Loss: 129342.9958365725\n",
      "Epoch: 6900 | Loss: 126702.97726571202\n",
      "Epoch: 7000 | Loss: 124062.30335264788\n",
      "Epoch: 7100 | Loss: 121423.59387345043\n",
      "Epoch: 7200 | Loss: 118789.49886226217\n",
      "Epoch: 7300 | Loss: 116162.60514405336\n",
      "Epoch: 7400 | Loss: 113545.45304953273\n",
      "Epoch: 7500 | Loss: 110940.52609894013\n",
      "Epoch: 7600 | Loss: 108350.2419291003\n",
      "Epoch: 7700 | Loss: 105776.94397152377\n",
      "Epoch: 7800 | Loss: 103222.92726459855\n",
      "Epoch: 7900 | Loss: 100690.31627256109\n",
      "Epoch: 8000 | Loss: 98181.22410899962\n",
      "Epoch: 8100 | Loss: 95697.64008513979\n",
      "Epoch: 8200 | Loss: 93241.45176302374\n",
      "Epoch: 8300 | Loss: 90814.44220565225\n",
      "Epoch: 8400 | Loss: 88418.29099505144\n",
      "Epoch: 8500 | Loss: 86054.56984532354\n",
      "Epoch: 8600 | Loss: 83724.71787947214\n",
      "Epoch: 8700 | Loss: 81430.09237029843\n",
      "Epoch: 8800 | Loss: 79171.93664519879\n",
      "Epoch: 8900 | Loss: 76951.33769881466\n",
      "Epoch: 9000 | Loss: 74780.15815918584\n",
      "Epoch: 9100 | Loss: 73691.73011829126\n",
      "Epoch: 9200 | Loss: 72587.09453014584\n",
      "Epoch: 9300 | Loss: 71467.03328445702\n",
      "Epoch: 9400 | Loss: 70332.53619942753\n",
      "Epoch: 9500 | Loss: 69184.6627948138\n",
      "Epoch: 9600 | Loss: 68024.47229617789\n",
      "Epoch: 9700 | Loss: 66853.12020973564\n",
      "Epoch: 9800 | Loss: 65671.78496255648\n",
      "Epoch: 9900 | Loss: 64481.68091576224\n",
      "Epoch: 10000 | Loss: 63284.053264178685\n",
      "Epoch: 10100 | Loss: 62080.17262510467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10200 | Loss: 60871.329327344116\n",
      "Epoch: 10300 | Loss: 59658.82798608622\n",
      "Epoch: 10400 | Loss: 58443.979272204306\n",
      "Epoch: 10500 | Loss: 57228.12540832511\n",
      "Epoch: 10600 | Loss: 56012.519278194304\n",
      "Epoch: 10700 | Loss: 54798.492025906584\n",
      "Epoch: 10800 | Loss: 53587.337801870424\n",
      "Epoch: 10900 | Loss: 52380.31461881033\n",
      "Epoch: 11000 | Loss: 51178.658755402415\n",
      "Epoch: 11100 | Loss: 49983.57572812708\n",
      "Epoch: 11200 | Loss: 48796.234280967394\n",
      "Epoch: 11300 | Loss: 47617.76186987372\n",
      "Epoch: 11400 | Loss: 46449.24036689882\n",
      "Epoch: 11500 | Loss: 45291.70225437441\n",
      "Epoch: 11600 | Loss: 44146.12069399904\n",
      "Epoch: 11700 | Loss: 43013.47403503292\n",
      "Epoch: 11800 | Loss: 41894.52655557371\n",
      "Epoch: 11900 | Loss: 40790.164964220334\n",
      "Epoch: 12000 | Loss: 39706.50824630841\n",
      "Epoch: 12100 | Loss: 39161.80627668738\n",
      "Epoch: 12200 | Loss: 38608.02801047423\n",
      "Epoch: 12300 | Loss: 38045.530370331166\n",
      "Epoch: 12400 | Loss: 37474.77295831249\n",
      "Epoch: 12500 | Loss: 36896.24477909471\n",
      "Epoch: 12600 | Loss: 36310.473940456184\n",
      "Epoch: 12700 | Loss: 35717.979065380794\n",
      "Epoch: 12800 | Loss: 35119.34006137865\n",
      "Epoch: 12900 | Loss: 34515.14408916601\n",
      "Epoch: 13000 | Loss: 33905.99745067542\n",
      "Epoch: 13100 | Loss: 33292.52309363356\n",
      "Epoch: 13200 | Loss: 32675.35768640571\n",
      "Epoch: 13300 | Loss: 32055.14864532934\n",
      "Epoch: 13400 | Loss: 31432.55133785025\n",
      "Epoch: 13500 | Loss: 30808.23749196952\n",
      "Epoch: 13600 | Loss: 30182.848845969995\n",
      "Epoch: 13700 | Loss: 29557.055055503126\n",
      "Epoch: 13800 | Loss: 28931.51622723288\n",
      "Epoch: 13900 | Loss: 28306.885206638573\n",
      "Epoch: 14000 | Loss: 27683.802591856514\n",
      "Epoch: 14100 | Loss: 27062.90393197928\n",
      "Epoch: 14200 | Loss: 26444.80742191126\n",
      "Epoch: 14300 | Loss: 25830.113643235374\n",
      "Epoch: 14400 | Loss: 25219.40662036023\n",
      "Epoch: 14500 | Loss: 24613.286603549765\n",
      "Epoch: 14600 | Loss: 24012.218019929227\n",
      "Epoch: 14700 | Loss: 23416.76771674027\n",
      "Epoch: 14800 | Loss: 22827.423304188113\n",
      "Epoch: 14900 | Loss: 22244.653497241663\n",
      "time=279.60764598846436\n",
      "error=21674.622533211317\n",
      "best loss=0.0001744818289701939\n",
      "best epoch=440\n",
      "36\n",
      "Epoch: 0 | Loss: 0.0002737954821343875\n",
      "Epoch: 100 | Loss: 0.023474044889483243\n",
      "Epoch: 200 | Loss: 0.009865098475598143\n",
      "Epoch: 300 | Loss: 0.005191469979690784\n",
      "Epoch: 400 | Loss: 0.0032280644423754914\n",
      "Epoch: 500 | Loss: 0.0021986093630249415\n",
      "Epoch: 600 | Loss: 0.0015868012892607918\n",
      "Epoch: 700 | Loss: 0.001151090560768449\n",
      "Epoch: 800 | Loss: 0.001184694937130898\n",
      "Epoch: 900 | Loss: 0.0009032199559482969\n",
      "Epoch: 1000 | Loss: 0.000603071851000227\n",
      "Epoch: 1100 | Loss: 0.0006522125880158105\n",
      "Epoch: 1200 | Loss: 0.0010943928373887387\n",
      "Epoch: 1300 | Loss: 0.0005225294320286312\n",
      "Epoch: 1400 | Loss: 0.0008543269696107426\n",
      "Epoch: 1500 | Loss: 0.0019866089058140726\n",
      "Epoch: 1600 | Loss: 0.0012894310157120813\n",
      "Epoch: 1700 | Loss: 0.0015313199268971688\n",
      "Epoch: 1800 | Loss: 0.0028536732707731046\n",
      "Epoch: 1900 | Loss: 0.004625410879579595\n",
      "Epoch: 2000 | Loss: 0.005413067791209888\n",
      "Epoch: 2100 | Loss: 0.006168030481308105\n",
      "Epoch: 2200 | Loss: 0.0038673966450466987\n",
      "Epoch: 2300 | Loss: 0.00676309834281614\n",
      "Epoch: 2400 | Loss: 0.003601661580888123\n",
      "Epoch: 2500 | Loss: 0.008099988193893619\n",
      "Epoch: 2600 | Loss: 0.002753799159258971\n",
      "Epoch: 2700 | Loss: 0.0034300388133297597\n",
      "Epoch: 2800 | Loss: 0.002995499796175893\n",
      "Epoch: 2900 | Loss: 0.004286529766311149\n",
      "Epoch: 3000 | Loss: 0.00019938391951299434\n",
      "Epoch: 3100 | Loss: 3.248215154241486e-05\n",
      "Epoch: 3200 | Loss: 2.1349349241289298e-05\n",
      "Epoch: 3300 | Loss: 1.6531363779510284e-05\n",
      "Epoch: 3400 | Loss: 1.3562954382390872e-05\n",
      "Epoch: 3500 | Loss: 1.1454316950305942e-05\n",
      "Epoch: 3600 | Loss: 9.856107392496006e-06\n",
      "Epoch: 3700 | Loss: 8.581946561430564e-06\n",
      "Epoch: 3800 | Loss: 7.737644725150973e-06\n",
      "Epoch: 3900 | Loss: 7.239673565962203e-06\n",
      "Epoch: 4000 | Loss: 1.0241384658718973e-05\n",
      "Epoch: 4100 | Loss: 9.861803522075206e-06\n",
      "Epoch: 4200 | Loss: 2.1583759311963596e-05\n",
      "Epoch: 4300 | Loss: 0.0005099973842876983\n",
      "Epoch: 4400 | Loss: 0.0006694160270058515\n",
      "Epoch: 4500 | Loss: 0.0013252547667026158\n",
      "Epoch: 4600 | Loss: 0.003548876778453998\n",
      "Epoch: 4700 | Loss: 0.0019805397425893315\n",
      "Epoch: 4800 | Loss: 0.0011722077400437227\n",
      "Epoch: 4900 | Loss: 0.002250147370583494\n",
      "Epoch: 5000 | Loss: 0.001522617118509243\n",
      "Epoch: 5100 | Loss: 0.002231294927272449\n",
      "Epoch: 5200 | Loss: 0.0021683638373456724\n",
      "Epoch: 5300 | Loss: 0.0008014894174387087\n",
      "Epoch: 5400 | Loss: 0.0021256405061573494\n",
      "Epoch: 5500 | Loss: 0.003101264654578653\n",
      "Epoch: 5600 | Loss: 0.00210518866518655\n",
      "Epoch: 5700 | Loss: 0.0012763023431778505\n",
      "Epoch: 5800 | Loss: 0.0036784747716252612\n",
      "Epoch: 5900 | Loss: 0.0007457634191811066\n",
      "Epoch: 6000 | Loss: 2.3228913155649002e-05\n",
      "Epoch: 6100 | Loss: 4.113105387971993e-06\n",
      "Epoch: 6200 | Loss: 2.604878241695864e-06\n",
      "Epoch: 6300 | Loss: 1.965104644211222e-06\n",
      "Epoch: 6400 | Loss: 1.5803741765966732e-06\n",
      "Epoch: 6500 | Loss: 1.3164101849068816e-06\n",
      "Epoch: 6600 | Loss: 1.1232311121018738e-06\n",
      "Epoch: 6700 | Loss: 1.1684638455938348e-06\n",
      "Epoch: 6800 | Loss: 8.609063883958229e-07\n",
      "Epoch: 6900 | Loss: 7.685852818850624e-07\n",
      "Epoch: 7000 | Loss: 7.871309936685419e-07\n",
      "Epoch: 7100 | Loss: 8.058897616937415e-07\n",
      "Epoch: 7200 | Loss: 1.4335108147117592e-06\n",
      "Epoch: 7300 | Loss: 0.0001692869983899713\n",
      "Epoch: 7400 | Loss: 0.0009048050870131379\n",
      "Epoch: 7500 | Loss: 0.00036304073389841656\n",
      "Epoch: 7600 | Loss: 0.0009186597833982183\n",
      "Epoch: 7700 | Loss: 0.0010287186631479845\n",
      "Epoch: 7800 | Loss: 0.0006978227736415904\n",
      "Epoch: 7900 | Loss: 0.00018884358899338993\n",
      "Epoch: 8000 | Loss: 0.001457934264147294\n",
      "Epoch: 8100 | Loss: 0.0004947336482157868\n",
      "Epoch: 8200 | Loss: 0.0012210480751543192\n",
      "Epoch: 8300 | Loss: 0.0003543060339378272\n",
      "Epoch: 8400 | Loss: 0.0006753731119449911\n",
      "Epoch: 8500 | Loss: 0.0003249767184889797\n",
      "Epoch: 8600 | Loss: 0.0003255231679860906\n",
      "Epoch: 8700 | Loss: 0.0016674149490675631\n",
      "Epoch: 8800 | Loss: 0.0006929176260617754\n",
      "Epoch: 8900 | Loss: 0.0009921951351401944\n",
      "Epoch: 9000 | Loss: 7.0794298117869065e-06\n",
      "Epoch: 9100 | Loss: 5.684277939012278e-07\n",
      "Epoch: 9200 | Loss: 2.831422413973153e-07\n",
      "Epoch: 9300 | Loss: 1.965096417648615e-07\n",
      "Epoch: 9400 | Loss: 1.5361891717305197e-07\n",
      "Epoch: 9500 | Loss: 1.2716508442883357e-07\n",
      "Epoch: 9600 | Loss: 1.0866489065913012e-07\n",
      "Epoch: 9700 | Loss: 9.470191191456772e-08\n",
      "Epoch: 9800 | Loss: 8.364501408268972e-08\n",
      "Epoch: 9900 | Loss: 7.46130982311933e-08\n",
      "Epoch: 10000 | Loss: 6.70798043158429e-08\n",
      "Epoch: 10100 | Loss: 6.070130799746314e-08\n",
      "Epoch: 10200 | Loss: 5.523510891044736e-08\n",
      "Epoch: 10300 | Loss: 1.8257143410317914e-05\n",
      "Epoch: 10400 | Loss: 0.00014315699798139966\n",
      "Epoch: 10500 | Loss: 5.6714578760204766e-05\n",
      "Epoch: 10600 | Loss: 0.0003734917934123466\n",
      "Epoch: 10700 | Loss: 0.000165731594568029\n",
      "Epoch: 10800 | Loss: 0.00034842957331582855\n",
      "Epoch: 10900 | Loss: 8.279928253113381e-05\n",
      "Epoch: 11000 | Loss: 1.528545026433679e-05\n",
      "Epoch: 11100 | Loss: 3.096157314639017e-05\n",
      "Epoch: 11200 | Loss: 0.00014787015011781692\n",
      "Epoch: 11300 | Loss: 0.00012230854812109794\n",
      "Epoch: 11400 | Loss: 0.0001724098174999035\n",
      "Epoch: 11500 | Loss: 1.741825201627913e-06\n",
      "Epoch: 11600 | Loss: 6.483049770305329e-05\n",
      "Epoch: 11700 | Loss: 0.00011664144406725436\n",
      "Epoch: 11800 | Loss: 0.00018963769831002904\n",
      "Epoch: 11900 | Loss: 0.00021749666426694236\n",
      "Epoch: 12000 | Loss: 1.3711238876622328e-06\n",
      "Epoch: 12100 | Loss: 1.3292562001811137e-07\n",
      "Epoch: 12200 | Loss: 7.12777166856204e-08\n",
      "Epoch: 12300 | Loss: 4.668105687270405e-08\n",
      "Epoch: 12400 | Loss: 3.407596457669461e-08\n",
      "Epoch: 12500 | Loss: 2.6731458002821506e-08\n",
      "Epoch: 12600 | Loss: 2.2052708770258144e-08\n",
      "Epoch: 12700 | Loss: 1.886325573136336e-08\n",
      "Epoch: 12800 | Loss: 1.6567807421127064e-08\n",
      "Epoch: 12900 | Loss: 1.4840003048215895e-08\n",
      "Epoch: 13000 | Loss: 1.3489587005742977e-08\n",
      "Epoch: 13100 | Loss: 1.2400116570162486e-08\n",
      "Epoch: 13200 | Loss: 1.1497446528014947e-08\n",
      "Epoch: 13300 | Loss: 1.0732782946830476e-08\n",
      "Epoch: 13400 | Loss: 1.0073466700644723e-08\n",
      "Epoch: 13500 | Loss: 5.718303855386534e-06\n",
      "Epoch: 13600 | Loss: 3.193538316115391e-05\n",
      "Epoch: 13700 | Loss: 1.4290501024241515e-05\n",
      "Epoch: 13800 | Loss: 1.0272757302267624e-05\n",
      "Epoch: 13900 | Loss: 9.95262987005499e-06\n",
      "Epoch: 14000 | Loss: 5.873347179222502e-05\n",
      "Epoch: 14100 | Loss: 3.86878428019893e-05\n",
      "Epoch: 14200 | Loss: 5.4918847284184455e-05\n",
      "Epoch: 14300 | Loss: 3.749483910968727e-05\n",
      "Epoch: 14400 | Loss: 7.270064345795759e-06\n",
      "Epoch: 14500 | Loss: 2.311744927941139e-05\n",
      "Epoch: 14600 | Loss: 6.894837178599845e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14700 | Loss: 8.493472414519831e-06\n",
      "Epoch: 14800 | Loss: 0.00011022087369564663\n",
      "Epoch: 14900 | Loss: 3.904179084055093e-05\n",
      "time=292.8885622024536\n",
      "error=4.0199466251882385e-05\n",
      "best loss=1.0056974736559076e-08\n",
      "best epoch=13404\n",
      "40\n",
      "Epoch: 0 | Loss: 0.00015418615644272512\n",
      "Epoch: 100 | Loss: 0.013630703001941188\n",
      "Epoch: 200 | Loss: 0.005432942334788362\n",
      "Epoch: 300 | Loss: 0.0025983798302630988\n",
      "Epoch: 400 | Loss: 0.001370594489138048\n",
      "Epoch: 500 | Loss: 0.0007855507630730257\n",
      "Epoch: 600 | Loss: 0.0013763086029125345\n",
      "Epoch: 700 | Loss: 0.0010824703626463698\n",
      "Epoch: 800 | Loss: 0.0012980814215905474\n",
      "Epoch: 900 | Loss: 0.002975146727395476\n",
      "Epoch: 1000 | Loss: 0.0008353838857682659\n",
      "Epoch: 1100 | Loss: 0.0058042762668700345\n",
      "Epoch: 1200 | Loss: 0.0062149598374470075\n",
      "Epoch: 1300 | Loss: 0.006252344535371797\n",
      "Epoch: 1400 | Loss: 0.008692883894590529\n",
      "Epoch: 1500 | Loss: 0.0019203847438224331\n",
      "Epoch: 1600 | Loss: 0.01449853919301622\n",
      "Epoch: 1700 | Loss: 0.026126537214033248\n",
      "Epoch: 1800 | Loss: 0.008618012330052749\n",
      "Epoch: 1900 | Loss: 0.016548169490727488\n",
      "Epoch: 2000 | Loss: 9829719.952992355\n",
      "Epoch: 2100 | Loss: 1075301.7485808753\n",
      "Epoch: 2200 | Loss: 389005.7875666303\n",
      "Epoch: 2300 | Loss: 334332.9725871444\n",
      "Epoch: 2400 | Loss: 299070.99193109747\n",
      "Epoch: 2500 | Loss: 272310.8932483292\n",
      "Epoch: 2600 | Loss: 250688.35995868075\n",
      "Epoch: 2700 | Loss: 232600.22153914152\n",
      "Epoch: 2800 | Loss: 217120.6435086577\n",
      "Epoch: 2900 | Loss: 203653.89702937615\n",
      "Epoch: 3000 | Loss: 191845.2068042441\n",
      "Epoch: 3100 | Loss: 186363.06282457456\n",
      "Epoch: 3200 | Loss: 181052.84600359932\n",
      "Epoch: 3300 | Loss: 175908.28111003907\n",
      "Epoch: 3400 | Loss: 170925.04455495745\n",
      "Epoch: 3500 | Loss: 166098.80823871156\n",
      "Epoch: 3600 | Loss: 161425.25310919923\n",
      "Epoch: 3700 | Loss: 156900.0811398364\n",
      "Epoch: 3800 | Loss: 152519.0263818734\n",
      "Epoch: 3900 | Loss: 148277.86650626973\n",
      "Epoch: 4000 | Loss: 144172.4254599309\n",
      "Epoch: 4100 | Loss: 140198.58519989267\n",
      "Epoch: 4200 | Loss: 136352.2906903642\n",
      "Epoch: 4300 | Loss: 132629.5552070128\n",
      "Epoch: 4400 | Loss: 129026.46552437896\n",
      "Epoch: 4500 | Loss: 125539.18611815153\n",
      "Epoch: 4600 | Loss: 122163.96124770606\n",
      "Epoch: 4700 | Loss: 118897.11949076933\n",
      "Epoch: 4800 | Loss: 115735.07472357708\n",
      "Epoch: 4900 | Loss: 112674.3371971185\n",
      "Epoch: 5000 | Loss: 109711.49897043474\n",
      "Epoch: 5100 | Loss: 106843.24689341684\n",
      "Epoch: 5200 | Loss: 104066.36024268868\n",
      "Epoch: 5300 | Loss: 101377.71050221613\n",
      "Epoch: 5400 | Loss: 98774.26669409472\n",
      "Epoch: 5500 | Loss: 96253.08933305589\n",
      "Epoch: 5600 | Loss: 93811.32159266547\n",
      "Epoch: 5700 | Loss: 91446.19578432504\n",
      "Epoch: 5800 | Loss: 89155.02386400866\n",
      "Epoch: 5900 | Loss: 86935.19113329345\n",
      "Epoch: 6000 | Loss: 84794.74039697145\n",
      "Epoch: 6100 | Loss: 83732.58156507171\n",
      "Epoch: 6200 | Loss: 82661.47866403025\n",
      "Epoch: 6300 | Loss: 81582.23461730659\n",
      "Epoch: 6400 | Loss: 80495.84453186775\n",
      "Epoch: 6500 | Loss: 79403.31391683497\n",
      "Epoch: 6600 | Loss: 78305.65411308501\n",
      "Epoch: 6700 | Loss: 77203.87755853162\n",
      "Epoch: 6800 | Loss: 76098.99302746082\n",
      "Epoch: 6900 | Loss: 74992.00099357314\n",
      "Epoch: 7000 | Loss: 73883.8892008113\n",
      "Epoch: 7100 | Loss: 72775.62845710604\n",
      "Epoch: 7200 | Loss: 71668.16864685495\n",
      "Epoch: 7300 | Loss: 70562.43497262635\n",
      "Epoch: 7400 | Loss: 69459.32444852935\n",
      "Epoch: 7500 | Loss: 68359.70267892728\n",
      "Epoch: 7600 | Loss: 67264.40108049435\n",
      "Epoch: 7700 | Loss: 66174.21509538853\n",
      "Epoch: 7800 | Loss: 65089.9012359779\n",
      "Epoch: 7900 | Loss: 64012.1731692293\n",
      "Epoch: 8000 | Loss: 62941.70237944604\n",
      "Epoch: 8100 | Loss: 61879.11675740769\n",
      "Epoch: 8200 | Loss: 60824.99938557615\n",
      "Epoch: 8300 | Loss: 59779.887926601215\n",
      "Epoch: 8400 | Loss: 58744.27438683695\n",
      "Epoch: 8500 | Loss: 57718.60523359088\n",
      "Epoch: 8600 | Loss: 56703.28185512091\n",
      "Epoch: 8700 | Loss: 55698.661337503276\n",
      "Epoch: 8800 | Loss: 54705.05751461913\n",
      "Epoch: 8900 | Loss: 53722.74223505161\n",
      "Epoch: 9000 | Loss: 52756.77154735013\n",
      "Epoch: 9100 | Loss: 52270.25092209292\n",
      "Epoch: 9200 | Loss: 51774.87723950291\n",
      "Epoch: 9300 | Loss: 51270.8606067354\n",
      "Epoch: 9400 | Loss: 50758.49239017761\n",
      "Epoch: 9500 | Loss: 50238.08251946569\n",
      "Epoch: 9600 | Loss: 49709.95818831183\n",
      "Epoch: 9700 | Loss: 49174.462430469066\n",
      "Epoch: 9800 | Loss: 48631.95258297287\n",
      "Epoch: 9900 | Loss: 48082.79865244796\n",
      "Epoch: 10000 | Loss: 47527.381601711866\n",
      "Epoch: 10100 | Loss: 46966.09157518619\n",
      "Epoch: 10200 | Loss: 46399.32608258912\n",
      "Epoch: 10300 | Loss: 45827.48816089587\n",
      "Epoch: 10400 | Loss: 45250.984534834366\n",
      "Epoch: 10500 | Loss: 44670.22379602654\n",
      "Epoch: 10600 | Loss: 44085.614620541644\n",
      "Epoch: 10700 | Loss: 43497.56404380695\n",
      "Epoch: 10800 | Loss: 42906.47581091538\n",
      "Epoch: 10900 | Loss: 42312.74881909088\n",
      "Epoch: 11000 | Loss: 41716.77566774463\n",
      "Epoch: 11100 | Loss: 41118.941329913214\n",
      "Epoch: 11200 | Loss: 40519.621957334886\n",
      "Epoch: 11300 | Loss: 39919.18382947299\n",
      "Epoch: 11400 | Loss: 39317.98245517415\n",
      "Epoch: 11500 | Loss: 38716.36183354709\n",
      "Epoch: 11600 | Loss: 38114.6538787867\n",
      "Epoch: 11700 | Loss: 37517.494352857415\n",
      "Epoch: 11800 | Loss: 36912.223750596386\n",
      "Epoch: 11900 | Loss: 36312.120405256974\n",
      "Epoch: 12000 | Loss: 35716.122343465686\n",
      "Epoch: 12100 | Loss: 35413.65169562067\n",
      "Epoch: 12200 | Loss: 35104.13222332706\n",
      "Epoch: 12300 | Loss: 34787.61126202707\n",
      "Epoch: 12400 | Loss: 34464.18244983801\n",
      "Epoch: 12500 | Loss: 34133.95355411842\n",
      "Epoch: 12600 | Loss: 33797.04630117921\n",
      "Epoch: 12700 | Loss: 33453.596138389126\n",
      "Epoch: 12800 | Loss: 33103.751931202314\n",
      "Epoch: 12900 | Loss: 32747.675599035843\n",
      "Epoch: 13000 | Loss: 32385.541693592153\n",
      "Epoch: 13100 | Loss: 32017.53691859022\n",
      "Epoch: 13200 | Loss: 31643.859555266652\n",
      "Epoch: 13300 | Loss: 31264.718894123835\n",
      "Epoch: 13400 | Loss: 30880.335752588995\n",
      "Epoch: 13500 | Loss: 30490.939552965174\n",
      "Epoch: 13600 | Loss: 30096.769676754833\n",
      "Epoch: 13700 | Loss: 29698.07447547012\n",
      "Epoch: 13800 | Loss: 29295.109538616194\n",
      "Epoch: 13900 | Loss: 28888.13820489032\n",
      "Epoch: 14000 | Loss: 28477.43054457634\n",
      "Epoch: 14100 | Loss: 28063.262709266797\n",
      "Epoch: 14200 | Loss: 27645.916287119806\n",
      "Epoch: 14300 | Loss: 27225.677663734983\n",
      "Epoch: 14400 | Loss: 26802.83738936101\n",
      "Epoch: 14500 | Loss: 26377.689552899028\n",
      "Epoch: 14600 | Loss: 25950.531163080093\n",
      "Epoch: 14700 | Loss: 25521.661541350775\n",
      "Epoch: 14800 | Loss: 25091.38170715755\n",
      "Epoch: 14900 | Loss: 24659.99379456712\n",
      "time=316.62993693351746\n",
      "error=24232.125393846534\n",
      "best loss=0.00015418615644272512\n",
      "best epoch=0\n",
      "44\n",
      "Epoch: 0 | Loss: 4.469939731583909\n",
      "Epoch: 100 | Loss: 0.5432481370360867\n",
      "Epoch: 200 | Loss: 42261364.69874363\n",
      "Epoch: 300 | Loss: 1266185.174409811\n",
      "Epoch: 400 | Loss: 627462.2701499296\n",
      "Epoch: 500 | Loss: 491927.88806601765\n",
      "Epoch: 600 | Loss: 410511.34685533517\n",
      "Epoch: 700 | Loss: 354237.0573708632\n",
      "Epoch: 800 | Loss: 312277.34811255836\n",
      "Epoch: 900 | Loss: 279435.9804930737\n",
      "Epoch: 1000 | Loss: 252849.14149427932\n",
      "Epoch: 1100 | Loss: 230784.01701057196\n",
      "Epoch: 1200 | Loss: 212119.61435197995\n",
      "Epoch: 1300 | Loss: 196093.48824488051\n",
      "Epoch: 1400 | Loss: 182161.77126124766\n",
      "Epoch: 1500 | Loss: 169933.05663178093\n",
      "Epoch: 1600 | Loss: 159101.35155102218\n",
      "Epoch: 1700 | Loss: 149439.95761511003\n",
      "Epoch: 1800 | Loss: 140760.6671597514\n",
      "Epoch: 1900 | Loss: 132921.6528495777\n",
      "Epoch: 2000 | Loss: 125806.0110109461\n",
      "Epoch: 2100 | Loss: 119306.45872747512\n",
      "Epoch: 2200 | Loss: 113348.34447000844\n",
      "Epoch: 2300 | Loss: 107861.37729270098\n",
      "Epoch: 2400 | Loss: 102784.38273895401\n",
      "Epoch: 2500 | Loss: 98071.05416324282\n",
      "Epoch: 2600 | Loss: 93702.58901784166\n",
      "Epoch: 2700 | Loss: 89709.81611015761\n",
      "Epoch: 2800 | Loss: 86049.99881110313\n",
      "Epoch: 2900 | Loss: 82662.5163115946\n",
      "Epoch: 3000 | Loss: 79509.35118314429\n",
      "Epoch: 3100 | Loss: 77983.67649121617\n",
      "Epoch: 3200 | Loss: 76468.85715630958\n",
      "Epoch: 3300 | Loss: 74966.49544944294\n",
      "Epoch: 3400 | Loss: 73477.76173661111\n",
      "Epoch: 3500 | Loss: 72004.36398621484\n",
      "Epoch: 3600 | Loss: 70547.5165239505\n",
      "Epoch: 3700 | Loss: 69108.34002339152\n",
      "Epoch: 3800 | Loss: 67687.85986281751\n",
      "Epoch: 3900 | Loss: 66287.00903793241\n",
      "Epoch: 4000 | Loss: 64906.60170281911\n",
      "Epoch: 4100 | Loss: 63547.40341596576\n",
      "Epoch: 4200 | Loss: 62209.96835510529\n",
      "Epoch: 4300 | Loss: 60894.838053526146\n",
      "Epoch: 4400 | Loss: 59602.817986787166\n",
      "Epoch: 4500 | Loss: 58333.35202030893\n",
      "Epoch: 4600 | Loss: 57087.19926643254\n",
      "Epoch: 4700 | Loss: 55864.50363087311\n",
      "Epoch: 4800 | Loss: 54665.29093215497\n",
      "Epoch: 4900 | Loss: 53489.571051578256\n",
      "Epoch: 5000 | Loss: 52337.34420152413\n",
      "Epoch: 5100 | Loss: 51208.48521543418\n",
      "Epoch: 5200 | Loss: 50102.84248176143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5300 | Loss: 49020.22810575387\n",
      "Epoch: 5400 | Loss: 47960.28971737555\n",
      "Epoch: 5500 | Loss: 46922.784196920824\n",
      "Epoch: 5600 | Loss: 45907.32932595434\n",
      "Epoch: 5700 | Loss: 44913.521989066474\n",
      "Epoch: 5800 | Loss: 43940.970309121054\n",
      "Epoch: 5900 | Loss: 42989.141507383174\n",
      "Epoch: 6000 | Loss: 42062.2613653114\n",
      "Epoch: 6100 | Loss: 41598.7591217855\n",
      "Epoch: 6200 | Loss: 41129.05793075824\n",
      "Epoch: 6300 | Loss: 40653.39571548092\n",
      "Epoch: 6400 | Loss: 40172.11285336464\n",
      "Epoch: 6500 | Loss: 39685.60208189128\n",
      "Epoch: 6600 | Loss: 39194.17352658145\n",
      "Epoch: 6700 | Loss: 38698.25932841947\n",
      "Epoch: 6800 | Loss: 38198.21096509464\n",
      "Epoch: 6900 | Loss: 37694.44506138646\n",
      "Epoch: 7000 | Loss: 37187.36842267393\n",
      "Epoch: 7100 | Loss: 36677.3847664217\n",
      "Epoch: 7200 | Loss: 36164.90372559409\n",
      "Epoch: 7300 | Loss: 35650.32724839843\n",
      "Epoch: 7400 | Loss: 35134.075022593985\n",
      "Epoch: 7500 | Loss: 34616.56800247476\n",
      "Epoch: 7600 | Loss: 34098.404367960335\n",
      "Epoch: 7700 | Loss: 33579.524539178215\n",
      "Epoch: 7800 | Loss: 33060.688923080445\n",
      "Epoch: 7900 | Loss: 32542.24582510484\n",
      "Epoch: 8000 | Loss: 32024.58235454487\n",
      "Epoch: 8100 | Loss: 31508.092521642997\n",
      "Epoch: 8200 | Loss: 30993.164941641182\n",
      "Epoch: 8300 | Loss: 30480.17352185386\n",
      "Epoch: 8400 | Loss: 29969.513017869125\n",
      "Epoch: 8500 | Loss: 29461.517152311353\n",
      "Epoch: 8600 | Loss: 28956.54653455104\n",
      "Epoch: 8700 | Loss: 28454.998810334444\n",
      "Epoch: 8800 | Loss: 27957.09529870486\n",
      "Epoch: 8900 | Loss: 27463.212185096803\n",
      "Epoch: 9000 | Loss: 26976.12708989232\n",
      "Epoch: 9100 | Loss: 26730.27703305489\n",
      "Epoch: 9200 | Loss: 26479.64868692602\n",
      "Epoch: 9300 | Loss: 26224.34992288605\n",
      "Epoch: 9400 | Loss: 25964.537381682774\n",
      "Epoch: 9500 | Loss: 25700.382864487266\n",
      "Epoch: 9600 | Loss: 25432.07201989279\n",
      "Epoch: 9700 | Loss: 25159.845251961717\n",
      "Epoch: 9800 | Loss: 24883.790041160275\n",
      "Epoch: 9900 | Loss: 24604.255051321386\n",
      "Epoch: 10000 | Loss: 24321.430094820083\n",
      "Epoch: 10100 | Loss: 24035.565125934525\n",
      "Epoch: 10200 | Loss: 23746.905756918008\n",
      "Epoch: 10300 | Loss: 23455.726536279602\n",
      "Epoch: 10400 | Loss: 23162.286056949026\n",
      "Epoch: 10500 | Loss: 22866.872162365435\n",
      "Epoch: 10600 | Loss: 22569.802514691797\n",
      "Epoch: 10700 | Loss: 22271.236679596062\n",
      "Epoch: 10800 | Loss: 21971.597585989653\n",
      "Epoch: 10900 | Loss: 21671.11440386658\n",
      "Epoch: 11000 | Loss: 21370.127706370367\n",
      "Epoch: 11100 | Loss: 21068.820051834347\n",
      "Epoch: 11200 | Loss: 20767.581793360405\n",
      "Epoch: 11300 | Loss: 20466.65639439989\n",
      "Epoch: 11400 | Loss: 20166.360290488235\n",
      "Epoch: 11500 | Loss: 19866.932135451872\n",
      "Epoch: 11600 | Loss: 19568.651899075878\n",
      "Epoch: 11700 | Loss: 19271.75800270054\n",
      "Epoch: 11800 | Loss: 18976.518817174652\n",
      "Epoch: 11900 | Loss: 18683.179020382773\n",
      "Epoch: 12000 | Loss: 18393.383707389326\n",
      "Epoch: 12100 | Loss: 18246.956081862052\n",
      "Epoch: 12200 | Loss: 18097.56854430473\n",
      "Epoch: 12300 | Loss: 17945.284685565624\n",
      "Epoch: 12400 | Loss: 17790.194856523434\n",
      "Epoch: 12500 | Loss: 17632.397861646423\n",
      "Epoch: 12600 | Loss: 17472.000443109435\n",
      "Epoch: 12700 | Loss: 17309.116642047877\n",
      "Epoch: 12800 | Loss: 17143.86384744645\n",
      "Epoch: 12900 | Loss: 16976.382880166224\n",
      "Epoch: 13000 | Loss: 16806.801810319026\n",
      "Epoch: 13100 | Loss: 16635.260995428034\n",
      "Epoch: 13200 | Loss: 16461.90427118093\n",
      "Epoch: 13300 | Loss: 16286.878584386282\n",
      "Epoch: 13400 | Loss: 16110.329603261373\n",
      "Epoch: 13500 | Loss: 15932.413575104467\n",
      "Epoch: 13600 | Loss: 15753.285123079844\n",
      "Epoch: 13700 | Loss: 15573.118316113381\n",
      "Epoch: 13800 | Loss: 15392.015856594131\n",
      "Epoch: 13900 | Loss: 15210.16533497782\n",
      "Epoch: 14000 | Loss: 15027.709495028757\n",
      "Epoch: 14100 | Loss: 14844.80092980856\n",
      "Epoch: 14200 | Loss: 14661.583485763644\n",
      "Epoch: 14300 | Loss: 14478.195108708194\n",
      "Epoch: 14400 | Loss: 14294.776773828351\n",
      "Epoch: 14500 | Loss: 14111.4607975064\n",
      "Epoch: 14600 | Loss: 13928.36684372021\n",
      "Epoch: 14700 | Loss: 13745.629248580542\n",
      "Epoch: 14800 | Loss: 13563.369422744945\n",
      "Epoch: 14900 | Loss: 13381.672445784174\n",
      "time=326.73282384872437\n",
      "error=13202.485252822704\n",
      "best loss=0.07440654828697436\n",
      "best epoch=80\n",
      "48\n",
      "Epoch: 0 | Loss: 0.07822081033492663\n",
      "Epoch: 100 | Loss: 4084985925.734469\n",
      "Epoch: 200 | Loss: 1328840.8828433957\n",
      "Epoch: 300 | Loss: 1386658.8557557\n",
      "Epoch: 400 | Loss: 1163416.0971564995\n",
      "Epoch: 500 | Loss: 1075024.8287217307\n",
      "Epoch: 600 | Loss: 1025416.1081820623\n",
      "Epoch: 700 | Loss: 992806.2633562428\n",
      "Epoch: 800 | Loss: 969139.6873530903\n",
      "Epoch: 900 | Loss: 950760.6442717013\n",
      "Epoch: 1000 | Loss: 935524.0843285519\n",
      "Epoch: 1100 | Loss: 922446.1393284918\n",
      "Epoch: 1200 | Loss: 910817.0036986452\n",
      "Epoch: 1300 | Loss: 900158.33904157\n",
      "Epoch: 1400 | Loss: 890162.0741718403\n",
      "Epoch: 1500 | Loss: 880699.541652679\n",
      "Epoch: 1600 | Loss: 871578.4778150729\n",
      "Epoch: 1700 | Loss: 862688.9237683194\n",
      "Epoch: 1800 | Loss: 853918.7379613009\n",
      "Epoch: 1900 | Loss: 845217.4856668067\n",
      "Epoch: 2000 | Loss: 836535.3116642998\n",
      "Epoch: 2100 | Loss: 827837.3398925583\n",
      "Epoch: 2200 | Loss: 819083.6828169476\n",
      "Epoch: 2300 | Loss: 810232.5723488404\n",
      "Epoch: 2400 | Loss: 801257.4972024112\n",
      "Epoch: 2500 | Loss: 792138.0342152676\n",
      "Epoch: 2600 | Loss: 782856.7609458813\n",
      "Epoch: 2700 | Loss: 773398.9401191019\n",
      "Epoch: 2800 | Loss: 763752.0496522991\n",
      "Epoch: 2900 | Loss: 753905.4029470917\n",
      "Epoch: 3000 | Loss: 743901.0665785631\n",
      "Epoch: 3100 | Loss: 738728.191219265\n",
      "Epoch: 3200 | Loss: 733363.7899012686\n",
      "Epoch: 3300 | Loss: 727803.5085240273\n",
      "Epoch: 3400 | Loss: 722043.3542197942\n",
      "Epoch: 3500 | Loss: 716079.8175917054\n",
      "Epoch: 3600 | Loss: 709908.1083381466\n",
      "Epoch: 3700 | Loss: 703525.052116634\n",
      "Epoch: 3800 | Loss: 696927.0255733761\n",
      "Epoch: 3900 | Loss: 690110.6893447125\n",
      "Epoch: 4000 | Loss: 683072.8714543346\n",
      "Epoch: 4100 | Loss: 675810.767775875\n",
      "Epoch: 4200 | Loss: 668321.8250838171\n",
      "Epoch: 4300 | Loss: 660603.8902292645\n",
      "Epoch: 4400 | Loss: 652655.2136054259\n",
      "Epoch: 4500 | Loss: 644474.5374354444\n",
      "Epoch: 4600 | Loss: 636061.0995496486\n",
      "Epoch: 4700 | Loss: 627414.7048395592\n",
      "Epoch: 4800 | Loss: 618536.6044594238\n",
      "Epoch: 4900 | Loss: 609426.0220592662\n",
      "Epoch: 5000 | Loss: 600085.8624324747\n",
      "Epoch: 5100 | Loss: 590518.6678791323\n",
      "Epoch: 5200 | Loss: 580727.6440060607\n",
      "Epoch: 5300 | Loss: 570717.0769075527\n",
      "Epoch: 5400 | Loss: 560491.9426670396\n",
      "Epoch: 5500 | Loss: 550058.2035237193\n",
      "Epoch: 5600 | Loss: 539423.0333829385\n",
      "Epoch: 5700 | Loss: 528593.4145630703\n",
      "Epoch: 5800 | Loss: 517578.7796077487\n",
      "Epoch: 5900 | Loss: 506388.64230220387\n",
      "Epoch: 6000 | Loss: 495090.9401017796\n",
      "Epoch: 6100 | Loss: 489286.7062572364\n",
      "Epoch: 6200 | Loss: 483300.4663507735\n",
      "Epoch: 6300 | Loss: 477130.3040514533\n",
      "Epoch: 6400 | Loss: 470776.58861662203\n",
      "Epoch: 6500 | Loss: 464239.5105926605\n",
      "Epoch: 6600 | Loss: 457519.7438296108\n",
      "Epoch: 6700 | Loss: 450619.0427395684\n",
      "Epoch: 6800 | Loss: 443538.48755268456\n",
      "Epoch: 6900 | Loss: 436281.1295072435\n",
      "Epoch: 7000 | Loss: 428850.16609156365\n",
      "Epoch: 7100 | Loss: 421249.448192698\n",
      "Epoch: 7200 | Loss: 413483.5141217236\n",
      "Epoch: 7300 | Loss: 405558.28402276215\n",
      "Epoch: 7400 | Loss: 397478.35928051354\n",
      "Epoch: 7500 | Loss: 389251.15721421706\n",
      "Epoch: 7600 | Loss: 380884.1568137632\n",
      "Epoch: 7700 | Loss: 372385.676862324\n",
      "Epoch: 7800 | Loss: 363764.608546059\n",
      "Epoch: 7900 | Loss: 355030.58950791013\n",
      "Epoch: 8000 | Loss: 346193.9494788197\n",
      "Epoch: 8100 | Loss: 337265.6944213874\n",
      "Epoch: 8200 | Loss: 328257.47255659505\n",
      "Epoch: 8300 | Loss: 319182.33191995235\n",
      "Epoch: 8400 | Loss: 310051.32874029543\n",
      "Epoch: 8500 | Loss: 300878.81082049327\n",
      "Epoch: 8600 | Loss: 291678.42020403576\n",
      "Epoch: 8700 | Loss: 282464.17920343595\n",
      "Epoch: 8800 | Loss: 273250.31925708154\n",
      "Epoch: 8900 | Loss: 264051.8756941873\n",
      "Epoch: 9000 | Loss: 254930.05031420593\n",
      "Epoch: 9100 | Loss: 250309.36245766934\n",
      "Epoch: 9200 | Loss: 245588.84653112423\n",
      "Epoch: 9300 | Loss: 240771.34437109646\n",
      "Epoch: 9400 | Loss: 235860.67204868645\n",
      "Epoch: 9500 | Loss: 230861.11171373565\n",
      "Epoch: 9600 | Loss: 225777.84374612288\n",
      "Epoch: 9700 | Loss: 220615.1405748857\n",
      "Epoch: 9800 | Loss: 215379.22861596436\n",
      "Epoch: 9900 | Loss: 210076.22872446533\n",
      "Epoch: 10000 | Loss: 204712.6957044454\n",
      "Epoch: 10100 | Loss: 199295.62568761085\n",
      "Epoch: 10200 | Loss: 193832.3944653165\n",
      "Epoch: 10300 | Loss: 188330.7468741604\n",
      "Epoch: 10400 | Loss: 182798.7605589735\n",
      "Epoch: 10500 | Loss: 177244.8139157683\n",
      "Epoch: 10600 | Loss: 171677.55113761692\n",
      "Epoch: 10700 | Loss: 166106.6356495158\n",
      "Epoch: 10800 | Loss: 160539.56153327425\n",
      "Epoch: 10900 | Loss: 154985.99823085748\n",
      "Epoch: 11000 | Loss: 149455.44903883897\n",
      "Epoch: 11100 | Loss: 143957.2502695349\n",
      "Epoch: 11200 | Loss: 138500.52375275208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11300 | Loss: 133094.37440300256\n",
      "Epoch: 11400 | Loss: 127747.75929505484\n",
      "Epoch: 11500 | Loss: 122469.42779661475\n",
      "Epoch: 11600 | Loss: 117267.87179486819\n",
      "Epoch: 11700 | Loss: 112151.28232939407\n",
      "Epoch: 11800 | Loss: 107127.81363310163\n",
      "Epoch: 11900 | Loss: 102204.9466190925\n",
      "Epoch: 12000 | Loss: 97413.46159418543\n",
      "Epoch: 12100 | Loss: 95021.03552917551\n",
      "Epoch: 12200 | Loss: 92600.7250600117\n",
      "Epoch: 12300 | Loss: 90155.38599979077\n",
      "Epoch: 12400 | Loss: 87688.34546764706\n",
      "Epoch: 12500 | Loss: 85204.20113863233\n",
      "Epoch: 12600 | Loss: 82704.34804124982\n",
      "Epoch: 12700 | Loss: 80194.04875418881\n",
      "Epoch: 12800 | Loss: 77677.34632972363\n",
      "Epoch: 12900 | Loss: 75158.30434845279\n",
      "Epoch: 13000 | Loss: 72641.10003266635\n",
      "Epoch: 13100 | Loss: 70130.00687024325\n",
      "Epoch: 13200 | Loss: 67631.25265931907\n",
      "Epoch: 13300 | Loss: 65144.871665253784\n",
      "Epoch: 13400 | Loss: 62677.71635148004\n",
      "Epoch: 13500 | Loss: 60234.48894784089\n",
      "Epoch: 13600 | Loss: 57818.58733370363\n",
      "Epoch: 13700 | Loss: 55434.50256947075\n",
      "Epoch: 13800 | Loss: 53086.302086764\n",
      "Epoch: 13900 | Loss: 50777.77538136227\n",
      "Epoch: 14000 | Loss: 48512.585068289154\n",
      "Epoch: 14100 | Loss: 46294.22120354805\n",
      "Epoch: 14200 | Loss: 44125.95091958483\n",
      "Epoch: 14300 | Loss: 42010.804875844995\n",
      "Epoch: 14400 | Loss: 39951.787851137\n",
      "Epoch: 14500 | Loss: 37950.99783867968\n",
      "Epoch: 14600 | Loss: 36010.74295906277\n",
      "Epoch: 14700 | Loss: 34133.26707659468\n",
      "Epoch: 14800 | Loss: 32320.305807011926\n",
      "Epoch: 14900 | Loss: 30572.2248052812\n",
      "time=360.22224831581116\n",
      "error=28907.35632992979\n",
      "best loss=0.07822081033492663\n",
      "best epoch=0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy import interpolate\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "interp_mode = \"bilinear\"\n",
    "align_corners = True\n",
    "\n",
    "\n",
    "#n_grids = [12,16,20,24,28,32,36,40]\n",
    "#n_grids = [12,16]\n",
    "#n_grids = [6,10,14,20,30,40,50]\n",
    "#n_grids = [6,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,200,300,400,500,600,700,800,900,1000]\n",
    "#n_grids = [10,20,30,40,50,60,70,80,90,100]\n",
    "n_grids = [6,8,12,16,20,24,28,32,36,40,44,48]\n",
    "#n_grids = [20]\n",
    "#n_grids = [200]\n",
    "theta_start = 0\n",
    "theta_end = np.pi/2\n",
    "r_start = 3\n",
    "r_end = 4\n",
    "\n",
    "a = 0.0\n",
    "M = 1\n",
    "\n",
    "errors = []\n",
    "times = []\n",
    "ii = 0\n",
    "\n",
    "\n",
    "for n_grid in n_grids:\n",
    "    print(n_grid)\n",
    "\n",
    "    thetas = torch.linspace(theta_start,theta_end,steps=n_grid, dtype=torch.double)\n",
    "    rs = torch.linspace(r_start,r_end,steps=n_grid, dtype=torch.double)\n",
    "    theta_h = (theta_end - theta_start)/(n_grid-1)\n",
    "    r_h  = (r_end - r_start)/(n_grid-1)\n",
    "\n",
    "    RS, THETAS = torch.meshgrid(rs, thetas)\n",
    "    # Transpose here is very important! Becareful of meshgrid and reshape stuff!\n",
    "    #RS = torch.transpose(RS,0,1)\n",
    "    #THETAS = torch.transpose(THETAS,0,1)\n",
    "    z = torch.transpose(torch.stack([RS.reshape(-1,), THETAS.reshape(-1,)]),0,1)\n",
    "    \n",
    "    #print(z)\n",
    "\n",
    "    # t' = t + f1(r,theta)\n",
    "    def f1(f1_free, n_grid):\n",
    "        # f1_free has shape (n_grid, n_grid-1).\n",
    "        # Along theta, zero derivative at theta=pi/2\n",
    "        f1_ = torch.zeros(n_grid,n_grid, dtype=torch.double)\n",
    "        f1_[:,:-1] = f1_free\n",
    "        f1_[:,-1] = f1_free[:,-1]\n",
    "        return f1_\n",
    "\n",
    "    # r' = r + f2(r,theta)\n",
    "    def f2(f2_free, n_grid):\n",
    "        # f2_free has shape (n_grid, n_grid-1).\n",
    "        # Along theta, zero derivative at theta=pi/2\n",
    "        f2_ = torch.zeros(n_grid,n_grid, dtype=torch.double)\n",
    "        f2_[:,:-1] = f2_free\n",
    "        f2_[:,-1] = f2_free[:,-1]\n",
    "        return f2_\n",
    "\n",
    "    # theta' = theta + f3(r,theta)\n",
    "    def f3(f3_free, n_grid):\n",
    "        # f3_free has shape (n_grid, n_grid-2)\n",
    "        # Along theta, zero at theta=0 and theta=pi/2\n",
    "        f3_ = torch.zeros(n_grid,n_grid, dtype=torch.double)\n",
    "        f3_[:,1:-1] = f3_free\n",
    "        return f3_\n",
    "\n",
    "    # phi' = phi + f4(r,theta)\n",
    "    def f4(f4_free, n_grid):\n",
    "        # f4_free has shape (n_grid, n_grid-1).\n",
    "        # Along theta, zero derivative at theta=pi/2\n",
    "        f4_ = torch.zeros(n_grid,n_grid, dtype=torch.double)\n",
    "        f4_[:,:-1] = f4_free\n",
    "        f4_[:,-1] = f4_free[:,-1]\n",
    "        return f4_\n",
    "    \n",
    "    \n",
    "    def interp_free(f_free, n_grid, mode=\"0\"):\n",
    "        n_grid_old = f_free.shape[0]\n",
    "        if mode == \"0\":\n",
    "            f_ = f1(f_free, n_grid_old)\n",
    "        else:\n",
    "            f_ = f3(f_free, n_grid_old)\n",
    "        f_free_std = f_.unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "        if mode == \"0\":\n",
    "            f_free_new = F.interpolate(f_free_std, size=(n_grid,n_grid), mode=interp_mode, align_corners=align_corners)[0,0,:,:-1]\n",
    "        else:\n",
    "            f_free_new = F.interpolate(f_free_std, size=(n_grid,n_grid), mode=interp_mode, align_corners=align_corners)[0,0,:,1:-1]\n",
    "        return f_free_new#torch.transpose(f_free_new,0,1)#\n",
    "\n",
    "    def interp_free_test(f_free, n_grid, mode=\"0\"):\n",
    "        if mode == \"0\":\n",
    "            f_ = f1(f_free, n_grid)\n",
    "        else:\n",
    "            f_ = f3(f_free, n_grid)\n",
    "        f_free_std = f_.unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "        if mode == \"0\":\n",
    "            f_free_new = F.interpolate(f_free_std, size=(2*n_grid-1,2*n_grid-1), mode=interp_mode, align_corners=align_corners)[0,0,1:-1:2,1:-3:2]\n",
    "        else:\n",
    "            f_free_new = F.interpolate(f_free_std, size=(2*n_grid-1,2*n_grid-1), mode=interp_mode, align_corners=align_corners)[0,0,1:-1:2,3:-3:2]\n",
    "        return f_free_new#torch.transpose(f_free_new,0,1)#\n",
    "\n",
    "    def decompose_free(f_free, n_grid):\n",
    "        f1_free = f_free[:,:n_grid-1]\n",
    "        f2_free = f_free[:,n_grid-1:2*n_grid-2]\n",
    "        f3_free = f_free[:,2*n_grid-2:3*n_grid-4]\n",
    "        f4_free = f_free[:,3*n_grid-4:4*n_grid-5]\n",
    "        return (f1_free,f2_free,f3_free,f4_free)\n",
    "\n",
    "    def compose_free(f1_free,f2_free,f3_free,f4_free):\n",
    "        return torch.cat([f1_free, f2_free, f3_free, f4_free], dim=1)\n",
    "\n",
    "    def interp_f_free(f_free, n_grid, n_grid_old):\n",
    "        f1_free, f2_free, f3_free, f4_free = decompose_free(f_free, n_grid_old)\n",
    "        f1_free_new = interp_free(f1_free, n_grid, mode=\"0\")\n",
    "        f2_free_new = interp_free(f2_free, n_grid, mode=\"0\")\n",
    "        f3_free_new = interp_free(f3_free, n_grid, mode=\"1\")\n",
    "        f4_free_new = interp_free(f4_free, n_grid, mode=\"0\")\n",
    "        f_free_new = compose_free(f1_free_new, f2_free_new, f3_free_new, f4_free_new)\n",
    "        return f_free_new\n",
    "\n",
    "\n",
    "    def interp_f_free_test(f_free, n_grid):\n",
    "        f_free = f_free.reshape(n_grid, 4*n_grid-5)\n",
    "        f1_free, f2_free, f3_free, f4_free = decompose_free(f_free, n_grid)\n",
    "        f1_free_new = interp_free_test(f1_free, n_grid, mode=\"0\")\n",
    "        f2_free_new = interp_free_test(f2_free, n_grid, mode=\"0\")\n",
    "        f3_free_new = interp_free_test(f3_free, n_grid, mode=\"1\")\n",
    "        f4_free_new = interp_free_test(f4_free, n_grid, mode=\"0\")\n",
    "        #print(f1_free_new.shape, f2_free_new.shape, f3_free_new.shape, f4_free_new.shape)\n",
    "        f_free_new = compose_free(f1_free_new, f2_free_new, f3_free_new, f4_free_new)\n",
    "        return f_free_new\n",
    "\n",
    "\n",
    "    def r_derivative(f, n_grid):\n",
    "        f_aug = torch.zeros(n_grid+2,n_grid,dtype=torch.double)\n",
    "        f_aug[1:-1] = f\n",
    "        f_aug[0] = 2*f[0] - f[1]\n",
    "        f_aug[-1] = 2*f[-1] - f[-2]\n",
    "        f_r = (f_aug[2:] - f_aug[:-2])/(2*r_h)\n",
    "        return f_r\n",
    "\n",
    "    def theta_derivative(f, n_grid):\n",
    "        f_aug = torch.zeros(n_grid,n_grid+2,dtype=torch.double)\n",
    "        f_aug[:,1:-1] = f\n",
    "        f_aug[:,0] = 2*f[:,0] - f[:,1]\n",
    "        f_aug[:,-1] = 2*f[:,-1] - f[:,-2]\n",
    "        f_theta = (f_aug[:,2:] - f_aug[:,:-2])/(2*theta_h)\n",
    "        return f_theta\n",
    "\n",
    "    def w(f1,f2,f3,f4, n_grid):\n",
    "        f1_r = r_derivative(f1, n_grid).reshape(-1,)\n",
    "        f2_r = r_derivative(f2, n_grid).reshape(-1,)\n",
    "        f3_r = r_derivative(f3, n_grid).reshape(-1,)\n",
    "        f4_r = r_derivative(f4, n_grid).reshape(-1,)\n",
    "        f1_theta = theta_derivative(f1, n_grid).reshape(-1,)\n",
    "        f2_theta = theta_derivative(f2, n_grid).reshape(-1,)\n",
    "        f3_theta = theta_derivative(f3, n_grid).reshape(-1,)\n",
    "        f4_theta = theta_derivative(f4, n_grid).reshape(-1,)\n",
    "        ones = torch.ones(f1_r.shape[0], dtype=torch.double)\n",
    "\n",
    "        stack1 = torch.stack([ones, f1_r, f1_theta, 0*ones])\n",
    "        stack2 = torch.stack([0*ones, 1+f2_r, f2_theta, 0*ones])\n",
    "        stack3 = torch.stack([0*ones, f3_r, 1+f3_theta, 0*ones])\n",
    "        stack4 = torch.stack([0*ones, f4_r, f4_theta, ones])\n",
    "        w_ = torch.stack([stack1, stack2, stack3, stack4])\n",
    "        w_ = w_.permute(2,0,1)\n",
    "        return w_\n",
    "\n",
    "    def w_inv_invt(w):\n",
    "        w_inv = torch.linalg.inv(w)\n",
    "        w_invt = w_inv.permute(0,2,1)\n",
    "        return w_inv, w_invt\n",
    "\n",
    "    def gp(g, w):\n",
    "        w_inv, w_invt = w_inv_invt(w)\n",
    "        gp_ = torch.matmul(torch.matmul(w_invt, g), w_inv)\n",
    "        return gp_\n",
    "\n",
    "    def zp(z, f2, f3):\n",
    "        f2 = f2.reshape(-1,)\n",
    "        f3 = f3.reshape(-1,)\n",
    "        rp = z[:,0] + f2\n",
    "        thetap = z[:,1] + f3\n",
    "        zp_ = torch.transpose(torch.stack([rp, thetap]),0,1)\n",
    "        return zp_\n",
    "\n",
    "    def g(x_, a=0.0):\n",
    "        r = x_[:,0]\n",
    "        theta = x_[:,1]\n",
    "        bs = x_.shape[0]\n",
    "        Sigma = r**2 + a**2*np.cos(theta)**2\n",
    "        Delta = r**2 - 2*M*r + a**2\n",
    "        one = torch.ones(bs, dtype=torch.double)\n",
    "        g01 = g02 = g10 = g12 = g13 = g20 = g21 = g23 = g31 = g32 = 0*one\n",
    "        g00 = -(1-2*M*r/Sigma)\n",
    "        g03 = g30 = -2*M*a*r*torch.sin(theta)**2/Sigma\n",
    "        g11 = Sigma/Delta\n",
    "        g22 = Sigma\n",
    "        g33 = (r**2+a**2+2*M*a**2*r*torch.sin(theta)**2/Sigma)*torch.sin(theta)**2\n",
    "        #print(g00.shape, g01.shape, g02.shape, g03.shape)\n",
    "        stack1 = torch.stack([g00, g01, g02, g03])\n",
    "        stack2 = torch.stack([g10, g11, g12, g13])\n",
    "        stack3 = torch.stack([g20, g21, g22, g23])\n",
    "        stack4 = torch.stack([g30, g31, g32, g33])\n",
    "        gs = torch.stack([stack1, stack2, stack3, stack4]).permute(2,0,1)\n",
    "        return gs\n",
    "\n",
    "    def gp_space_target(zp):\n",
    "        bs = zp.shape[0]\n",
    "        one = torch.ones(bs, dtype=torch.double)\n",
    "        g11 = one\n",
    "        g12 = g13 = g21 = g23 = g31 = g32 = 0*one\n",
    "        g22 = zp[:,0]**2\n",
    "        g33 = zp[:,0]**2*torch.sin(zp[:,1])**2\n",
    "        stack1 = torch.stack([g11,g12,g13])\n",
    "        stack2 = torch.stack([g21,g22,g23])\n",
    "        stack3 = torch.stack([g31,g32,g33])\n",
    "        gs = torch.stack([stack1, stack2, stack3]).permute(2,0,1)\n",
    "        return gs\n",
    "\n",
    "    def error(f_free, mode=\"train\"):\n",
    "        f_free = f_free.reshape(n_grid, 4*n_grid-5)\n",
    "        f1_free, f2_free, f3_free, f4_free = decompose_free(f_free, n_grid)\n",
    "        f1_ = f1(f1_free, n_grid)\n",
    "        f2_ = f2(f2_free, n_grid)\n",
    "        f3_ = f3(f3_free, n_grid)\n",
    "        f4_ = f4(f4_free, n_grid)\n",
    "        g_ = g(z, a=a)\n",
    "        w_ = w(f1_,f2_,f3_,f4_, n_grid)\n",
    "        zp_ = zp(z,f2_,f3_)\n",
    "        gp_space = gp(g_, w_)[:,1:,1:].reshape(n_grid,n_grid,3,3)\n",
    "        #print(gp_space): inconsistent here\n",
    "        \n",
    "        gp_space_target_ = gp_space_target(zp_).reshape(n_grid,n_grid,3,3)\n",
    "        if mode == \"train\":\n",
    "            error_ = torch.mean((gp_space-gp_space_target_)[1:-1,:]**2)\n",
    "        else:\n",
    "            error_ = torch.mean((gp_space-gp_space_target_)[1:-1,1:-1]**2)\n",
    "        return error_\n",
    "    \n",
    "    # Initialize next grid with the former solution\n",
    "    if ii == 0:\n",
    "    #if True:\n",
    "        f_free = torch.zeros((n_grid,4*n_grid-5), dtype=torch.double)\n",
    "        #f_free[:,:n_grid-1] = 1*M*(2*np.sqrt(rs/(2*M)) + 0.5*np.log((np.sqrt(rs/(2*M))-1)/(np.sqrt(rs/(2*M))+1)))[:,np.newaxis]\n",
    "        #f_free[:,:n_grid-1] = 2*M*(2*np.sqrt(rs/(2*M)) + 1*np.log((np.sqrt(rs/(2*M))-1)/(np.sqrt(rs/(2*M))+1)))[:,np.newaxis]\n",
    "        #f_free[:,:n_grid-1] = - 2*M*(2*np.sqrt(rs/(2*M)) - 1*np.log((np.sqrt(rs/(2*M))-1)/(np.sqrt(rs/(2*M))+1)))[:,np.newaxis]\n",
    "        f_free[:,:n_grid-1] = 0.001*(rs[:,np.newaxis] + thetas[np.newaxis,:-1])\n",
    "        f_free[:,n_grid-1:2*(n_grid-1)] = 0.001*(rs[:,np.newaxis] + thetas[np.newaxis,:-1])\n",
    "        f_free[:,2*(n_grid-1):3*n_grid-4] = 0.001*(rs[:,np.newaxis] + thetas[np.newaxis,1:-1])\n",
    "        f_free[:,3*n_grid-4:4*n_grid-5] = 0.001*(rs[:,np.newaxis] + thetas[np.newaxis,:-1])\n",
    "        f_free = f_free.reshape(-1,)\n",
    "        f_free = torch.nn.Parameter(f_free, requires_grad=True)\n",
    "        #print(f_free.shape)\n",
    "    else:\n",
    "        #best_free = torch.load('./results_grid/a_%.3f_grid_%d'%(1.0,50))\n",
    "        #f_free_old = best_free.reshape(50, 4*50-5)\n",
    "        #f_free = interp_f_free(f_free_old, n_grid, 50).reshape(-1,)\n",
    "        f_free_old = best_free.reshape(n_grid_old, 4*n_grid_old-5)\n",
    "        #print(f_free_old.shape)\n",
    "        #print(n_grid, n_grid_old)\n",
    "        f_free = interp_f_free(f_free_old, n_grid, n_grid_old).reshape(-1,)\n",
    "        f_free = torch.nn.Parameter(f_free, requires_grad=True)\n",
    "        #print(interp_f_free(f_free_old, n_grid, n_grid_old).shape)\n",
    "    \n",
    "    # \"Testing\"\n",
    "    #rs_test, thetas_test = grid(n_grid)\n",
    "    rs_test = (rs[1:] + rs[:-1])/2\n",
    "    thetas_test = (thetas[1:] + thetas[:-1])/2\n",
    "    f_free_test = interp_f_free_test(f_free, n_grid).reshape(-1,)\n",
    "    #plt.matshow(f_free_test.reshape(n_grid-1,4*(n_grid-1)-5))\n",
    "    RS_test, THETAS_test = torch.meshgrid(rs_test, thetas_test)\n",
    "    # Transpose here is very important! Becareful of meshgrid and reshape stuff!\n",
    "    #RS_test = torch.transpose(RS_test,0,1)\n",
    "    #THETAS_test = torch.transpose(THETAS_test,0,1)\n",
    "    z_test = torch.transpose(torch.stack([RS_test.reshape(-1,), THETAS_test.reshape(-1,)]),0,1)\n",
    "\n",
    "    \n",
    "    def error_test(f_free, mode=\"train\"):\n",
    "        #print(f_free.shape)\n",
    "        f_free = f_free.reshape(n_grid-1, 4*(n_grid-1)-5)\n",
    "        f1_free, f2_free, f3_free, f4_free = decompose_free(f_free, n_grid-1)\n",
    "        f1_ = f1(f1_free, n_grid-1)\n",
    "        f2_ = f2(f2_free, n_grid-1)\n",
    "        f3_ = f3(f3_free, n_grid-1)\n",
    "        f4_ = f4(f4_free, n_grid-1)\n",
    "        g_ = g(z_test, a=a)\n",
    "        w_ = w(f1_,f2_,f3_,f4_, n_grid-1)\n",
    "        zp_test = zp(z_test,f2_,f3_)\n",
    "        gp_space = gp(g_, w_)[:,1:,1:].reshape(n_grid-1,n_grid-1,3,3)\n",
    "        \n",
    "        gp_space_target_ = gp_space_target(zp_test).reshape(n_grid-1,n_grid-1,3,3)\n",
    "        if mode == \"train\":\n",
    "            error_ = torch.mean((gp_space-gp_space_target_)[1:-1,:]**2)\n",
    "        else:\n",
    "            error_ = torch.mean((gp_space-gp_space_target_)[1:-1,1:-1]**2)\n",
    "        return error_\n",
    "    \n",
    "    def error_all(f_free, mode=\"train\"):\n",
    "        f_free_test = interp_f_free_test(f_free, n_grid).reshape(-1,)\n",
    "        #print(interp_f_free_test(f_free, n_grid).shape)\n",
    "        return error(f_free, mode=mode) + error_test(f_free_test, mode=mode)\n",
    "    \n",
    "    \n",
    "    # Test and Train at the same time\n",
    "    start = time.time()\n",
    "    #lr = 36/n_grid**2\n",
    "    #opt = LBFGS({f_free}, lr=lr, max_iter=1000, max_eval=None, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=1000, line_search_fn='strong_wolfe')\n",
    "    #opt = LBFGS({f_free}, lr=lr, max_iter=100, max_eval=None, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=1000)\n",
    "    lr = 1e-2#*(6/n_grid)**2\n",
    "    opt = torch.optim.Adam({f_free}, lr=lr, eps=1e-8)\n",
    "    \n",
    "    epochs = 15000\n",
    "    switch_epoch = 3000\n",
    "    log = 100\n",
    "    best_loss = 1e20\n",
    "    losses = []\n",
    "    for i in range(epochs):\n",
    "        if (i+1) % switch_epoch == 0:\n",
    "            for opt_param in opt.param_groups:\n",
    "                lr = lr * 0.5\n",
    "                opt_param['lr'] = lr\n",
    "        \n",
    "        def loss_closure():\n",
    "            opt.zero_grad()\n",
    "            loss = error_all(f_free, mode=\"train\")\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        def loss_closure2():\n",
    "            opt.zero_grad()\n",
    "            loss = error_all(f_free, mode=\"evaluate\")\n",
    "            loss.backward()\n",
    "            return loss\n",
    "          # -------------------------------------------\n",
    "        loss = loss_closure()\n",
    "        #print(\"loss_0={}\".format(loss.detach().numpy()))\n",
    "        #loss2 = loss_closure2()\n",
    "        opt.step(loss_closure)  # get loss, use to update wts\n",
    "        #loss = loss_closure()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            #best_loss2 = loss2\n",
    "            best_epoch = i\n",
    "            best_free = f_free.clone()\n",
    "        if i % log == 0:\n",
    "            print(\"Epoch: {}\".format(i) + \" | \" + \"Loss: {}\".format(loss.detach().numpy()))\n",
    "        losses.append(loss.detach().numpy())\n",
    "    end = time.time()\n",
    "    print(\"time={}\".format(end-start))\n",
    "    times.append(end-start)\n",
    "    errors.append(best_loss.detach().numpy())\n",
    "    print(\"error={}\".format(loss.detach().numpy()))\n",
    "    print(\"best loss={}\".format(best_loss.detach().numpy()))\n",
    "    #print(\"best loss2={}\".format(best_loss2.detach().numpy()))\n",
    "    print(\"best epoch={}\".format(best_epoch))\n",
    "    #errors.append(error_all(f_free))\n",
    "    ii = ii + 1\n",
    "    n_grid_old = n_grid\n",
    "    torch.save(best_free, './results_grid/params_grid_adam_nolrdecay_randominit_seq_a_%.3f_n_%d'%(a,n_grid))\n",
    "np.save('./results_grid/loss_grid_adam_nolrdecay_randominit_seq_a_%.3f'%a, np.array([n_grids, errors, times]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.00000000e+00, 8.00000000e+00, 1.20000000e+01, 1.60000000e+01,\n",
       "        2.00000000e+01, 2.40000000e+01, 2.80000000e+01, 3.20000000e+01,\n",
       "        3.60000000e+01, 4.00000000e+01, 4.40000000e+01, 4.80000000e+01],\n",
       "       [1.71634783e-06, 8.02625129e-07, 2.10494418e-07, 7.56252584e-08,\n",
       "        3.36992749e-08, 1.75715278e-08, 1.05641157e-08, 1.74481829e-04,\n",
       "        1.00569747e-08, 1.54186156e-04, 7.44065483e-02, 7.82208103e-02],\n",
       "       [1.82513148e+02, 1.86205219e+02, 1.90518918e+02, 1.99296564e+02,\n",
       "        2.24838160e+02, 2.47057247e+02, 2.58655245e+02, 2.79607646e+02,\n",
       "        2.92888562e+02, 3.16629937e+02, 3.26732824e+02, 3.60222248e+02]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./results_grid/loss_grid_adam_nolrdecay_randominit_seq_a_%.3f.npy'%a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'error')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAETCAYAAADzrOu5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxmElEQVR4nO3de3Tc9X3n/+dbI42utiSPZNmSdbEtW7YhgLGCE+4EO5gFx5STpEBP9qSwYdP90f72UlrYbU5+Tdo6OXT390sKW+oklKXZks2FEkNdHMzFBkITYxMCtmRrfNXNGtmSrLt1e//+GI0sC42lkebynfm+H+f4BH31ne98BBO9/Lm9P6KqGGOMMfORlugGGGOMSX4WJsYYY+bNwsQYY8y8WZgYY4yZNwsTY4wx82ZhYowxZt7SE92ARCkqKtKqqqpEN8MYY5LKgQMHzqpq8dTrrg2Tqqoq3nvvvUQ3wxhjkoqInJruug1zGWOMmbeUCBMRWSEiPxCRnya6LcYY40YJDxMReUZEAiLy0ZTrW0TkiIj4ReSxyz1DVY+r6kOxbakxxphwnDBn8izwJPBc6IKIeICngM1AE7BfRHYCHmD7lNc/qKqB+DTVGGPMdBIeJqq6T0Sqply+DvCr6nEAEfkRsE1VtwN3z/W9RORh4GGAioqKuT7GGGOSzovvN/PE7iO0dA1QWpDNo3fUcM/6sqg9P+HDXGGUAY2Tvm4avzYtEfGJyNPAehF5PNx9qrpDVWtVtba4+GMr24wxJmm8+H4zN3zrdZY/9s/c8K3XefH95sve+/gLH9LcNYACzV0DPP7Ch5d9TaQS3jMJQ6a5FrZWvqqeA746qweLbAW2VldXz7FpxhiTWKFwGBgeBS6GAzDR2xgeHaP/wii9QyP81a66iXtDBoZHeWL3kaj1TpwaJk1A+aSvlwEtCWqLMcY4yhO7j0wbDv/lJx/w5y8dom9olKGRsRmf09I1ELU2OTVM9gOrRGQ50AzcBzwQjQer6kvAS7W1tV+JxvOMMSbewoXA6Jhy91Wl5GR6yPOmk5OZTl6mh2/9Sz2d/cMfu7+0IDtqbUp4mIjI88CtQJGINAFfV9UfiMgjwG6CK7ieUdVDUXo/G+YyxiS10oJsmqcJlLKCbL55z5Ufu56Z7rlkWAwgO8PDo3fURK1N4tZje2tra9XKqRhjktGL7zfzxz/5gJGxi7+/szM8bL/3E2HnQKK1mktEDqhq7ceuuy1MJvVMvtLQ0JDo5hhjzJx8/m/f4eDpLlSJyVLfcMKFScKHueLN5kyMMamgb2iMm1cX8+zvX5fopgDO3WcSMyKyVUR2nD9/PtFNMcaYORkeHcMf6GHNkoWJbsoE14WJqr6kqg/n5+cnuinGGDMnx9v7GB5V1i5dkOimTHBdmBhjTLKra+0GYO1S65kkjA1zGWOSXd2ZbryeNJYX5Sa6KRNcFyY2zGWMSXb1rT2sKskjw+OcX+HOaYkxxphZqWvtdtTkO7gwTGyYyxiTzM71XiDQc8FRk+/gwjCxYS5jTDKrP9MDOGvyHVwYJsYYk8xCK7nWLLGeiTHGmDmqP9ND8YJMfHmZiW7KJSxMjDEmidS1djtuiAtcGCY2AW+MSVYjo2M0tPWy1mFDXODCMLEJeGNMsjp+to+h0THrmRhjjJm7icl3hy0LBgsTY4xJGvVnesjwCCuK8hLdlI+xMDHGmCRR19pN9eIFeNOd96vbeS0yxhgzrfrWHkdOvkMKhYmI3CMi3xORn4vIZxPdHmOMiabOviHOdA86cvIdHBImIvKMiARE5KMp17eIyBER8YvIY5d7hqq+qKpfAb4M/G4Mm2uMMXFXd8a5k+/gnDPgnwWeBJ4LXRARD/AUsBloAvaLyE7AA2yf8voHVTUw/s9/Nv46Y4xJGfWtwZpcTqsWHOKIMFHVfSJSNeXydYBfVY8DiMiPgG2quh24e+ozRESAbwH/oqoHp3sfEXkYeBigoqIiej+AMcbEWF1rN0V5mRQvcFYZlRBHhEkYZUDjpK+bgI2Xuf8PgU1AvohUq+rTU29Q1R0i0gps9Xq9G6LaWmOMiaH6Mz2OKzs/mSPmTMKQaa5puJtV9buqukFVvzpdkEy6z3bAG2OSysjoGEfbehw7+Q7ODpMmoHzS18uAlvk+1GpzGWOSzclzfVwYGXNc2fnJnBwm+4FVIrJcRLzAfcDO+T7UeibGmGRT5/DJd3BImIjI88C7QI2INInIQ6o6AjwC7AbqgB+r6qEovJf1TIwxSaWutZv0NKF6sfPKqIQ4YgJeVe8Pc30XsCvOzTHGGEepP9ND9eI8R5ZRCXFuy2LEhrmMMcmmvrXb0fMl4MIwMcaYZNLVP0TLeeeWUQlxXZjYnIkxJpnUnxmffLcwcRYb5jLGJJPQgVhO3rAILgwT65kYY5JJfWsPvlwvxXnOLKMS4rowsZ6JMSaZ1J/pZs3SBQTLDzqX68LEGGOSxeiYcqSth7UO3qwYYmFijDEOdfJcH4PDY46ffAcXhonNmRhjkkWyTL6DC8PE5kyMMcmivrUHj8PLqIS4LkyMMSZZ1J/pZmVxLpnpnkQ3ZUYWJsYY41B1rc4+w2QyCxNjjHGg8wPDNHcNOLrs/GSuCxObgDfGJIP6JJp8BxeGiU3AG2OSQagmlw1zGWOMmbP6M90U5mSweIGzy6iEWJgYY4wDHR6ffHd6GZUQCxNjjHGY0THl6JmepJl8hxQJExFZKyJPi8hPReQPEt0eY4yZj9Md/QwMj7ImSSbfwQFhIiLPiEhARD6acn2LiBwREb+IPHa5Z6hqnap+FfgiUBvL9hpjTKyFyqisS5LJd3BAmADPAlsmXxARD/AUcCewDrhfRNaJyCdE5OUpfxaPv+ZzwNvAa/FtvjHGRFd9a3fSlFEJSU90A1R1n4hUTbl8HeBX1eMAIvIjYJuqbgfuDvOcncBOEfln4B9j2GRjjImpw609rCjKJSvD+WVUQhIeJmGUAY2Tvm4CNoa7WURuBe4FMoFdl7nvYeBhgIqKiig00xhjoq/+TDfrKwoT3YyIODVMplsLp+FuVtU3gTdneqiq7hCRVmCr1+vdMOfWGWNMjHQPDtPUOcD91yXXX3idMGcynSagfNLXy4CWaDzYdsAbY5zsyPjO92SafAfnhsl+YJWILBcRL3AfsDMaD7baXMYYJwvV5EqmZcHggDARkeeBd4EaEWkSkYdUdQR4BNgN1AE/VtVDiWynMcbEw+HWHgpyMliyMCvRTYlIwudMVPX+MNd3cZnJ9Hm830vAS7W1tV+J9rONMWa+6s90s2bJgqQpoxKS8J5JvNkwlzHGqcbGlCNJVkYlxHVhYhPwxhinOt3RT//QaNJNvoMLw8R6JsYYp6o/k5yT7+DCMLGeiTHGqQ639pAmsLrEwsQYY8wc1bd2szzJyqiEuC5MbJjLGONU9Wd6WJOE8yXgwjCxYS5jjBP1DA5zuqM/KSffwYVhYowxTnS0LVhGZc2S5JsvAQsTY4xxhLrW8TCxnklysDkTY4wT1bV2szArndL85CqjEuK6MLE5E2OME4Um35OtjEqI68LEGGOcZmxMqW/tTtrJd7AwMcaYhGvqHKBvaDRpJ9/BAVWDjTEmUV58v5kndh+hpWuA0oJsHr2jhnvWl8W9HXUTZVSsZ5I0bALeGAPBIHn8hQ9p7hpAgeauAR5/4UNefL857u344598AMB/+OGBuL9/tLguTGwC3hgD8MTuIwwMj15ybWB4lCd2H4lbG0KB1jM4AkDL+cGEBFo0uC5MjDEGoKVrIKLrseCEQIuWiMJERF4XkW/GqjHGGBMvpQXZEV2PBScEWrRE2jP5FJB85SyNMWaKR++oISv90l+B2RkeHr2jJm5tcEKgRUukYdIAlMeiIfMlIrkickBE7k50W4wxznfP+jIevHH5xNcLs9LZfu8n4rqa69E7avB6Ehto0RJpmHwfuEtEKqLVABF5RkQCIvLRlOtbROSIiPhF5LFZPOpPgR9Hq13GmNRXsjBYuiQzPY07r1wa92XB96wv4571pQAIUFaQHfdAi5ZI95m8BGwG3hGRbwP7gTOATr1RVU/P8pnPAk8Cz4UuiIgHeGr8vZqA/SKyk+AQ2/Ypr38QuAo4DCRnURtjTEI0BHpYkJVOTckCTp7rS0gbivIySU8TjvzFnXjSkrOUCkQeJscJBocA37nMfTrbZ6vqPhGpmnL5OsCvqscBRORHwDZV3Q58bBhLRG4DcoF1wICI7FLVsWnuexh4GKCiImqdK2NMkvIHelm1OI+qolzebjibkDY0dgY3TCZzkEDkYfIc0/RCYqAMaJz0dROwMdzNqvrfAETky8DZ6YJk/L4dwA6A2traePwcxhgH8wf6+MyaYioW5fDTA4MMDI2S7Y3vGqPGjn7KFyXfhPtUEYWJqn45Ru2YarqInvGXv6o+O+ODRbYCW6urq+fQLGNMqujqH+Js7wWqF+exND/4y/xURx9rlsS3pElTZz+b1pbE9T1jwambFpu4dNXYMqAlQW0xxqQgf6AXgFWLF1DlywXg5Nn+uLahf2iEs71DlC/Kiev7xsKcw0RElo3XufqSiHxORJZFsV37gVUislxEvMB9wM5oPNjKqRhj4GKYVC/Oo7Io+Mv8VJwn4Zs6g5sTlxW6bJgLYHxZ8A6CK62mfu9V4KuqejKC5z0P3AoUiUgT8HVV/YGIPALsJriC6xlVPRRpW8O8nw1zGWNoCPSSlZFGWUE2aWmCL9cb9xVdTZ3BnlAq9EwiChMRWQK8Q3CC/CSwD2gFlgI3Ap8F3haRWlU9M5tnqur9Ya7vAnZF0r5Zvt9LwEu1tbVfifazjTHJwx/oZWVxHmnjq6gqfTlxH+Zq7Aj2TMoLkz9MIh3m+hrBIPlTYJWqfllVHx+fmK8B/gQoBf4sqq2MIitBb4yBYJhUL86b+LqqKDfuw1yNHf1kZ3goyvPG9X1jIdIwuQv4hao+oaqXlLpU1VFV/WvgF0yzF8QpbM7EGNN3YYTmrgGqiyeFiS+XlvODDE6p4htLjZ39LCvMTtpz3yeLNEyWAAdmuOfA+H2OZD0TY8zx9mAPZFXJxTCp9AWHmk53xG+oq7FjICUm3yHyMDkPVM5wT8X4fY5kPRNjTEOgB+DSYa6J5cHxG+pq7OxPicl3iDxM3gY+LyLXT/dNEdkIfGH8PmOMcSR/oJf0NKFyPEDgYpicOhefnsn5/mF6BkdSYvIdIl8a/JcE5032jtfLeoPgaq4lBJf33g+MAX8VxTZGlS0NNsb4A71UFeWSMan8e35OBoU5GZyI0yR848SyYBcOc6nqQeDzBIexfg/4HvAywdL0XwK6gS+q6kzzKgljw1zGGH+g95LJ95BKX/xWdIX2mCxzac8EVX1ZRCqBbcC1QD7BcHkfeFFVE1PH2RhjZmFoZIxTHf3cddXSj31veVEuvz7REZd2TOwxSZE5k0g3LT4DfKiq/y/wj+N/kooNcxnjbifP9TE6ppdMvodU+nJ48TfNDA6PkpUR2+rBjZ39LMxKJz87I6bvEy+RTsA/ACyORUPixYa5jHG3hrZgTa6V0wxzVflyUb04BBVLwdLzqdErgcjD5CRJHibGGHfzB3oRmT5MQntN4lFWpbEzdfaYQORh8o/AnSJSGIvGGGNMrPnbe1lWmD3tIVjLi8b3msR4El5VaersT5llwRB5mGwH3gPeEJG7RST5T3QxxrhKQ1vPtCu5AApyvORnZ8Q8TNp7LzA4PJZSw1yRruYaHP9fAX4OhKspo6oa8UqxeLAJeGPca3RMOX62j5tXF4e9p8qXE/ONixdXcqXOMFekv/DfIj5nwMeMlaA3xr0aO/oZGhkL2zOBYPXgg6c7Y9qOiXNMUmiYK9Iz4G+NUTuMMSbmQqcrrpxmWXBIpS+Xlz5oYWhkDG96bE42v3jCYuqESUT/pkTkGRH5T7FqjDHGxJK//eJRveFU+XIY04vlTmKhsaOforzMaRcBJCvX7TMxxrhXQ1svixdkXnajYOVEwcfYTcIHqwWnznwJ2D4TY4yL+Nt7L9srgYvLg0/EcK9J8ByT1BnighTZZyIit4rIWyLytIjcmuj2GGOcR1U5Fuhl1QxhUpiTwYKs9Jj1TEbHlJauAcpTaMMiOGCfyfg8TEBEPppyfYuIHBERv4g8NsNjFOgFsoCm+bbJGJN6znQP0nthZMaeiYhQ5cvlZIyWB7eeH2BkTFNqjwk4Y5/Js8CTwHOhCyLiAZ4CNhMMh/0ishPwEAy0yR4E3lLVvePh9j8Ilsc3xpgJs1nJFVJVlMtvm7pi0o6JPSYpNsyV8H0mqrpPRKqmXL4O8KvqcYDxg7i2qep24O7LPK4TyAz3TRF5GHgYoKKiYj7NNsYkmVCYrFq8YMZ7q3w57PqwleHRsUsO0IqGVDsUK8Sp+0zKgMZJXzcBG8PdLCL3AncABQR7OdNS1R0i0gps9Xq9G6LTVGNMMmgI9JKfnUFRnnfGeyt9uYyOKU2dAxMT8tHS1NFPmkBpQWqFyZwjV0RyRWS9iNwUzQaFHj/NtbA9IlV9QVX/var+rqq+ebkHWwl6Y9zJPz75HmZo/hJVoerBMZiEb+ocYGl+dtR7PIkW8U8jIstE5GcEh5TeI3gOfOh7N4rI4SisqGoCyid9vQxomeczgWBtLhHZcf78+Wg8zhiTJI4FZl4WHFIVqh58Nvph0tjZn1Kl50Mi3QG/FPgVwSN7Xwbe5dJexK8I7kP53Xm2az+wSkSWi4gXuA/YOc9nAtYzMcaNOvqGONc3NOsw8eV6yctMj0nBx8aOgZRbyQWR90y+TjAsNqnqvcCrk7+pqsMEJ+lvmO0DReR5gqFUIyJNIvKQqo4AjwC7gTrgx6p6KMK2hns/65kY4zKhyffZhomIUOnLifow14WRUdp6BlOyZxLpaq5/A+ycYV7iNDDreRRVvT/M9V3ArohaZ4wx02gI9ACzDxMIDnUdbumOajuaOwdQTb1lwRB5z6QEaJjhnmEgussfosiGuYxxH3+gl+wMD6X5s+8RVPlyaOzoZ2R0LGrtaOwMnWNiYdLBpRPj01kNnJlbc4wxJvr845PvaWkzr+QKqfTlMjKmNHcNRK0djR2puccEIg+Td4DPiciS6b4pIquALUxa4eU0NmdijPv4I1jJFVLlC50HH71J+MbOfryeNEoWZEXtmU4RaZg8QbD+1V4RuRPIgYk9J3cCLwFjwH+PaiujyIa5jHGX3gsjtJ4fjDxMisb3mkRxeXBT5wBlhdkR9ZCSRaQ74H81XpLkaYJLg0NCs1QjwIPRWnlljDHzdSzClVwhxXmZ5Hg9UV3R1dSRmntMYA6bFlX174Erge8CvwaOAQeB/wlcpar/O6otjDIb5jLGXRrmGCbB5cG5Ud1r0tiZmntMIPKlwQCoagOQlMf3qupLwEu1tbVfSXRbjDGx5w/0kuERKufwS3x5UQ71rT1RaUffhRE6+oasZ2KMMcnIH+hleVEu6XOohVXpy6WxMzrLgyeqBafgHhNwYZjYMJcx7uIP9EQ8xBVS5ctheFRpPT84880zmDjHJEWHuVwXJraayxj3GBwe5XRHP9WzOMNkOpUTy4PnPwk/scfEhrmMMSa5nDjbx5hGPvkesjyK1YMbO/vJ8XpYlDvzeSrJyMLEGJOyJgo8Fs8tTBYvyCQrIy0qGxcbOwYoL8yZ1XkqyWhOq7nc6sX3m3li9xFaugYoLcjm0TtquGd9WaKbZYwJwx/oJU1gRfHcygWKCFW+XE5FYZirqbM/JcuohLiuZzLXCfgX32/m8Rc+pLlrAAWauwZ4/IUPefH95tg01Bgzb/5AL+WLcsjK8Mz5GVW+XE7Mc5hLNXgE8LIUXckFLgyTuU7AP7H7CAPDo5dcGxge5Ynd9dFsnjEmivyB3jkPcYVUFuXQ2DHA6FjYk8Nn1NU/TO+FkZTdYwIuDJO5aglTObS5a5AHn93Pk6838MtjZ+m7MBLnlhljpjMyOsaJs31Ul8wvTKp8uQyNjtF6fu7Vgyf2mKTosmCwOZNZKy3InrYUdY7Xw+mOfl6vDwDgSRPWLFnAhspCrq0oZENlIcsKs1N20s0Ypzrd0c/Q6Nj8eya+YACcOtc/52GqiT0mKTzMZWEyS4/eUcPjL3x4yVBXdoaHv/qdT3DP+jK6+od4v7GLg6c6OXi6k58daOK5d08BUJSXyYbKgomAubIsf15juMaYmUV6VG84oeXBJ872cUN10ZyecbFnkrrDXCkRJiKSBnwTWAi8p6r/K9rvEVq1FW41V0GOl9tqFnNbzWIg2MU+0tbDwdMXA2b3oTYAMjzCFaX5l/ReluSn3vkGxiSSvz06YVKyIIvM9LR5rehq7OinICeDBVkZ82qLkyU8TETkGeBuIKCqV066vgX4DuABvq+q37rMY7YBZQRPgmyKVVvvWV8266XA6Z40rijN54rSfL70qUoA2nsu8P7pTg6c7uTgqU5++K+n+MHbJwAoK8hmfcXF3su60oVkzKGWkDEmyN/Wy5KFWfP+BZ6WJlT6cua116SxcyClh7jAAWECPAs8CTwXuiAiHuApYDPBcNgvIjsJBsv2Ka9/EKgB3lXVvxORnwKvxaHdEStekMlnr1jCZ68IHlQ5NDLG4dZuDp66GDAv/7YVgKyMNK5aVjDRc7m2ogBfXmYim29MUvG3R366YjjzXR7c1NHPmqVzK+mSLBIeJqq6T0Sqply+DvCr6nEAEfkRsE1VtxPsxVxCRJqAofEvR6d+36m86WlcU17ANeUFPMhyAFrPD3DwVBcHxgPmB28f5+m9wSWJVb4crq0o5NrKYMCsLlmAJwVPbDNmvlQVf6CXL9aWR+V5VUW5vHm0nbExjfiUxLExpalrgM3rSqLSFqdKeJiEUQY0Tvq6Cdh4mftfAP5GRG4C9oW7afyUyIcBKioqotDM6Fuan81dV2Vz11VLgWChug+bzwd7L6c62dfQzgvjGyXzMtO5pryAaysKuLaykPUVheRnZ9hOfeN6LecH6R8ajVrPpNKXw9DIGGe6ByktiGwSvb33AkMjYym9xwScGybTRX/YHUOq2g88NNNDVXWHiLQCW71e74Z5tC9usjI8fLJqEZ+sWgQE/8bV2DHAgdMdEz2YJ9/wE9pPVbIgk7N9QxMbrEI79QELFOMa0VrJFVI1qXpwpGESqha8LIX3mIBzw6QJmNw/XQa0ROPByX7SoohQ4cuhwpfD76xfBgRPcPugsYuDpzv5m9f9H9upOzA8yjdePsymdSXkZTr1P7kx0dPQFjwdcVW0wmSienA/16+M7LWpfihWiFOXC+0HVonIchHxAvcBO6Px4FQ8HCs3M53rq4t45DOrGBqZ/kS4jr4hrvnzX3Dfjnf52zePcbilG9W5l4cwxsmOtfdSmJMRtUUrSxdm4Z3j8uDQhkUb5ooxEXkeuBUoGp9I/7qq/kBEHgF2E1zB9YyqHkpgM5NGuJ36RXlePr+hnL1H2/n2K/V8+5V6ihdkcvOqYm6pKeam6iIKU/ScBeM+/kAvq+Z4INZ00tKEikU5czokq7Gjf7yUfWpvVE54mKjq/WGu7wJ2xeD9knqYaybhdur/2V3ruGd9GY/duYa27kH2HW1nX8NZXqtv42cHmxCBq5cVcMvqYLhcvazAVoqZpKSqNAR6ufPKpVF9bpUvl5NnI99r0tjZn9I1uUISHibxJiJbga3V1dWJbkpMzLRTH6BkYRZfqC3nC7XljI4pv23qYu/RdvYebee7rzfwndcayM/O4KZVRcFwWV3M4oW2Q98kh3N9Q3T1D0dt8j2kypfD2/7Ilwc3dgzwyarCqLbFiVwXJqneM4HIdup70oT1FcFlxf9x02o6+4Z42392IlxCmyjXLl04ESwbKgvxpjt1us24XWglV7Qm30Mqi3IZHB4j0HNh1uWPhserDZcvSv2VlK4Lk1TvmcxXYa6XrVeXsvXqUlSVutae8WAJ8P23jvP03mPkej18emURt9QUc+vqYld04U3yaIjysuCQqvHqwSfO9s06TM6cH2RMU38lF7gwTNzQM4kWEWFd6ULWlS7kD25dSe+FEd49do69RwO8eaSdPXXBwpUrinK5eXyu5VPLfWR7U3ui0TjbsUAvuV4PS6NcPDW01+TUuT4+vdI3q9dM7DFJ8ZVc4MIwMXOXl5nO5nUlbF5Xgqpy4mzfxHDY878+zbO/PIk3PY2Nyxdxy+pibq0pZmVxnp3lYuLKHwjW5Ir25660IJsMj0RU8NENh2KFuC5MbJgrOkSEFcV5rCjO4/dvWM7g8Ci/PtExES5/8c91/MU/11FWkB3stawu5vpqHwtTuAS3cYaGQM+czx25HE+aUL4oJ6K9Jo0dA3jSJOq9JCdyXZjYMFdsZGV4uHl1MTevLuZrQFNnP/uOnmXv0QAvfdDC878+jSdN2FBRyC01wXBZt3RhxEXzjLmc7sFh2rovRH2+JGR5hNWDGzv7WZqfRboLjpNwXZiY+FhWmMMDGyt4YGMFw6NjHDzVOdFreWL3EZ7YfYSiPO/Epskbq4usxL6Zt2MTK7liU+690pfLL4+dQ1VnNYzW2NHvisl3sDAxcZDhSWPjCh8bV/j4ky1raO+5wFsNwWB540iAF95vRgSuKsu/ZNOkG/42Z6IrViu5QqqKchgYHqW958Ks9l41dg5wW01xTNriNK4LE5szSbziBZnce+0y7r12GaNjykfN5yd6LU++4ee7r/tZmJXOjeObJm9eXczS/NRfDWPm71igF68njfIYrZ6q9F08D36mMBkcDx3rmaQomzNxFk+acHV5AVeXF/BHt6/ifP/w+KbJAHuPtrPrwzMA1JQsmJhrqa0qJDP94vJjO7/FhDQEellRnBuzXu3yieXB/WxccfnlwU2dwRp5bljJBS4ME+Ns+TkZ3HXVUu66aimqypG2HvYeaWdfQzt//84Jduw7TnaGh+tX+rilppihkTH++y+OTtQis/Nb3M0f6OUTy/Jj9vzSgizS02RWBR9Dy4LdsMcELEyMg4kIa5YsZM2Shfz7W1bSd2GEfz1+jr1H23nzSDuv1Qemfd3A8ChP7D5iYeIyg8OjNHb2c++1sfvvnu5JG18ePPNek6YO9+wxAQsTk0RyM9O5fW0Jt68NnqV98mwft/71m9Pe29w1wLneC7ZCzEWOtfeiGrvJ95AqX86slgc3dg7gTU+j2CWfQdctl0nFw7Hcqqool7LLHKFa+5d7+Pzf/pK/ffMY/kCPHQaW4qJ9VG84lb5cTp3rm/Hz1NjRz7LCbNfspXJdmKjqS6r6cH5+7MZVTfw8ekcN2VMOHcrOSOO/bF7NH31mFQPDo3z7lXo2/Y993PbXb/LNlw/z7rFzDI9OfyKlSV7HAr2kCSwfP2I3Vqp8OfQNjXK2d+iy9zV2umePCdgwl0lyM53f8p82r6ala4DX6gPsOdzGP7x7ih+8fYKFWenctmYxt68t4ZbVxeRnW5mXZNcQ6KXSl3vJSr9YqAydB3+uj+IF4YewGjsGuKa8IKZtcRILE5P0Zjq/pbQgmy99qpIvfaqS3gsjvN3Qzp66AK/XB/j5b1pITxOuW76ITWtL2LS2hAqfe/42mUr8gV5WFsd2iAsuLg8+ebaPT1Ytmvae7sFhzg8MW8/EmFSVl5nOliuXsuXKpYyOKb9p7OTVwwFeq2vjGy8f5hsvH2Z1SR6bxif6rym344uTwfDoGCfP9bFpXUnM36usMBtPmlx2RVejy1ZyQYqEiYjcBPwewZ9nnapen+AmmSTgSRM2VC5iQ+UiHrtzDafO9bGnLjgc9nf7jvM/3zxGUZ6X22oWs2ldCTetKiLHmxL/l0k5p871MzyqVMehZ5LhSWNZYfZl95qENiy6ZY8JOCBMROQZ4G4goKpXTrq+BfgO4AG+r6rfCvcMVX0LeEtE7gH2x7bFJlVV+nJ56MblPHTjcs73D/Pm0QB76gK8cugMPznQhDc9jRtW+ti0roTb15TM+rQ9E3vxWskVUuXLvWyYTPRMbJgrrp4FngSeC10QEQ/wFLAZaAL2i8hOgsGyfcrrH1TV0O61B4B/F+sGm9SXn5PBtmvK2HZNGcOjY+w/2cGewwH21LXxxj99xH/jIz5Rls/taxezaW0JV5QutEPAEsgf6AFgZdzCJIeDpzrDVg9u6hwgLzOdghz3LOxIeJio6j4RqZpy+TrAr6rHAUTkR8A2Vd1OsBfzMSJSAZxX1e5Ytte4T4YnjetXFnH9yiK+dvda/IFeXq1r47W6AN95rYH/b08DS/OzuH1tcHXYp1f4yMqwo4vjyR/opTQ/i7zM+PxKq/Tl0nNhhI6+oWk3xob2mLjpLxgJD5MwyoDGSV83ARtneM1DwN9f7gYReRh4GKCiomI+7TMuJSKsKlnAqpIF/Idbqznbe4E36oM9lhcONvPDfz1NjtfDTauK2LS2hM+sWTzxy8YKUsaOv703br0SCJaih+Dy4GnDpLN/osKwWzg1TKaL88tuN1XVr8/0UFXdISKtwFav17thro0zJqQoL5Mv1JbzhdpyBodHeff4OV6ra2PP4QC7D7UhAtdWFLI0P4tXD7dxYSS4WdIKUkbP2JjiD/TywHWVcXvPqonlwf1sqLx0ebCq0tgxwI3V7jjHJMSpYdIElE/6ehnQkqC2GDMrWRkebqtZzG01i/nmNuVQSzd76trYU9fGy79t/dj9VpAyOpq7BhgcHovb5DsETxJNE6Y9D/5c3xADw6OUL3LPSi5wbjmV/cAqEVkuIl7gPmBnNB5s5VRMPIgIV5bl8x83reblP7xp2q42BH8RvvJRK30XRuLavlTib4/vSi4Ab3oaZYXZnJhmr4kbV3KBA3omIvI8cCtQJCJNwNdV9Qci8giwm+AKrmdU9VCU3s9OWjRxV1qQTXPXwMeui8BXf3hwYtnx5nVL2LR28ayOhDVB/rbQue/xCxMIDnVN1zNpDO0xcVnPJOFhoqr3h7m+C9gVg/ezkxZN3D16Rw2Pv/DhxCFeANkZHv7ynitYWpDDq4fbeLXuDG/804f813+Ca8oL2LyuhM+uK6F6cZ6rVgVFyh/oxZfrpTDXG9f3rfLl8uJvmj+2PLip03omrmA9E5MIMxWk/PRKH1+7ey1H2np49VAbr9a18cTuIzyx+whVvhw2ryth87olbKgstPIuU/jbe+M6xBVS6cuhZ3CErv7hS4KssWOARblecuO0TNkp3PXTYj0TkzgzFaScfLLkH96+ijPnB3m1ro09h9v4X788xffeOsGiXC+fWbOYzVbeBQiunGpo62Hr1aVxf+/Qiq4T5/ouCZOmzn7KXVRGJcR1n0TrmZhksSQ/a6Lacc/gMPuOnuXVw2f4xaEz/PRAE5npadxYXcTmdcGilJcrh56q2nsv0D04kpCeSdV4KfpT5/q4tqJw4npjRz9XlLlvgY/rwsR6JiYZLcjK4K6rlnLXVUuD5V1OdPCLw228eriN1+oDiHzI+vICNq9bwubxeRY3CNXkWrV4Qdzfu3xRNiLBvSYho2NKc9cAW65cGvf2JJrrwsSYZJfhSeP66iKury7i61vXUdfaMzGB/+1X6vn2K/WsKModn2cpYX1FcJ4lFXfgx7vA42SZ6R5K8y+tHtzWPcjwqLpujwm4MExsmMukEhFhXelC1pUu5P/etIqWrgH21AV7LM+8c4K/23ccX66X6sW5vH/6PEOjqbUD3x/oJS8znZKFiRniW16Uy8lJe03cuscEnLtpMWZs06JJZaUF2fzbT1fxDw9t5MDXNvM396/nhuoifn2icyJIQkI78JNZQ1tvQpdOV/pyLtlrEtpj4qZDsUJcFybGuMXCrAy2Xl3Kd+9fH/ae5q4BnnrDz9G2HlQvW/7OkRK1LDikypdLV/8wXf1DQHAllwiUFrhv06nrhrmMcaNwO/AzPDKxn6ViUQ6b1pawad1iPlm1iAyPs/+ueb5/mPaeCwkNk0pfqHpwP9fkeGnsGKBkQRaZ6e47gsB1YWJzJsaNwu3A337vJ/j0Sh+v1QXL6P/wV6d45p0TLMxK59bx44pvWV1MfrbzDnnytwcPxIp3GZXJlk9aHnxNeQGNnf2unHwHF4aJLQ02bjTTDvwHNlbwwMYK+odGeKvhLHsOt/F6fYCdH7SQniZsXLGI29cEV4c5ZT4gkSu5QsoX5VyyPLipo59PrfAlrD2J5LowMcatZtqBD5DjTeeOK5ZwxxVLGB1TftPYFSyjf7iNb7x8mG+8fJiakgVsWhc8rvjqZQWkJai8iz/Qizc9jWUJXDmVleFh6cIsTp7rY2hkjNbuQZY5JGzjzcLEGDMtT5qwobKQDZWF/OmWNZw618eeugB7Drfx9N7jPPXGMYryMrl9TXA47MbqIrK9wbmCeOxpaQj0srI4L+G1yqqKcjl5ro+WrgFUcWUpFbAwMcbMUqUvl4duXM5DNy7nfP8wbx4N8OrhNnZ92Mr/ea+RzPQ0blpVhC/Xy89/08JgjE+V9Ad6WT+pjEmiVPpy2X3oDI2hasHWM3EHm4A3Zv7yczLYdk0Z264pY2hkjP0nO3j1cPBUyabOj68ai/apkv1DIzR3DfDF2vKZb46xKl8OHX1DHG7pBtwbJs5e+xcDtmnRmOjypqdxQ3UR/8/nruCtP7ntsqdKvnCwifaeC/N+z+PtfagmdvI9pHK8evDb/rOkpwlLXHqwmet6JsaY2BGRsHta0gT+848/AODKsoXcsrqYW1YvZn1FQcR7WpywkisktDz41yc6KC3ITvgcTqJYmBhjoircnpa/uudKVi1ZwN6j7ew90j4xib8gM50bqou4paaYm1cXU1Yw8wS2P9CLJ00mzhRJpIrxYa0LI2Ou3WMCFibGmCibaU/LlWX5/F+3VdM9OMwv/WcnwuWVQ2eA4CbEW1YXc0tNMZ+sWkRWxsd3kzcEeqj05eBNT/xIfbbXw5KFWZzpHnRlgccQScZ6PFOJSAXwJHAWOKqq35rpNbW1tfree+/FvG3GmJmpKsfae3nzSDt7j7bzqxMdDI2MkZWRxqdW+MaHxIpZXpTLz3/Twh//5ANGxpQyB5TSf/H9Zv7kZ79laGSMhVnpfGPblUldiXkmInJAVWs/dj3RYSIizwB3AwFVvXLS9S3AdwAP8P3LBYSIbAJWqurfichzqvpvZ3pfCxNjnGtgaJR/PXGOvUfa2Xe0neNng5V5F+VmcH5ghNGxi7+3QmVhEvEL/MX3m8OWqUnVQHFymNwM9ALPhcJERDzAUWAz0ATsB+4nGCzbpzziQWAU+CmgwD+o6t/P9L4WJsYkj9Pn+tnb0M5fvnx4Yv/KZGUF2bzz2Gfi3q4bvvX6tIsNEtWeeAgXJgkfcFTVfUDHlMvXAX5VPa6qQ8CPgG2q+qGq3j3lTwD4feDrqvoZ4K5w7yUiD4vIeyLyXnt7e6x+JGNMlFX4cvjSpyq5ME2QALRM8ws9HsK9b6Lak0gJD5MwyoDGSV83jV8L5xXgj0TkaeBkuJtUdQfw58BBr9cbhWYaY+KpNMxKr3DXY81p7Ukkp4bJdAu1w47HqepHqvp5Vf2qqv7x5R5smxaNSV6P3lFD9pTVXdkZHh69o8bak2BOXRrcBEyuk7AMaInGg62cijHJa6Zlx25vTyIlfAIeQESqgJcnTcCnE5yAvx1oJjgB/4CqHorWe9oEvDHGRM6xE/Ai8jzwLlAjIk0i8pCqjgCPALuBOuDH0QoSEdkqIjvOnz8fjccZY4zBIT2TRLCeiTHGRM6xPZN4s56JMcZEn+vCxFZzGWNM9LkuTKxnYowx0efaORMRaQdOAflAtJNlvs+c6+sjed1s753pvpm+X0SwAGcqiMVnJRHvGY1nzuUZifh8znSPfT4jV6mqxR+7qqqu/gPscNoz5/r6SF4323tnum8W338v0f+NnfLf1SnvGY1nzuUZifh8znSPfT6j98d1w1zTeMmBz5zr6yN53Wzvnem+WPz7c6pE/KxO/HzO9RmJ+HxG+r7JLKE/p2uHuUx8iMh7Os0yQmOcwD6f0WM9ExNrOxLdAGMuwz6fUWI9E2OMMfNmPRNjjDHzZmFijDFm3ixMjDHGzJuFiYkrEblHRL4nIj8Xkc8muj3GTCYia0XkaRH5qYj8QaLbk0wsTMy8icgzIhIQkY+mXN8iIkdExC8ijwGo6ouq+hXgy8DvJqC5xmUi/HzWqepXgS8CtmQ4AhYmJhqeBbZMviAiHuAp4E5gHXC/iKybdMufjX/fmFh7lgg+nyLyOeBt4LX4NjO5WZiYeVPVfUDHlMvXAX5VPa6qQ8CPgG0S9G3gX1T1YLzbatwnks/n+P07VfV64Pfi29Lk5tQz4E3yKwMaJ33dBGwE/hDYBOSLSLWqPp2IxhnXm/bzKSK3AvcCmcCu+DcreVmYmFiRaa6pqn4X+G68G2PMFOE+n28Cb8a3KanBhrlMrDQB5ZO+Xga0JKgtxkxln88oszAxsbIfWCUiy0XEC9wH7Exwm4wJsc9nlFmYmHkTkeeBd4EaEWkSkYdUdQR4BNgN1AE/VtVDiWyncSf7fMaHFXo0xhgzb9YzMcYYM28WJsYYY+bNwsQYY8y8WZgYY4yZNwsTY4wx82ZhYowxZt4sTIwxxsybhYkxCSYir4qIjv+5Nsw93xv//u/Eu33GzIaFiTGJNzlAvhjmntBBTe/FuC3GzIntgDcmgURkJeAnGBKlwKCqrpxyTybQA3Sqakn8W2nMzKxnYkxihXoc+4GfAStEZOpxsdcAGVivxDiYhYkxiTV5+Oon4/88dajLhriM41mYGJNYk4PiHYJnanzhMvcY40gWJsYkiIgIsB4YAA6r6hjBoa4qEblu0q0WJsbxLEyMSZzVQD7wwfj5GjBlqEtEcoC1QIuqtsa/icbMjoWJMYkzXY/jHaAV+MKknosH65UYh7MwMSZxQmFyIHRh0lBXBbARG+IyScLCxJjECRcUk4e6LExMUrBNi8YkgIikAecJ/oVuoaqOTvleEzAK9AJrgMWq2p6IthozG9YzMSYx1gJ5wG8mBwlMDHW9ACwjGCSnLUiM01mYGJMYG8b/N9zw1U8m/bMNcRnHs2EuY4wx82Y9E2OMMfNmYWKMMWbeLEyMMcbMm4WJMcaYebMwMcYYM28WJsYYY+bNwsQYY8y8WZgYY4yZNwsTY4wx82ZhYowxZt7+f1ngSLW3dY5nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_grids = np.array(n_grids)\n",
    "#n_params = (4*n_grids-5)*n_grids\n",
    "n_params = n_grids**2\n",
    "#n_params = (n_grids-1)**2\n",
    "plt.plot(n_params, errors, marker=\"o\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "#plt.ylim(1e-8,10e-5)\n",
    "plt.xlabel(r\"$N$\",fontsize=20)\n",
    "plt.ylabel(\"error\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9201069227039909"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_id = -6\n",
    "end_id = -1\n",
    "\n",
    "(np.log(errors[start_id]) - np.log(errors[end_id]))/(np.log(n_params[start_id])-np.log(n_params[end_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcc3e5b6dc0>]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy\n",
    "\n",
    "start_id = -6\n",
    "end_id = -1\n",
    "loss_w = errors[start_id:end_id]\n",
    "log_ws = np.log(n_params[start_id:end_id])\n",
    "log_loss = np.log(errors[start_id:end_id])\n",
    "\n",
    "reg = LinearRegression().fit(log_ws[:,np.newaxis], log_loss)\n",
    "eps_max = np.min(loss_w)*0.999\n",
    "\n",
    "num_sweep = 10001\n",
    "eps0_sweep = np.linspace(0, eps_max, num=num_sweep)\n",
    "scores = []\n",
    "\n",
    "for i in range(num_sweep):\n",
    "    score = np.abs(scipy.stats.pearsonr(log_ws, np.log(loss_w-eps0_sweep[i]))[0])\n",
    "    scores.append(score)\n",
    "    \n",
    "plt.plot(eps0_sweep, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "-1.9184066707629372\n",
      "0.0033148606783546743\n"
     ]
    }
   ],
   "source": [
    "max_id = np.argmax(scores)\n",
    "eps0 = eps0_sweep[max_id]\n",
    "reg.fit(log_ws[:,np.newaxis], np.log(loss_w-eps0))\n",
    "alpha = reg.coef_[0]\n",
    "A = np.e**reg.intercept_\n",
    "print(max_id)\n",
    "print(eps0)\n",
    "print(alpha)\n",
    "print(A)\n",
    "#[eps0, A, alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 5.549117469329293e-23\n",
       " hess_inv: array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])\n",
       "      jac: array([1.49027668e-08, 9.45245568e-18, 2.01377313e-19])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 236\n",
       "      nit: 0\n",
       "     njev: 56\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([ 0.        ,  0.00331486, -1.91840667])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def f(x):\n",
    "    eps0 = x[0]\n",
    "    A = x[1]\n",
    "    alpha = x[2]\n",
    "    return np.mean((loss_w-(A*n_params[start_id:end_id]**alpha+eps0))**2)\n",
    "\n",
    "x0 = np.array([eps0, A, alpha])\n",
    "sol = minimize(f, x0, tol=1e-32, options={'gtol':1e-30})\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "# Doubt: NN may have bad landscapes. BFGS may perform worse than Adam at high loss.\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Define Transformer\n",
    "\n",
    "\n",
    "# (t,rho,z) -> (t',rho',z')\n",
    "class T(nn.Module):\n",
    "    def __init__(self,w=256,a=0.,M=1.):\n",
    "        super(T, self).__init__()\n",
    "        self.l1 = nn.Linear(2,w)\n",
    "        self.l2 = nn.Linear(w,w)\n",
    "        self.l3 = nn.Linear(w,4)\n",
    "        self.a = a\n",
    "        self.M = torch.nn.Parameter(torch.ones(1,)*1., requires_grad=False)\n",
    "        self.eps = torch.nn.Parameter(torch.ones(1,)*0.01, requires_grad=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        # These non-polynomial activation function may not lead to power laws\n",
    "        #f = nn.Tanh()\n",
    "        #f = nn.SiLU()\n",
    "        #f = Rational()\n",
    "        f = nn.ReLU()\n",
    "        self.t = x[:,[0]]\n",
    "        self.x = x[:,[1]]\n",
    "        self.y = x[:,[2]]\n",
    "        self.z = x[:,[3]]\n",
    "        self.r = torch.sqrt(self.x**2+self.y**2+self.z**2)\n",
    "        self.u = torch.sqrt(self.r/(2*self.M))\n",
    "\n",
    "        self.rho = torch.unsqueeze(torch.sqrt(x[:,1]**2+x[:,2]**2),dim=1)\n",
    "        self.rhoz = torch.transpose(torch.stack([self.rho,self.z]),0,1)[:,:,0]\n",
    "        \n",
    "        self.x1 = f(self.l1(self.rhoz))\n",
    "        self.x2 = f(self.l2(self.x1))**2\n",
    "        self.x3 = self.l3(self.x2)\n",
    "\n",
    "        self.dt = self.x3[:,[0]]\n",
    "        self.drho = self.x3[:,[1]]\n",
    "        self.dphi = self.x3[:,[2]]\n",
    "        self.dz = self.x3[:,[3]]\n",
    "        nn_out = torch.empty((x.shape[0], 4), requires_grad=False)\n",
    "        nn_out[:,[0]] = self.dt\n",
    "        nn_out[:,[1]] = (-self.y*self.dphi+self.x*self.drho)\n",
    "        nn_out[:,[2]] = (self.x*self.dphi+self.y*self.drho)\n",
    "        nn_out[:,[3]] = self.dz*self.z\n",
    "\n",
    "        return x + self.eps.unsqueeze(dim=0)*nn_out\n",
    "    \n",
    "    def set_a(self,a):\n",
    "        self.a = a\n",
    "        \n",
    "    def batch_jacobian(self, func, x, create_graph=False):\n",
    "        # x in shape (Batch, Length)\n",
    "        def _func_sum(x):\n",
    "            return func(x).sum(dim=0)\n",
    "        return torch.autograd.functional.jacobian(_func_sum, x, create_graph=create_graph).permute(1,0,2)\n",
    "    \n",
    "    def transform_g(self, x):\n",
    "        jac_ts = self.batch_jacobian(self.forward, x, create_graph=True)\n",
    "        jac_inv_ts = torch.inverse(jac_ts)\n",
    "        return torch.matmul(torch.matmul(jac_inv_ts.permute(0,2,1), g(x)),jac_inv_ts)\n",
    "        \n",
    "    def jac(self, x):\n",
    "        jac_ts = self.batch_jacobian(self.forward, x, create_graph=True)\n",
    "        return jac_ts\n",
    "    \n",
    "\n",
    "def grow(t1, t2, w_s, w_l):\n",
    "\n",
    "    w_mask = torch.zeros(w_l,w_l)\n",
    "    w_mask[:w_s,:w_s] = torch.ones(w_s,w_s)\n",
    "\n",
    "    b_mask = torch.zeros(w_l,)\n",
    "    b_mask[:w_s] = torch.ones(w_s,)\n",
    "\n",
    "    t2.l2.weight.data = t2.l2.weight.data*w_mask\n",
    "    t2.l2.weight.data[:w_s,:w_s] = t1.l2.weight.data\n",
    "    t2.l2.bias.data = t2.l2.bias.data*b_mask\n",
    "    t2.l2.bias.data[:w_s] = t1.l2.bias.data\n",
    "\n",
    "    t2.l1.weight.data[:w_s,:] = t1.l1.weight.data\n",
    "    t2.l1.bias.data[:w_s] = t1.l1.bias.data\n",
    "\n",
    "    t2.l3.weight.data[:,:w_s] = t1.l3.weight.data\n",
    "    t2.l3.bias.data = t1.l3.bias.data\n",
    "    return t2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "n_train = 1000\n",
    "\n",
    "W = torch.normal(0,1,size=(n_train,4),requires_grad=True)\n",
    "input_ = torch.empty(n_train,4, requires_grad=False)\n",
    "input_[:,0] = (torch.rand(n_train, requires_grad=True)-0.5)*3.0 + 1.5\n",
    "rs = torch.linspace(3,4,steps=n_train+1)[:n_train]\n",
    "input_[:,1:] = W[:,1:]/torch.norm(W[:,1:], dim=1, keepdim=True)*torch.unsqueeze(rs, dim=1)\n",
    "\n",
    "n_test = 1000\n",
    "\n",
    "W_test = torch.normal(0,1,size=(n_test,4),requires_grad=True)\n",
    "input_test_ = torch.empty(n_test,4, requires_grad=False)\n",
    "input_test_[:,0] = (torch.rand(n_test, requires_grad=True)-0.5)*3.0 + 1.5\n",
    "rs_test = torch.linspace(3,4,steps=n_test+1)[:n_test]\n",
    "input_test_[:,1:] = W_test[:,1:]/torch.norm(W_test[:,1:], dim=1, keepdim=True)*torch.unsqueeze(rs_test, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=5\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.840038895607 \n",
      "Epoch:  100 | loss: 0.220892041922 \n",
      "Epoch:  200 | loss: 0.011808759533 \n",
      "Epoch:  300 | loss: 0.007408276200 \n",
      "Epoch:  400 | loss: 0.005450650118 \n",
      "Epoch:  500 | loss: 0.004063544329 \n",
      "Epoch:  600 | loss: 0.003507145448 \n",
      "Epoch:  700 | loss: 0.003068746533 \n",
      "Epoch:  800 | loss: 0.002919696271 \n",
      "Epoch:  900 | loss: 0.002911941381 \n",
      "Epoch:  1000 | loss: 0.002808196237 \n",
      "Epoch:  1100 | loss: 0.002858462976 \n",
      "Epoch:  1200 | loss: 0.002822192619 \n",
      "Epoch:  1300 | loss: 0.003009750741 \n",
      "Epoch:  1400 | loss: 0.003038014984 \n",
      "Epoch:  1500 | loss: 0.003112118924 \n",
      "Epoch:  1600 | loss: 0.003081937321 \n",
      "Epoch:  1700 | loss: 0.003082874231 \n",
      "Epoch:  1800 | loss: 0.003016611096 \n",
      "Epoch:  1900 | loss: 0.002996519208 \n",
      "Epoch:  2000 | loss: 0.002950438531 \n",
      "Epoch:  2100 | loss: 0.003023384605 \n",
      "Epoch:  2200 | loss: 0.003028366482 \n",
      "Epoch:  2300 | loss: 0.003080296330 \n",
      "Epoch:  2400 | loss: 0.003162111389 \n",
      "Epoch:  2500 | loss: 0.003244433319 \n",
      "Epoch:  2600 | loss: 0.003256468801 \n",
      "Epoch:  2700 | loss: 0.003248866647 \n",
      "Epoch:  2800 | loss: 0.003270122223 \n",
      "Epoch:  2900 | loss: 0.003270407673 \n",
      "Epoch:  3000 | loss: 0.003317234339 \n",
      "Epoch:  3100 | loss: 0.003302074503 \n",
      "Epoch:  3200 | loss: 0.003293103538 \n",
      "Epoch:  3300 | loss: 0.003302888479 \n",
      "Epoch:  3400 | loss: 0.003324134508 \n",
      "Epoch:  3500 | loss: 0.003280750709 \n",
      "Epoch:  3600 | loss: 0.003163587069 \n",
      "Epoch:  3700 | loss: 0.003154928330 \n",
      "Epoch:  3800 | loss: 0.003184399800 \n",
      "Epoch:  3900 | loss: 0.003204510314 \n",
      "Epoch:  4000 | loss: 0.003216548124 \n",
      "Epoch:  4100 | loss: 0.003168006428 \n",
      "Epoch:  4200 | loss: 0.002998640295 \n",
      "Epoch:  4300 | loss: 0.002141318051 \n",
      "Epoch:  4400 | loss: 0.000702480029 \n",
      "Epoch:  4500 | loss: 0.000343836116 \n",
      "Epoch:  4600 | loss: 0.000244916184 \n",
      "Epoch:  4700 | loss: 0.000243314789 \n",
      "Epoch:  4800 | loss: 0.000243114890 \n",
      "Epoch:  4900 | loss: 0.000243734976 \n",
      "Epoch:  5000 | loss: 0.000247419666 \n",
      "Epoch:  5100 | loss: 0.000260179717 \n",
      "Epoch:  5200 | loss: 0.000271787925 \n",
      "Epoch:  5300 | loss: 0.000276777777 \n",
      "Epoch:  5400 | loss: 0.000280741166 \n",
      "Epoch:  5500 | loss: 0.000283645844 \n",
      "Epoch:  5600 | loss: 0.000285059679 \n",
      "Epoch:  5700 | loss: 0.000282261230 \n",
      "Epoch:  5800 | loss: 0.000281683548 \n",
      "Epoch:  5900 | loss: 0.000281171146 \n",
      "Epoch:  6000 | loss: 0.000284225825 \n",
      "Epoch:  6100 | loss: 0.000289444200 \n",
      "Epoch:  6200 | loss: 0.000289160875 \n",
      "Epoch:  6300 | loss: 0.000288922893 \n",
      "Epoch:  6400 | loss: 0.000290837401 \n",
      "Epoch:  6500 | loss: 0.000290595635 \n",
      "Epoch:  6600 | loss: 0.000294117897 \n",
      "Epoch:  6700 | loss: 0.000297057471 \n",
      "Epoch:  6800 | loss: 0.000296798768 \n",
      "Epoch:  6900 | loss: 0.000296539685 \n",
      "Epoch:  7000 | loss: 0.000302848464 \n",
      "Epoch:  7100 | loss: 0.000319362531 \n",
      "Epoch:  7200 | loss: 0.000319156679 \n",
      "Epoch:  7300 | loss: 0.000324441324 \n",
      "Epoch:  7400 | loss: 0.000334379554 \n",
      "Epoch:  7500 | loss: 0.000348931324 \n",
      "Epoch:  7600 | loss: 0.000357877318 \n",
      "Epoch:  7700 | loss: 0.000376778946 \n",
      "Epoch:  7800 | loss: 0.000387026521 \n",
      "Epoch:  7900 | loss: 0.000386335625 \n",
      "Epoch:  8000 | loss: 0.000397827796 \n",
      "Epoch:  8100 | loss: 0.000423135643 \n",
      "Epoch:  8200 | loss: 0.000360743637 \n",
      "Epoch:  8300 | loss: 0.000354594231 \n",
      "Epoch:  8400 | loss: 0.000370457012 \n",
      "Epoch:  8500 | loss: 0.000371326489 \n",
      "Epoch:  8600 | loss: 0.000385673047 \n",
      "Epoch:  8700 | loss: 0.000400037592 \n",
      "Epoch:  8800 | loss: 0.000408602325 \n",
      "Epoch:  8900 | loss: 0.000432242872 \n",
      "Epoch:  9000 | loss: 0.000487152836 \n",
      "Epoch:  9100 | loss: 0.000486775360 \n",
      "Epoch:  9200 | loss: 0.000480715069 \n",
      "Epoch:  9300 | loss: 0.000479188166 \n",
      "Epoch:  9400 | loss: 0.000479576382 \n",
      "Epoch:  9500 | loss: 0.000479150302 \n",
      "Epoch:  9600 | loss: 0.000461401360 \n",
      "Epoch:  9700 | loss: 0.000471783744 \n",
      "Epoch:  9800 | loss: 0.000471468607 \n",
      "Epoch:  9900 | loss: 0.000469029066 \n",
      "Epoch:  10000 | loss: 0.000443607394 \n",
      "Epoch:  10100 | loss: 0.000445477694 \n",
      "Epoch:  10200 | loss: 0.000445067446 \n",
      "Epoch:  10300 | loss: 0.000441080861 \n",
      "Epoch:  10400 | loss: 0.000431674416 \n",
      "Epoch:  10500 | loss: 0.000413705391 \n",
      "Epoch:  10600 | loss: 0.000405638391 \n",
      "Epoch:  10700 | loss: 0.000402626145 \n",
      "Epoch:  10800 | loss: 0.000397738913 \n",
      "Epoch:  10900 | loss: 0.000391455978 \n",
      "Epoch:  11000 | loss: 0.000385002670 \n",
      "Epoch:  11100 | loss: 0.000368374982 \n",
      "Epoch:  11200 | loss: 0.000357148383 \n",
      "Epoch:  11300 | loss: 0.000341744104 \n",
      "Epoch:  11400 | loss: 0.000326874200 \n",
      "Epoch:  11500 | loss: 0.000287301489 \n",
      "Epoch:  11600 | loss: 0.000258921471 \n",
      "Epoch:  11700 | loss: 0.000242214446 \n",
      "Epoch:  11800 | loss: 0.000223327370 \n",
      "Epoch:  11900 | loss: 0.000220966584 \n",
      "Epoch:  12000 | loss: 0.000198358262 \n",
      "Epoch:  12100 | loss: 0.000185134777 \n",
      "Epoch:  12200 | loss: 0.000171289998 \n",
      "Epoch:  12300 | loss: 0.000149321379 \n",
      "Epoch:  12400 | loss: 0.000141857628 \n",
      "Epoch:  12500 | loss: 0.000133757771 \n",
      "Epoch:  12600 | loss: 0.000130498927 \n",
      "Epoch:  12700 | loss: 0.000122277459 \n",
      "Epoch:  12800 | loss: 0.000115462542 \n",
      "Epoch:  12900 | loss: 0.000108522981 \n",
      "Epoch:  13000 | loss: 0.000107009728 \n",
      "Epoch:  13100 | loss: 0.000102670943 \n",
      "Epoch:  13200 | loss: 0.000098648074 \n",
      "Epoch:  13300 | loss: 0.000094015733 \n",
      "Epoch:  13400 | loss: 0.000092670874 \n",
      "Epoch:  13500 | loss: 0.000092276860 \n",
      "Epoch:  13600 | loss: 0.000091873779 \n",
      "Epoch:  13700 | loss: 0.000091212481 \n",
      "Epoch:  13800 | loss: 0.000090900299 \n",
      "Epoch:  13900 | loss: 0.000089841196 \n",
      "Epoch:  14000 | loss: 0.000088239140 \n",
      "Epoch:  14100 | loss: 0.000087841421 \n",
      "Epoch:  14200 | loss: 0.000087581451 \n",
      "Epoch:  14300 | loss: 0.000087431712 \n",
      "Epoch:  14400 | loss: 0.000087378627 \n",
      "Epoch:  14500 | loss: 0.000087200191 \n",
      "Epoch:  14600 | loss: 0.000086900116 \n",
      "Epoch:  14700 | loss: 0.000086713379 \n",
      "Epoch:  14800 | loss: 0.000086207074 \n",
      "Epoch:  14900 | loss: 0.000086083113 \n",
      "time=307.22954392433167\n",
      "best_train_loss=8.59807405504398e-05\n",
      "test_loss=9.117241279454902e-05\n",
      "best_epoch=14999\n",
      "w=10\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000085980006 \n",
      "Epoch:  100 | loss: 0.000068629197 \n",
      "Epoch:  200 | loss: 0.000051902367 \n",
      "Epoch:  300 | loss: 0.000049228533 \n",
      "Epoch:  400 | loss: 0.000045925881 \n",
      "Epoch:  500 | loss: 0.000045846667 \n",
      "Epoch:  600 | loss: 0.000041443851 \n",
      "Epoch:  700 | loss: 0.000040045863 \n",
      "Epoch:  800 | loss: 0.000039307393 \n",
      "Epoch:  900 | loss: 0.000037391332 \n",
      "Epoch:  1000 | loss: 0.000039998649 \n",
      "Epoch:  1100 | loss: 0.000033929711 \n",
      "Epoch:  1200 | loss: 0.000030967334 \n",
      "Epoch:  1300 | loss: 0.000029601561 \n",
      "Epoch:  1400 | loss: 0.000027674943 \n",
      "Epoch:  1500 | loss: 0.000026578316 \n",
      "Epoch:  1600 | loss: 0.000026075279 \n",
      "Epoch:  1700 | loss: 0.000030682746 \n",
      "Epoch:  1800 | loss: 0.000022250500 \n",
      "Epoch:  1900 | loss: 0.000020569823 \n",
      "Epoch:  2000 | loss: 0.000027011629 \n",
      "Epoch:  2100 | loss: 0.000018519724 \n",
      "Epoch:  2200 | loss: 0.000018202360 \n",
      "Epoch:  2300 | loss: 0.000017385273 \n",
      "Epoch:  2400 | loss: 0.000016902644 \n",
      "Epoch:  2500 | loss: 0.000016529240 \n",
      "Epoch:  2600 | loss: 0.000015838057 \n",
      "Epoch:  2700 | loss: 0.000015109334 \n",
      "Epoch:  2800 | loss: 0.000014828778 \n",
      "Epoch:  2900 | loss: 0.000076438148 \n",
      "Epoch:  3000 | loss: 0.000013753551 \n",
      "Epoch:  3100 | loss: 0.000013568155 \n",
      "Epoch:  3200 | loss: 0.000013306869 \n",
      "Epoch:  3300 | loss: 0.000013222268 \n",
      "Epoch:  3400 | loss: 0.000012936822 \n",
      "Epoch:  3500 | loss: 0.000012792746 \n",
      "Epoch:  3600 | loss: 0.000012546853 \n",
      "Epoch:  3700 | loss: 0.000012066998 \n",
      "Epoch:  3800 | loss: 0.000011422830 \n",
      "Epoch:  3900 | loss: 0.000010847856 \n",
      "Epoch:  4000 | loss: 0.000010524647 \n",
      "Epoch:  4100 | loss: 0.000010130394 \n",
      "Epoch:  4200 | loss: 0.000009767307 \n",
      "Epoch:  4300 | loss: 0.000009597365 \n",
      "Epoch:  4400 | loss: 0.000009385855 \n",
      "Epoch:  4500 | loss: 0.000009224052 \n",
      "Epoch:  4600 | loss: 0.000009070706 \n",
      "Epoch:  4700 | loss: 0.000019804867 \n",
      "Epoch:  4800 | loss: 0.000008770015 \n",
      "Epoch:  4900 | loss: 0.000009364846 \n",
      "Epoch:  5000 | loss: 0.000008778138 \n",
      "Epoch:  5100 | loss: 0.000008773433 \n",
      "Epoch:  5200 | loss: 0.000021666125 \n",
      "Epoch:  5300 | loss: 0.000008696945 \n",
      "Epoch:  5400 | loss: 0.000008760367 \n",
      "Epoch:  5500 | loss: 0.000009269486 \n",
      "Epoch:  5600 | loss: 0.000014387028 \n",
      "Epoch:  5700 | loss: 0.000010017402 \n",
      "Epoch:  5800 | loss: 0.000008436058 \n",
      "Epoch:  5900 | loss: 0.000008365752 \n",
      "Epoch:  6000 | loss: 0.000008455057 \n",
      "Epoch:  6100 | loss: 0.000008391086 \n",
      "Epoch:  6200 | loss: 0.000008346703 \n",
      "Epoch:  6300 | loss: 0.000008296225 \n",
      "Epoch:  6400 | loss: 0.000008247751 \n",
      "Epoch:  6500 | loss: 0.000008206321 \n",
      "Epoch:  6600 | loss: 0.000008201920 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6700 | loss: 0.000008150165 \n",
      "Epoch:  6800 | loss: 0.000008100073 \n",
      "Epoch:  6900 | loss: 0.000008070972 \n",
      "Epoch:  7000 | loss: 0.000008092622 \n",
      "Epoch:  7100 | loss: 0.000008057440 \n",
      "Epoch:  7200 | loss: 0.000008055169 \n",
      "Epoch:  7300 | loss: 0.000008084140 \n",
      "Epoch:  7400 | loss: 0.000008105681 \n",
      "Epoch:  7500 | loss: 0.000008429654 \n",
      "Epoch:  7600 | loss: 0.000009964134 \n",
      "Epoch:  7700 | loss: 0.000008545027 \n",
      "Epoch:  7800 | loss: 0.000009033420 \n",
      "Epoch:  7900 | loss: 0.000008124373 \n",
      "Epoch:  8000 | loss: 0.000008052418 \n",
      "Epoch:  8100 | loss: 0.000008161429 \n",
      "Epoch:  8200 | loss: 0.000008128146 \n",
      "Epoch:  8300 | loss: 0.000008089886 \n",
      "Epoch:  8400 | loss: 0.000008051293 \n",
      "Epoch:  8500 | loss: 0.000008019413 \n",
      "Epoch:  8600 | loss: 0.000008292222 \n",
      "Epoch:  8700 | loss: 0.000008012721 \n",
      "Epoch:  8800 | loss: 0.000007977697 \n",
      "Epoch:  8900 | loss: 0.000007945028 \n",
      "Epoch:  9000 | loss: 0.000007899285 \n",
      "Epoch:  9100 | loss: 0.000007882703 \n",
      "Epoch:  9200 | loss: 0.000007867065 \n",
      "Epoch:  9300 | loss: 0.000007851165 \n",
      "Epoch:  9400 | loss: 0.000007835022 \n",
      "Epoch:  9500 | loss: 0.000007818551 \n",
      "Epoch:  9600 | loss: 0.000007801720 \n",
      "Epoch:  9700 | loss: 0.000007784784 \n",
      "Epoch:  9800 | loss: 0.000007851215 \n",
      "Epoch:  9900 | loss: 0.000007830083 \n",
      "Epoch:  10000 | loss: 0.000007857259 \n",
      "Epoch:  10100 | loss: 0.000007942820 \n",
      "Epoch:  10200 | loss: 0.000008038223 \n",
      "Epoch:  10300 | loss: 0.000008018340 \n",
      "Epoch:  10400 | loss: 0.000008014839 \n",
      "Epoch:  10500 | loss: 0.000007989591 \n",
      "Epoch:  10600 | loss: 0.000008138365 \n",
      "Epoch:  10700 | loss: 0.000008043314 \n",
      "Epoch:  10800 | loss: 0.000008027261 \n",
      "Epoch:  10900 | loss: 0.000008341218 \n",
      "Epoch:  11000 | loss: 0.000008292369 \n",
      "Epoch:  11100 | loss: 0.000008479861 \n",
      "Epoch:  11200 | loss: 0.000008313134 \n",
      "Epoch:  11300 | loss: 0.000008339390 \n",
      "Epoch:  11400 | loss: 0.000008288315 \n",
      "Epoch:  11500 | loss: 0.000008299255 \n",
      "Epoch:  11600 | loss: 0.000008917457 \n",
      "Epoch:  11700 | loss: 0.000008235617 \n",
      "Epoch:  11800 | loss: 0.000008191344 \n",
      "Epoch:  11900 | loss: 0.000008131602 \n",
      "Epoch:  12000 | loss: 0.000008266318 \n",
      "Epoch:  12100 | loss: 0.000008292256 \n",
      "Epoch:  12200 | loss: 0.000008279177 \n",
      "Epoch:  12300 | loss: 0.000008266770 \n",
      "Epoch:  12400 | loss: 0.000008224485 \n",
      "Epoch:  12500 | loss: 0.000008226915 \n",
      "Epoch:  12600 | loss: 0.000008210530 \n",
      "Epoch:  12700 | loss: 0.000008195496 \n",
      "Epoch:  12800 | loss: 0.000008250816 \n",
      "Epoch:  12900 | loss: 0.000008220127 \n",
      "Epoch:  13000 | loss: 0.000008205782 \n",
      "Epoch:  13100 | loss: 0.000008191630 \n",
      "Epoch:  13200 | loss: 0.000008265756 \n",
      "Epoch:  13300 | loss: 0.000008241693 \n",
      "Epoch:  13400 | loss: 0.000008351120 \n",
      "Epoch:  13500 | loss: 0.000008317296 \n",
      "Epoch:  13600 | loss: 0.000008398449 \n",
      "Epoch:  13700 | loss: 0.000008285539 \n",
      "Epoch:  13800 | loss: 0.000008370433 \n",
      "Epoch:  13900 | loss: 0.000008346196 \n",
      "Epoch:  14000 | loss: 0.000008326459 \n",
      "Epoch:  14100 | loss: 0.000008295966 \n",
      "Epoch:  14200 | loss: 0.000008305899 \n",
      "Epoch:  14300 | loss: 0.000008265981 \n",
      "Epoch:  14400 | loss: 0.000008267262 \n",
      "Epoch:  14500 | loss: 0.000008248413 \n",
      "Epoch:  14600 | loss: 0.000008443084 \n",
      "Epoch:  14700 | loss: 0.000008726404 \n",
      "Epoch:  14800 | loss: 0.000008611868 \n",
      "Epoch:  14900 | loss: 0.000008803447 \n",
      "time=327.1101429462433\n",
      "best_train_loss=7.777092832839116e-06\n",
      "test_loss=1.0152714821742848e-05\n",
      "best_epoch=9744\n",
      "w=15\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000008726838 \n",
      "Epoch:  100 | loss: 0.000009098837 \n",
      "Epoch:  200 | loss: 0.000008639013 \n",
      "Epoch:  300 | loss: 0.000008423023 \n",
      "Epoch:  400 | loss: 0.000008217860 \n",
      "Epoch:  500 | loss: 0.000008002427 \n",
      "Epoch:  600 | loss: 0.000007933281 \n",
      "Epoch:  700 | loss: 0.000017181350 \n",
      "Epoch:  800 | loss: 0.000007504212 \n",
      "Epoch:  900 | loss: 0.000007539685 \n",
      "Epoch:  1000 | loss: 0.000007024396 \n",
      "Epoch:  1100 | loss: 0.000006824063 \n",
      "Epoch:  1200 | loss: 0.000006429452 \n",
      "Epoch:  1300 | loss: 0.000006351709 \n",
      "Epoch:  1400 | loss: 0.000006056107 \n",
      "Epoch:  1500 | loss: 0.000005891258 \n",
      "Epoch:  1600 | loss: 0.000005583994 \n",
      "Epoch:  1700 | loss: 0.000005281266 \n",
      "Epoch:  1800 | loss: 0.000078703044 \n",
      "Epoch:  1900 | loss: 0.000004906621 \n",
      "Epoch:  2000 | loss: 0.000006502313 \n",
      "Epoch:  2100 | loss: 0.000004265150 \n",
      "Epoch:  2200 | loss: 0.000004063020 \n",
      "Epoch:  2300 | loss: 0.000004173393 \n",
      "Epoch:  2400 | loss: 0.000003874603 \n",
      "Epoch:  2500 | loss: 0.000004160418 \n",
      "Epoch:  2600 | loss: 0.000003661302 \n",
      "Epoch:  2700 | loss: 0.000003599996 \n",
      "Epoch:  2800 | loss: 0.000005525431 \n",
      "Epoch:  2900 | loss: 0.000003798516 \n",
      "Epoch:  3000 | loss: 0.000003677383 \n",
      "Epoch:  3100 | loss: 0.000003570233 \n",
      "Epoch:  3200 | loss: 0.000003514335 \n",
      "Epoch:  3300 | loss: 0.000003469454 \n",
      "Epoch:  3400 | loss: 0.000003427414 \n",
      "Epoch:  3500 | loss: 0.000003465489 \n",
      "Epoch:  3600 | loss: 0.000003409147 \n",
      "Epoch:  3700 | loss: 0.000003358819 \n",
      "Epoch:  3800 | loss: 0.000003328233 \n",
      "Epoch:  3900 | loss: 0.000003208484 \n",
      "Epoch:  4000 | loss: 0.000003139305 \n",
      "Epoch:  4100 | loss: 0.000003039142 \n",
      "Epoch:  4200 | loss: 0.000002920148 \n",
      "Epoch:  4300 | loss: 0.000002780790 \n",
      "Epoch:  4400 | loss: 0.000002900640 \n",
      "Epoch:  4500 | loss: 0.000006648050 \n",
      "Epoch:  4600 | loss: 0.000002707086 \n",
      "Epoch:  4700 | loss: 0.000002651562 \n",
      "Epoch:  4800 | loss: 0.000003207015 \n",
      "Epoch:  4900 | loss: 0.000002766661 \n",
      "Epoch:  5000 | loss: 0.000004129088 \n",
      "Epoch:  5100 | loss: 0.000005262371 \n",
      "Epoch:  5200 | loss: 0.000002526210 \n",
      "Epoch:  5300 | loss: 0.000002830740 \n",
      "Epoch:  5400 | loss: 0.000002531774 \n",
      "Epoch:  5500 | loss: 0.000003044701 \n",
      "Epoch:  5600 | loss: 0.000002490096 \n",
      "Epoch:  5700 | loss: 0.000002472431 \n",
      "Epoch:  5800 | loss: 0.000002634006 \n",
      "Epoch:  5900 | loss: 0.000002922991 \n",
      "Epoch:  6000 | loss: 0.000002577775 \n",
      "Epoch:  6100 | loss: 0.000002402521 \n",
      "Epoch:  6200 | loss: 0.000002390129 \n",
      "Epoch:  6300 | loss: 0.000002378892 \n",
      "Epoch:  6400 | loss: 0.000002363098 \n",
      "Epoch:  6500 | loss: 0.000002347781 \n",
      "Epoch:  6600 | loss: 0.000002335449 \n",
      "Epoch:  6700 | loss: 0.000002355756 \n",
      "Epoch:  6800 | loss: 0.000002341333 \n",
      "Epoch:  6900 | loss: 0.000002327521 \n",
      "Epoch:  7000 | loss: 0.000002313986 \n",
      "Epoch:  7100 | loss: 0.000002324825 \n",
      "Epoch:  7200 | loss: 0.000002312500 \n",
      "Epoch:  7300 | loss: 0.000002293158 \n",
      "Epoch:  7400 | loss: 0.000002282531 \n",
      "Epoch:  7500 | loss: 0.000002700889 \n",
      "Epoch:  7600 | loss: 0.000002245556 \n",
      "Epoch:  7700 | loss: 0.000002297400 \n",
      "Epoch:  7800 | loss: 0.000002245775 \n",
      "Epoch:  7900 | loss: 0.000002225065 \n",
      "Epoch:  8000 | loss: 0.000002230380 \n",
      "Epoch:  8100 | loss: 0.000002414541 \n",
      "Epoch:  8200 | loss: 0.000002238086 \n",
      "Epoch:  8300 | loss: 0.000002957928 \n",
      "Epoch:  8400 | loss: 0.000002200555 \n",
      "Epoch:  8500 | loss: 0.000002210680 \n",
      "Epoch:  8600 | loss: 0.000002166163 \n",
      "Epoch:  8700 | loss: 0.000002218721 \n",
      "Epoch:  8800 | loss: 0.000002163286 \n",
      "Epoch:  8900 | loss: 0.000002161371 \n",
      "Epoch:  9000 | loss: 0.000002154633 \n",
      "Epoch:  9100 | loss: 0.000002151412 \n",
      "Epoch:  9200 | loss: 0.000002147975 \n",
      "Epoch:  9300 | loss: 0.000002129978 \n",
      "Epoch:  9400 | loss: 0.000002120427 \n",
      "Epoch:  9500 | loss: 0.000002119871 \n",
      "Epoch:  9600 | loss: 0.000002104900 \n",
      "Epoch:  9700 | loss: 0.000002094506 \n",
      "Epoch:  9800 | loss: 0.000002084299 \n",
      "Epoch:  9900 | loss: 0.000002061690 \n",
      "Epoch:  10000 | loss: 0.000002043563 \n",
      "Epoch:  10100 | loss: 0.000002029415 \n",
      "Epoch:  10200 | loss: 0.000002019505 \n",
      "Epoch:  10300 | loss: 0.000002006042 \n",
      "Epoch:  10400 | loss: 0.000002021880 \n",
      "Epoch:  10500 | loss: 0.000002003499 \n",
      "Epoch:  10600 | loss: 0.000001999237 \n",
      "Epoch:  10700 | loss: 0.000002115671 \n",
      "Epoch:  10800 | loss: 0.000001973734 \n",
      "Epoch:  10900 | loss: 0.000001971919 \n",
      "Epoch:  11000 | loss: 0.000001956592 \n",
      "Epoch:  11100 | loss: 0.000001952920 \n",
      "Epoch:  11200 | loss: 0.000001944399 \n",
      "Epoch:  11300 | loss: 0.000001938764 \n",
      "Epoch:  11400 | loss: 0.000001932503 \n",
      "Epoch:  11500 | loss: 0.000001925432 \n",
      "Epoch:  11600 | loss: 0.000003242836 \n",
      "Epoch:  11700 | loss: 0.000001909801 \n",
      "Epoch:  11800 | loss: 0.000001923386 \n",
      "Epoch:  11900 | loss: 0.000001929027 \n",
      "Epoch:  12000 | loss: 0.000001919995 \n",
      "Epoch:  12100 | loss: 0.000001915825 \n",
      "Epoch:  12200 | loss: 0.000001913226 \n",
      "Epoch:  12300 | loss: 0.000001910715 \n",
      "Epoch:  12400 | loss: 0.000001908231 \n",
      "Epoch:  12500 | loss: 0.000001909109 \n",
      "Epoch:  12600 | loss: 0.000001906783 \n",
      "Epoch:  12700 | loss: 0.000001903967 \n",
      "Epoch:  12800 | loss: 0.000001898996 \n",
      "Epoch:  12900 | loss: 0.000001895998 \n",
      "Epoch:  13000 | loss: 0.000001894005 \n",
      "Epoch:  13100 | loss: 0.000001891160 \n",
      "Epoch:  13200 | loss: 0.000001888416 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13300 | loss: 0.000001885715 \n",
      "Epoch:  13400 | loss: 0.000001892475 \n",
      "Epoch:  13500 | loss: 0.000001880444 \n",
      "Epoch:  13600 | loss: 0.000001877854 \n",
      "Epoch:  13700 | loss: 0.000001924519 \n",
      "Epoch:  13800 | loss: 0.000001872833 \n",
      "Epoch:  13900 | loss: 0.000001887305 \n",
      "Epoch:  14000 | loss: 0.000001868540 \n",
      "Epoch:  14100 | loss: 0.000001866770 \n",
      "Epoch:  14200 | loss: 0.000001865547 \n",
      "Epoch:  14300 | loss: 0.000001862872 \n",
      "Epoch:  14400 | loss: 0.000001866414 \n",
      "Epoch:  14500 | loss: 0.000001863008 \n",
      "Epoch:  14600 | loss: 0.000001924946 \n",
      "Epoch:  14700 | loss: 0.000001857342 \n",
      "Epoch:  14800 | loss: 0.000001882134 \n",
      "Epoch:  14900 | loss: 0.000001894180 \n",
      "time=359.9884159564972\n",
      "best_train_loss=1.8545358670962742e-06\n",
      "test_loss=2.492193743819371e-06\n",
      "best_epoch=14676\n",
      "w=20\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000001891045 \n",
      "Epoch:  100 | loss: 0.000002785098 \n",
      "Epoch:  200 | loss: 0.000001990082 \n",
      "Epoch:  300 | loss: 0.000001843039 \n",
      "Epoch:  400 | loss: 0.000001814618 \n",
      "Epoch:  500 | loss: 0.000001781878 \n",
      "Epoch:  600 | loss: 0.000001751988 \n",
      "Epoch:  700 | loss: 0.000002633777 \n",
      "Epoch:  800 | loss: 0.000001733863 \n",
      "Epoch:  900 | loss: 0.000006276394 \n",
      "Epoch:  1000 | loss: 0.000001713441 \n",
      "Epoch:  1100 | loss: 0.000025001909 \n",
      "Epoch:  1200 | loss: 0.000001683794 \n",
      "Epoch:  1300 | loss: 0.000001656622 \n",
      "Epoch:  1400 | loss: 0.000001625568 \n",
      "Epoch:  1500 | loss: 0.000001643653 \n",
      "Epoch:  1600 | loss: 0.000002323044 \n",
      "Epoch:  1700 | loss: 0.000001608144 \n",
      "Epoch:  1800 | loss: 0.000013320795 \n",
      "Epoch:  1900 | loss: 0.000001591457 \n",
      "Epoch:  2000 | loss: 0.000066570363 \n",
      "Epoch:  2100 | loss: 0.000001543374 \n",
      "Epoch:  2200 | loss: 0.000001685521 \n",
      "Epoch:  2300 | loss: 0.000002196784 \n",
      "Epoch:  2400 | loss: 0.000001551940 \n",
      "Epoch:  2500 | loss: 0.000005319725 \n",
      "Epoch:  2600 | loss: 0.000001568054 \n",
      "Epoch:  2700 | loss: 0.000009237660 \n",
      "Epoch:  2800 | loss: 0.000001558959 \n",
      "Epoch:  2900 | loss: 0.000006837749 \n",
      "Epoch:  3000 | loss: 0.000001542369 \n",
      "Epoch:  3100 | loss: 0.000001520237 \n",
      "Epoch:  3200 | loss: 0.000001511616 \n",
      "Epoch:  3300 | loss: 0.000001504628 \n",
      "Epoch:  3400 | loss: 0.000001496845 \n",
      "Epoch:  3500 | loss: 0.000001486562 \n",
      "Epoch:  3600 | loss: 0.000001482895 \n",
      "Epoch:  3700 | loss: 0.000001475766 \n",
      "Epoch:  3800 | loss: 0.000001468556 \n",
      "Epoch:  3900 | loss: 0.000001472752 \n",
      "Epoch:  4000 | loss: 0.000001464187 \n",
      "Epoch:  4100 | loss: 0.000001456607 \n",
      "Epoch:  4200 | loss: 0.000001455582 \n",
      "Epoch:  4300 | loss: 0.000001448933 \n",
      "Epoch:  4400 | loss: 0.000001623882 \n",
      "Epoch:  4500 | loss: 0.000001442221 \n",
      "Epoch:  4600 | loss: 0.000003035339 \n",
      "Epoch:  4700 | loss: 0.000001434989 \n",
      "Epoch:  4800 | loss: 0.000010638801 \n",
      "Epoch:  4900 | loss: 0.000001432580 \n",
      "Epoch:  5000 | loss: 0.000001606141 \n",
      "Epoch:  5100 | loss: 0.000002037047 \n",
      "Epoch:  5200 | loss: 0.000005033873 \n",
      "Epoch:  5300 | loss: 0.000001423191 \n",
      "Epoch:  5400 | loss: 0.000001477504 \n",
      "Epoch:  5500 | loss: 0.000001417908 \n",
      "Epoch:  5600 | loss: 0.000001437538 \n",
      "Epoch:  5700 | loss: 0.000001420783 \n",
      "Epoch:  5800 | loss: 0.000001458753 \n",
      "Epoch:  5900 | loss: 0.000001419299 \n",
      "Epoch:  6000 | loss: 0.000001419429 \n",
      "Epoch:  6100 | loss: 0.000001416292 \n",
      "Epoch:  6200 | loss: 0.000001413755 \n",
      "Epoch:  6300 | loss: 0.000001411177 \n",
      "Epoch:  6400 | loss: 0.000001408207 \n",
      "Epoch:  6500 | loss: 0.000001405703 \n",
      "Epoch:  6600 | loss: 0.000001403381 \n",
      "Epoch:  6700 | loss: 0.000001401263 \n",
      "Epoch:  6800 | loss: 0.000001399161 \n",
      "Epoch:  6900 | loss: 0.000001397074 \n",
      "Epoch:  7000 | loss: 0.000001394987 \n",
      "Epoch:  7100 | loss: 0.000001392899 \n",
      "Epoch:  7200 | loss: 0.000001390806 \n",
      "Epoch:  7300 | loss: 0.000001391563 \n",
      "Epoch:  7400 | loss: 0.000001389240 \n",
      "Epoch:  7500 | loss: 0.000001398253 \n",
      "Epoch:  7600 | loss: 0.000001378672 \n",
      "Epoch:  7700 | loss: 0.000001379892 \n",
      "Epoch:  7800 | loss: 0.000001373707 \n",
      "Epoch:  7900 | loss: 0.000001369990 \n",
      "Epoch:  8000 | loss: 0.000002724257 \n",
      "Epoch:  8100 | loss: 0.000001373237 \n",
      "Epoch:  8200 | loss: 0.000001425369 \n",
      "Epoch:  8300 | loss: 0.000001422089 \n",
      "Epoch:  8400 | loss: 0.000001361375 \n",
      "Epoch:  8500 | loss: 0.000001338734 \n",
      "Epoch:  8600 | loss: 0.000001341602 \n",
      "Epoch:  8700 | loss: 0.000001338142 \n",
      "Epoch:  8800 | loss: 0.000001332269 \n",
      "Epoch:  8900 | loss: 0.000001332906 \n",
      "Epoch:  9000 | loss: 0.000001329326 \n",
      "Epoch:  9100 | loss: 0.000001328325 \n",
      "Epoch:  9200 | loss: 0.000001327497 \n",
      "Epoch:  9300 | loss: 0.000001326671 \n",
      "Epoch:  9400 | loss: 0.000001325833 \n",
      "Epoch:  9500 | loss: 0.000001324981 \n",
      "Epoch:  9600 | loss: 0.000001324126 \n",
      "Epoch:  9700 | loss: 0.000001323259 \n",
      "Epoch:  9800 | loss: 0.000001320902 \n",
      "Epoch:  9900 | loss: 0.000001319948 \n",
      "Epoch:  10000 | loss: 0.000001318395 \n",
      "Epoch:  10100 | loss: 0.000001317374 \n",
      "Epoch:  10200 | loss: 0.000001316368 \n",
      "Epoch:  10300 | loss: 0.000001315354 \n",
      "Epoch:  10400 | loss: 0.000001314448 \n",
      "Epoch:  10500 | loss: 0.000001332196 \n",
      "Epoch:  10600 | loss: 0.000001436766 \n",
      "Epoch:  10700 | loss: 0.000001311243 \n",
      "Epoch:  10800 | loss: 0.000001310511 \n",
      "Epoch:  10900 | loss: 0.000001311271 \n",
      "Epoch:  11000 | loss: 0.000001361016 \n",
      "Epoch:  11100 | loss: 0.000001307496 \n",
      "Epoch:  11200 | loss: 0.000001307490 \n",
      "Epoch:  11300 | loss: 0.000001306058 \n",
      "Epoch:  11400 | loss: 0.000001356948 \n",
      "Epoch:  11500 | loss: 0.000001529458 \n",
      "Epoch:  11600 | loss: 0.000001303069 \n",
      "Epoch:  11700 | loss: 0.000001321064 \n",
      "Epoch:  11800 | loss: 0.000001301490 \n",
      "Epoch:  11900 | loss: 0.000001348411 \n",
      "Epoch:  12000 | loss: 0.000001303317 \n",
      "Epoch:  12100 | loss: 0.000001302789 \n",
      "Epoch:  12200 | loss: 0.000001302282 \n",
      "Epoch:  12300 | loss: 0.000001301774 \n",
      "Epoch:  12400 | loss: 0.000001301251 \n",
      "Epoch:  12500 | loss: 0.000001300708 \n",
      "Epoch:  12600 | loss: 0.000001300157 \n",
      "Epoch:  12700 | loss: 0.000001299587 \n",
      "Epoch:  12800 | loss: 0.000001298998 \n",
      "Epoch:  12900 | loss: 0.000001298373 \n",
      "Epoch:  13000 | loss: 0.000001297739 \n",
      "Epoch:  13100 | loss: 0.000001297085 \n",
      "Epoch:  13200 | loss: 0.000001296410 \n",
      "Epoch:  13300 | loss: 0.000001295687 \n",
      "Epoch:  13400 | loss: 0.000001294958 \n",
      "Epoch:  13500 | loss: 0.000001294781 \n",
      "Epoch:  13600 | loss: 0.000001293528 \n",
      "Epoch:  13700 | loss: 0.000001311697 \n",
      "Epoch:  13800 | loss: 0.000001292168 \n",
      "Epoch:  13900 | loss: 0.000001293896 \n",
      "Epoch:  14000 | loss: 0.000001292251 \n",
      "Epoch:  14100 | loss: 0.000001291495 \n",
      "Epoch:  14200 | loss: 0.000001304497 \n",
      "Epoch:  14300 | loss: 0.000001337493 \n",
      "Epoch:  14400 | loss: 0.000001289260 \n",
      "Epoch:  14500 | loss: 0.000001290065 \n",
      "Epoch:  14600 | loss: 0.000001289992 \n",
      "Epoch:  14700 | loss: 0.000001293122 \n",
      "Epoch:  14800 | loss: 0.000001309191 \n",
      "Epoch:  14900 | loss: 0.000001293001 \n",
      "time=367.1665589809418\n",
      "best_train_loss=1.2853864745920873e-06\n",
      "test_loss=1.921097236845526e-06\n",
      "best_epoch=14949\n",
      "w=25\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000001285573 \n",
      "Epoch:  100 | loss: 0.000003176844 \n",
      "Epoch:  200 | loss: 0.000001714409 \n",
      "Epoch:  300 | loss: 0.000001392089 \n",
      "Epoch:  400 | loss: 0.000001308471 \n",
      "Epoch:  500 | loss: 0.000001270837 \n",
      "Epoch:  600 | loss: 0.000001247683 \n",
      "Epoch:  700 | loss: 0.000001233336 \n",
      "Epoch:  800 | loss: 0.000001224631 \n",
      "Epoch:  900 | loss: 0.000001212447 \n",
      "Epoch:  1000 | loss: 0.000001220694 \n",
      "Epoch:  1100 | loss: 0.000001214727 \n",
      "Epoch:  1200 | loss: 0.000001202098 \n",
      "Epoch:  1300 | loss: 0.000001306805 \n",
      "Epoch:  1400 | loss: 0.000001191092 \n",
      "Epoch:  1500 | loss: 0.000001150959 \n",
      "Epoch:  1600 | loss: 0.000001197582 \n",
      "Epoch:  1700 | loss: 0.000001290441 \n",
      "Epoch:  1800 | loss: 0.000001361412 \n",
      "Epoch:  1900 | loss: 0.000002091570 \n",
      "Epoch:  2000 | loss: 0.000001804113 \n",
      "Epoch:  2100 | loss: 0.000001133193 \n",
      "Epoch:  2200 | loss: 0.000001755891 \n",
      "Epoch:  2300 | loss: 0.000016835067 \n",
      "Epoch:  2400 | loss: 0.000001161067 \n",
      "Epoch:  2500 | loss: 0.000001824065 \n",
      "Epoch:  2600 | loss: 0.000002104043 \n",
      "Epoch:  2700 | loss: 0.000001097492 \n",
      "Epoch:  2800 | loss: 0.000001192091 \n",
      "Epoch:  2900 | loss: 0.000015823169 \n",
      "Epoch:  3000 | loss: 0.000001111141 \n",
      "Epoch:  3100 | loss: 0.000001076887 \n",
      "Epoch:  3200 | loss: 0.000001074075 \n",
      "Epoch:  3300 | loss: 0.000001068572 \n",
      "Epoch:  3400 | loss: 0.000001061058 \n",
      "Epoch:  3500 | loss: 0.000001054164 \n",
      "Epoch:  3600 | loss: 0.000001047627 \n",
      "Epoch:  3700 | loss: 0.000001042403 \n",
      "Epoch:  3800 | loss: 0.000001036858 \n",
      "Epoch:  3900 | loss: 0.000001030999 \n",
      "Epoch:  4000 | loss: 0.000001016519 \n",
      "Epoch:  4100 | loss: 0.000001008999 \n",
      "Epoch:  4200 | loss: 0.000001004102 \n",
      "Epoch:  4300 | loss: 0.000000998258 \n",
      "Epoch:  4400 | loss: 0.000008465752 \n",
      "Epoch:  4500 | loss: 0.000000998324 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4600 | loss: 0.000001399010 \n",
      "Epoch:  4700 | loss: 0.000001000815 \n",
      "Epoch:  4800 | loss: 0.000001009101 \n",
      "Epoch:  4900 | loss: 0.000002142779 \n",
      "Epoch:  5000 | loss: 0.000001374187 \n",
      "Epoch:  5100 | loss: 0.000001372319 \n",
      "Epoch:  5200 | loss: 0.000001432476 \n",
      "Epoch:  5300 | loss: 0.000003879204 \n",
      "Epoch:  5400 | loss: 0.000000987424 \n",
      "Epoch:  5500 | loss: 0.000001626799 \n",
      "Epoch:  5600 | loss: 0.000001027678 \n",
      "Epoch:  5700 | loss: 0.000001023314 \n",
      "Epoch:  5800 | loss: 0.000004111606 \n",
      "Epoch:  5900 | loss: 0.000000979394 \n",
      "Epoch:  6000 | loss: 0.000001049677 \n",
      "Epoch:  6100 | loss: 0.000000967277 \n",
      "Epoch:  6200 | loss: 0.000000958037 \n",
      "Epoch:  6300 | loss: 0.000000952177 \n",
      "Epoch:  6400 | loss: 0.000000949772 \n",
      "Epoch:  6500 | loss: 0.000000948073 \n",
      "Epoch:  6600 | loss: 0.000000945154 \n",
      "Epoch:  6700 | loss: 0.000000942250 \n",
      "Epoch:  6800 | loss: 0.000000939306 \n",
      "Epoch:  6900 | loss: 0.000000938254 \n",
      "Epoch:  7000 | loss: 0.000000935307 \n",
      "Epoch:  7100 | loss: 0.000000931896 \n",
      "Epoch:  7200 | loss: 0.000000927038 \n",
      "Epoch:  7300 | loss: 0.000000922664 \n",
      "Epoch:  7400 | loss: 0.000000919699 \n",
      "Epoch:  7500 | loss: 0.000000920044 \n",
      "Epoch:  7600 | loss: 0.000000911706 \n",
      "Epoch:  7700 | loss: 0.000000923449 \n",
      "Epoch:  7800 | loss: 0.000000918160 \n",
      "Epoch:  7900 | loss: 0.000000977179 \n",
      "Epoch:  8000 | loss: 0.000000912817 \n",
      "Epoch:  8100 | loss: 0.000000912859 \n",
      "Epoch:  8200 | loss: 0.000004504686 \n",
      "Epoch:  8300 | loss: 0.000000900884 \n",
      "Epoch:  8400 | loss: 0.000001521747 \n",
      "Epoch:  8500 | loss: 0.000000898316 \n",
      "Epoch:  8600 | loss: 0.000000895137 \n",
      "Epoch:  8700 | loss: 0.000000924080 \n",
      "Epoch:  8800 | loss: 0.000000890777 \n",
      "Epoch:  8900 | loss: 0.000000887358 \n",
      "Epoch:  9000 | loss: 0.000000886101 \n",
      "Epoch:  9100 | loss: 0.000000885410 \n",
      "Epoch:  9200 | loss: 0.000000883824 \n",
      "Epoch:  9300 | loss: 0.000000880738 \n",
      "Epoch:  9400 | loss: 0.000000880702 \n",
      "Epoch:  9500 | loss: 0.000000877291 \n",
      "Epoch:  9600 | loss: 0.000000875886 \n",
      "Epoch:  9700 | loss: 0.000000875422 \n",
      "Epoch:  9800 | loss: 0.000000873311 \n",
      "Epoch:  9900 | loss: 0.000000869774 \n",
      "Epoch:  10000 | loss: 0.000000869997 \n",
      "Epoch:  10100 | loss: 0.000000869260 \n",
      "Epoch:  10200 | loss: 0.000000865860 \n",
      "Epoch:  10300 | loss: 0.000000865339 \n",
      "Epoch:  10400 | loss: 0.000000861440 \n",
      "Epoch:  10500 | loss: 0.000000870497 \n",
      "Epoch:  10600 | loss: 0.000000926465 \n",
      "Epoch:  10700 | loss: 0.000000855575 \n",
      "Epoch:  10800 | loss: 0.000000860288 \n",
      "Epoch:  10900 | loss: 0.000000855448 \n",
      "Epoch:  11000 | loss: 0.000000954615 \n",
      "Epoch:  11100 | loss: 0.000000852389 \n",
      "Epoch:  11200 | loss: 0.000000856858 \n",
      "Epoch:  11300 | loss: 0.000000973496 \n",
      "Epoch:  11400 | loss: 0.000000843845 \n",
      "Epoch:  11500 | loss: 0.000000847042 \n",
      "Epoch:  11600 | loss: 0.000002423270 \n",
      "Epoch:  11700 | loss: 0.000000837592 \n",
      "Epoch:  11800 | loss: 0.000000839177 \n",
      "Epoch:  11900 | loss: 0.000000832587 \n",
      "Epoch:  12000 | loss: 0.000000829350 \n",
      "Epoch:  12100 | loss: 0.000000831070 \n",
      "Epoch:  12200 | loss: 0.000000829087 \n",
      "Epoch:  12300 | loss: 0.000000827844 \n",
      "Epoch:  12400 | loss: 0.000000826909 \n",
      "Epoch:  12500 | loss: 0.000000824632 \n",
      "Epoch:  12600 | loss: 0.000000823963 \n",
      "Epoch:  12700 | loss: 0.000000820467 \n",
      "Epoch:  12800 | loss: 0.000000818202 \n",
      "Epoch:  12900 | loss: 0.000000816750 \n",
      "Epoch:  13000 | loss: 0.000000814472 \n",
      "Epoch:  13100 | loss: 0.000000814855 \n",
      "Epoch:  13200 | loss: 0.000000811645 \n",
      "Epoch:  13300 | loss: 0.000000810306 \n",
      "Epoch:  13400 | loss: 0.000000809399 \n",
      "Epoch:  13500 | loss: 0.000000808205 \n",
      "Epoch:  13600 | loss: 0.000000808887 \n",
      "Epoch:  13700 | loss: 0.000000806099 \n",
      "Epoch:  13800 | loss: 0.000000798479 \n",
      "Epoch:  13900 | loss: 0.000000796895 \n",
      "Epoch:  14000 | loss: 0.000000796581 \n",
      "Epoch:  14100 | loss: 0.000000799568 \n",
      "Epoch:  14200 | loss: 0.000000800952 \n",
      "Epoch:  14300 | loss: 0.000000793082 \n",
      "Epoch:  14400 | loss: 0.000000796721 \n",
      "Epoch:  14500 | loss: 0.000000791882 \n",
      "Epoch:  14600 | loss: 0.000000791650 \n",
      "Epoch:  14700 | loss: 0.000000788964 \n",
      "Epoch:  14800 | loss: 0.000000790562 \n",
      "Epoch:  14900 | loss: 0.000000788951 \n",
      "time=389.9036500453949\n",
      "best_train_loss=7.84932353781187e-07\n",
      "test_loss=1.2692970585703733e-06\n",
      "best_epoch=14995\n",
      "w=30\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000789700 \n",
      "Epoch:  100 | loss: 0.000001783194 \n",
      "Epoch:  200 | loss: 0.000001084007 \n",
      "Epoch:  300 | loss: 0.000000896753 \n",
      "Epoch:  400 | loss: 0.000000853815 \n",
      "Epoch:  500 | loss: 0.000000847343 \n",
      "Epoch:  600 | loss: 0.000000857268 \n",
      "Epoch:  700 | loss: 0.000000866814 \n",
      "Epoch:  800 | loss: 0.000000922397 \n",
      "Epoch:  900 | loss: 0.000000983208 \n",
      "Epoch:  1000 | loss: 0.000000957823 \n",
      "Epoch:  1100 | loss: 0.000002117125 \n",
      "Epoch:  1200 | loss: 0.000004512256 \n",
      "Epoch:  1300 | loss: 0.000001222954 \n",
      "Epoch:  1400 | loss: 0.000000897268 \n",
      "Epoch:  1500 | loss: 0.000071326671 \n",
      "Epoch:  1600 | loss: 0.000001007411 \n",
      "Epoch:  1700 | loss: 0.000000932111 \n",
      "Epoch:  1800 | loss: 0.000008293729 \n",
      "Epoch:  1900 | loss: 0.000048133210 \n",
      "Epoch:  2000 | loss: 0.000000940781 \n",
      "Epoch:  2100 | loss: 0.000000931311 \n",
      "Epoch:  2200 | loss: 0.000000931156 \n",
      "Epoch:  2300 | loss: 0.000000847372 \n",
      "Epoch:  2400 | loss: 0.000000949626 \n",
      "Epoch:  2500 | loss: 0.000000854185 \n",
      "Epoch:  2600 | loss: 0.000000835310 \n",
      "Epoch:  2700 | loss: 0.000001196321 \n",
      "Epoch:  2800 | loss: 0.000005578800 \n",
      "Epoch:  2900 | loss: 0.000003439395 \n",
      "Epoch:  3000 | loss: 0.000001298491 \n",
      "Epoch:  3100 | loss: 0.000000862794 \n",
      "Epoch:  3200 | loss: 0.000000847713 \n",
      "Epoch:  3300 | loss: 0.000000836406 \n",
      "Epoch:  3400 | loss: 0.000000829986 \n",
      "Epoch:  3500 | loss: 0.000000821540 \n",
      "Epoch:  3600 | loss: 0.000000810261 \n",
      "Epoch:  3700 | loss: 0.000000803667 \n",
      "Epoch:  3800 | loss: 0.000000798202 \n",
      "Epoch:  3900 | loss: 0.000000798839 \n",
      "Epoch:  4000 | loss: 0.000000791654 \n",
      "Epoch:  4100 | loss: 0.000000786133 \n",
      "Epoch:  4200 | loss: 0.000000779529 \n",
      "Epoch:  4300 | loss: 0.000000774548 \n",
      "Epoch:  4400 | loss: 0.000000783190 \n",
      "Epoch:  4500 | loss: 0.000000778098 \n",
      "Epoch:  4600 | loss: 0.000000961361 \n",
      "Epoch:  4700 | loss: 0.000000774671 \n",
      "Epoch:  4800 | loss: 0.000011174813 \n",
      "Epoch:  4900 | loss: 0.000000760497 \n",
      "Epoch:  5000 | loss: 0.000000856313 \n",
      "Epoch:  5100 | loss: 0.000001008628 \n",
      "Epoch:  5200 | loss: 0.000000748314 \n",
      "Epoch:  5300 | loss: 0.000000765424 \n",
      "Epoch:  5400 | loss: 0.000002277896 \n",
      "Epoch:  5500 | loss: 0.000001166546 \n",
      "Epoch:  5600 | loss: 0.000002035564 \n",
      "Epoch:  5700 | loss: 0.000012869838 \n",
      "Epoch:  5800 | loss: 0.000000744656 \n",
      "Epoch:  5900 | loss: 0.000000808112 \n",
      "Epoch:  6000 | loss: 0.000000770371 \n",
      "Epoch:  6100 | loss: 0.000000740225 \n",
      "Epoch:  6200 | loss: 0.000000729254 \n",
      "Epoch:  6300 | loss: 0.000000739111 \n",
      "Epoch:  6400 | loss: 0.000000737790 \n",
      "Epoch:  6500 | loss: 0.000000737169 \n",
      "Epoch:  6600 | loss: 0.000000736153 \n",
      "Epoch:  6700 | loss: 0.000000735159 \n",
      "Epoch:  6800 | loss: 0.000000732560 \n",
      "Epoch:  6900 | loss: 0.000000721493 \n",
      "Epoch:  7000 | loss: 0.000000720402 \n",
      "Epoch:  7100 | loss: 0.000000728171 \n",
      "Epoch:  7200 | loss: 0.000000717243 \n",
      "Epoch:  7300 | loss: 0.000000716829 \n",
      "Epoch:  7400 | loss: 0.000000726113 \n",
      "Epoch:  7500 | loss: 0.000000728826 \n",
      "Epoch:  7600 | loss: 0.000000723461 \n",
      "Epoch:  7700 | loss: 0.000000722579 \n",
      "Epoch:  7800 | loss: 0.000000722677 \n",
      "Epoch:  7900 | loss: 0.000006366503 \n",
      "Epoch:  8000 | loss: 0.000000720273 \n",
      "Epoch:  8100 | loss: 0.000003245194 \n",
      "Epoch:  8200 | loss: 0.000000718717 \n",
      "Epoch:  8300 | loss: 0.000000855069 \n",
      "Epoch:  8400 | loss: 0.000000716948 \n",
      "Epoch:  8500 | loss: 0.000001064094 \n",
      "Epoch:  8600 | loss: 0.000000709659 \n",
      "Epoch:  8700 | loss: 0.000000758478 \n",
      "Epoch:  8800 | loss: 0.000000879251 \n",
      "Epoch:  8900 | loss: 0.000001748699 \n",
      "Epoch:  9000 | loss: 0.000000690260 \n",
      "Epoch:  9100 | loss: 0.000000697773 \n",
      "Epoch:  9200 | loss: 0.000000696957 \n",
      "Epoch:  9300 | loss: 0.000000696550 \n",
      "Epoch:  9400 | loss: 0.000000695766 \n",
      "Epoch:  9500 | loss: 0.000000685045 \n",
      "Epoch:  9600 | loss: 0.000000694342 \n",
      "Epoch:  9700 | loss: 0.000000682907 \n",
      "Epoch:  9800 | loss: 0.000000681728 \n",
      "Epoch:  9900 | loss: 0.000000681278 \n",
      "Epoch:  10000 | loss: 0.000000680233 \n",
      "Epoch:  10100 | loss: 0.000000679015 \n",
      "Epoch:  10200 | loss: 0.000000678624 \n",
      "Epoch:  10300 | loss: 0.000000677799 \n",
      "Epoch:  10400 | loss: 0.000000676548 \n",
      "Epoch:  10500 | loss: 0.000000694009 \n",
      "Epoch:  10600 | loss: 0.000000686223 \n",
      "Epoch:  10700 | loss: 0.000000728437 \n",
      "Epoch:  10800 | loss: 0.000000673948 \n",
      "Epoch:  10900 | loss: 0.000000682363 \n",
      "Epoch:  11000 | loss: 0.000000671205 \n",
      "Epoch:  11100 | loss: 0.000000685804 \n",
      "Epoch:  11200 | loss: 0.000000673632 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11300 | loss: 0.000000671045 \n",
      "Epoch:  11400 | loss: 0.000000675870 \n",
      "Epoch:  11500 | loss: 0.000000670964 \n",
      "Epoch:  11600 | loss: 0.000000678984 \n",
      "Epoch:  11700 | loss: 0.000000673327 \n",
      "Epoch:  11800 | loss: 0.000000699281 \n",
      "Epoch:  11900 | loss: 0.000000695536 \n",
      "Epoch:  12000 | loss: 0.000000669643 \n",
      "Epoch:  12100 | loss: 0.000000669196 \n",
      "Epoch:  12200 | loss: 0.000000680566 \n",
      "Epoch:  12300 | loss: 0.000000668272 \n",
      "Epoch:  12400 | loss: 0.000000679637 \n",
      "Epoch:  12500 | loss: 0.000000667431 \n",
      "Epoch:  12600 | loss: 0.000000678787 \n",
      "Epoch:  12700 | loss: 0.000000680783 \n",
      "Epoch:  12800 | loss: 0.000000667932 \n",
      "Epoch:  12900 | loss: 0.000000667108 \n",
      "Epoch:  13000 | loss: 0.000000666518 \n",
      "Epoch:  13100 | loss: 0.000000676741 \n",
      "Epoch:  13200 | loss: 0.000000676137 \n",
      "Epoch:  13300 | loss: 0.000000664994 \n",
      "Epoch:  13400 | loss: 0.000000756634 \n",
      "Epoch:  13500 | loss: 0.000000664460 \n",
      "Epoch:  13600 | loss: 0.000000684211 \n",
      "Epoch:  13700 | loss: 0.000000662262 \n",
      "Epoch:  13800 | loss: 0.000000661598 \n",
      "Epoch:  13900 | loss: 0.000000672499 \n",
      "Epoch:  14000 | loss: 0.000000661303 \n",
      "Epoch:  14100 | loss: 0.000000661562 \n",
      "Epoch:  14200 | loss: 0.000000661549 \n",
      "Epoch:  14300 | loss: 0.000000672020 \n",
      "Epoch:  14400 | loss: 0.000000685160 \n",
      "Epoch:  14500 | loss: 0.000000660144 \n",
      "Epoch:  14600 | loss: 0.000000656602 \n",
      "Epoch:  14700 | loss: 0.000000799085 \n",
      "Epoch:  14800 | loss: 0.000000670257 \n",
      "Epoch:  14900 | loss: 0.000000678415 \n",
      "time=387.97775173187256\n",
      "best_train_loss=6.536170076287817e-07\n",
      "test_loss=1.052743186846783e-06\n",
      "best_epoch=14993\n",
      "w=35\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000653566 \n",
      "Epoch:  100 | loss: 0.000002315061 \n",
      "Epoch:  200 | loss: 0.000001082616 \n",
      "Epoch:  300 | loss: 0.000000790477 \n",
      "Epoch:  400 | loss: 0.000000700480 \n",
      "Epoch:  500 | loss: 0.000000682719 \n",
      "Epoch:  600 | loss: 0.000000660471 \n",
      "Epoch:  700 | loss: 0.000000655492 \n",
      "Epoch:  800 | loss: 0.000000649977 \n",
      "Epoch:  900 | loss: 0.000000640140 \n",
      "Epoch:  1000 | loss: 0.000000646579 \n",
      "Epoch:  1100 | loss: 0.000000641796 \n",
      "Epoch:  1200 | loss: 0.000001486845 \n",
      "Epoch:  1300 | loss: 0.000001111183 \n",
      "Epoch:  1400 | loss: 0.000000651262 \n",
      "Epoch:  1500 | loss: 0.000000671312 \n",
      "Epoch:  1600 | loss: 0.000000877307 \n",
      "Epoch:  1700 | loss: 0.000002469483 \n",
      "Epoch:  1800 | loss: 0.000000777018 \n",
      "Epoch:  1900 | loss: 0.000000701442 \n",
      "Epoch:  2000 | loss: 0.000001053209 \n",
      "Epoch:  2100 | loss: 0.000000680109 \n",
      "Epoch:  2200 | loss: 0.000001276827 \n",
      "Epoch:  2300 | loss: 0.000000676111 \n",
      "Epoch:  2400 | loss: 0.000001200213 \n",
      "Epoch:  2500 | loss: 0.000000679794 \n",
      "Epoch:  2600 | loss: 0.000003874955 \n",
      "Epoch:  2700 | loss: 0.000000689037 \n",
      "Epoch:  2800 | loss: 0.000075085409 \n",
      "Epoch:  2900 | loss: 0.000000679296 \n",
      "Epoch:  3000 | loss: 0.000001921257 \n",
      "Epoch:  3100 | loss: 0.000000704040 \n",
      "Epoch:  3200 | loss: 0.000000680642 \n",
      "Epoch:  3300 | loss: 0.000000670292 \n",
      "Epoch:  3400 | loss: 0.000000666053 \n",
      "Epoch:  3500 | loss: 0.000000652662 \n",
      "Epoch:  3600 | loss: 0.000000646114 \n",
      "Epoch:  3700 | loss: 0.000000645204 \n",
      "Epoch:  3800 | loss: 0.000000656678 \n",
      "Epoch:  3900 | loss: 0.000000651080 \n",
      "Epoch:  4000 | loss: 0.000000647403 \n",
      "Epoch:  4100 | loss: 0.000000640261 \n",
      "Epoch:  4200 | loss: 0.000000635138 \n",
      "Epoch:  4300 | loss: 0.000000633266 \n",
      "Epoch:  4400 | loss: 0.000000629146 \n",
      "Epoch:  4500 | loss: 0.000011900679 \n",
      "Epoch:  4600 | loss: 0.000000633020 \n",
      "Epoch:  4700 | loss: 0.000000627278 \n",
      "Epoch:  4800 | loss: 0.000000677056 \n",
      "Epoch:  4900 | loss: 0.000000621262 \n",
      "Epoch:  5000 | loss: 0.000001328637 \n",
      "Epoch:  5100 | loss: 0.000000619809 \n",
      "Epoch:  5200 | loss: 0.000000660768 \n",
      "Epoch:  5300 | loss: 0.000000620337 \n",
      "Epoch:  5400 | loss: 0.000000616420 \n",
      "Epoch:  5500 | loss: 0.000000651123 \n",
      "Epoch:  5600 | loss: 0.000000739532 \n",
      "Epoch:  5700 | loss: 0.000000606057 \n",
      "Epoch:  5800 | loss: 0.000000632968 \n",
      "Epoch:  5900 | loss: 0.000003585576 \n",
      "Epoch:  6000 | loss: 0.000000599840 \n",
      "Epoch:  6100 | loss: 0.000000596174 \n",
      "Epoch:  6200 | loss: 0.000000610271 \n",
      "Epoch:  6300 | loss: 0.000000593143 \n",
      "Epoch:  6400 | loss: 0.000000590048 \n",
      "Epoch:  6500 | loss: 0.000000609914 \n",
      "Epoch:  6600 | loss: 0.000000608414 \n",
      "Epoch:  6700 | loss: 0.000000589996 \n",
      "Epoch:  6800 | loss: 0.000000586852 \n",
      "Epoch:  6900 | loss: 0.000000585583 \n",
      "Epoch:  7000 | loss: 0.000000583569 \n",
      "Epoch:  7100 | loss: 0.000000582144 \n",
      "Epoch:  7200 | loss: 0.000000579665 \n",
      "Epoch:  7300 | loss: 0.000000572817 \n",
      "Epoch:  7400 | loss: 0.000001588612 \n",
      "Epoch:  7500 | loss: 0.000000568561 \n",
      "Epoch:  7600 | loss: 0.000000655661 \n",
      "Epoch:  7700 | loss: 0.000003903639 \n",
      "Epoch:  7800 | loss: 0.000000588812 \n",
      "Epoch:  7900 | loss: 0.000000566838 \n",
      "Epoch:  8000 | loss: 0.000001759845 \n",
      "Epoch:  8100 | loss: 0.000000558374 \n",
      "Epoch:  8200 | loss: 0.000000679413 \n",
      "Epoch:  8300 | loss: 0.000000872645 \n",
      "Epoch:  8400 | loss: 0.000000550153 \n",
      "Epoch:  8500 | loss: 0.000000941725 \n",
      "Epoch:  8600 | loss: 0.000000540817 \n",
      "Epoch:  8700 | loss: 0.000000737831 \n",
      "Epoch:  8800 | loss: 0.000000552795 \n",
      "Epoch:  8900 | loss: 0.000000554432 \n",
      "Epoch:  9000 | loss: 0.000000549376 \n",
      "Epoch:  9100 | loss: 0.000000531093 \n",
      "Epoch:  9200 | loss: 0.000000529609 \n",
      "Epoch:  9300 | loss: 0.000000528395 \n",
      "Epoch:  9400 | loss: 0.000000527481 \n",
      "Epoch:  9500 | loss: 0.000000525366 \n",
      "Epoch:  9600 | loss: 0.000000523911 \n",
      "Epoch:  9700 | loss: 0.000000527417 \n",
      "Epoch:  9800 | loss: 0.000000527665 \n",
      "Epoch:  9900 | loss: 0.000000526951 \n",
      "Epoch:  10000 | loss: 0.000000525427 \n",
      "Epoch:  10100 | loss: 0.000000524124 \n",
      "Epoch:  10200 | loss: 0.000000522605 \n",
      "Epoch:  10300 | loss: 0.000000537497 \n",
      "Epoch:  10400 | loss: 0.000000819926 \n",
      "Epoch:  10500 | loss: 0.000000549082 \n",
      "Epoch:  10600 | loss: 0.000000534048 \n",
      "Epoch:  10700 | loss: 0.000000932829 \n",
      "Epoch:  10800 | loss: 0.000000518959 \n",
      "Epoch:  10900 | loss: 0.000000518422 \n",
      "Epoch:  11000 | loss: 0.000000518143 \n",
      "Epoch:  11100 | loss: 0.000000531351 \n",
      "Epoch:  11200 | loss: 0.000002393872 \n",
      "Epoch:  11300 | loss: 0.000000526752 \n",
      "Epoch:  11400 | loss: 0.000000646177 \n",
      "Epoch:  11500 | loss: 0.000000610018 \n",
      "Epoch:  11600 | loss: 0.000000539974 \n",
      "Epoch:  11700 | loss: 0.000000549888 \n",
      "Epoch:  11800 | loss: 0.000000524053 \n",
      "Epoch:  11900 | loss: 0.000000536767 \n",
      "Epoch:  12000 | loss: 0.000000522314 \n",
      "Epoch:  12100 | loss: 0.000000509331 \n",
      "Epoch:  12200 | loss: 0.000000508557 \n",
      "Epoch:  12300 | loss: 0.000000518741 \n",
      "Epoch:  12400 | loss: 0.000000518169 \n",
      "Epoch:  12500 | loss: 0.000000517505 \n",
      "Epoch:  12600 | loss: 0.000000516847 \n",
      "Epoch:  12700 | loss: 0.000000505735 \n",
      "Epoch:  12800 | loss: 0.000000514767 \n",
      "Epoch:  12900 | loss: 0.000000513089 \n",
      "Epoch:  13000 | loss: 0.000000512216 \n",
      "Epoch:  13100 | loss: 0.000000511397 \n",
      "Epoch:  13200 | loss: 0.000000510544 \n",
      "Epoch:  13300 | loss: 0.000000499755 \n",
      "Epoch:  13400 | loss: 0.000000498606 \n",
      "Epoch:  13500 | loss: 0.000000516398 \n",
      "Epoch:  13600 | loss: 0.000000507175 \n",
      "Epoch:  13700 | loss: 0.000000509372 \n",
      "Epoch:  13800 | loss: 0.000000694797 \n",
      "Epoch:  13900 | loss: 0.000000495545 \n",
      "Epoch:  14000 | loss: 0.000000507722 \n",
      "Epoch:  14100 | loss: 0.000000503391 \n",
      "Epoch:  14200 | loss: 0.000000520045 \n",
      "Epoch:  14300 | loss: 0.000000501733 \n",
      "Epoch:  14400 | loss: 0.000000511824 \n",
      "Epoch:  14500 | loss: 0.000000500084 \n",
      "Epoch:  14600 | loss: 0.000000570149 \n",
      "Epoch:  14700 | loss: 0.000000498740 \n",
      "Epoch:  14800 | loss: 0.000000538147 \n",
      "Epoch:  14900 | loss: 0.000000497066 \n",
      "time=464.3653609752655\n",
      "best_train_loss=4.89080832721811e-07\n",
      "test_loss=7.781157478348177e-07\n",
      "best_epoch=14932\n",
      "w=40\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000497594 \n",
      "Epoch:  100 | loss: 0.000005132976 \n",
      "Epoch:  200 | loss: 0.000001656356 \n",
      "Epoch:  300 | loss: 0.000000895765 \n",
      "Epoch:  400 | loss: 0.000000670604 \n",
      "Epoch:  500 | loss: 0.000000610340 \n",
      "Epoch:  600 | loss: 0.000000582362 \n",
      "Epoch:  700 | loss: 0.000000569692 \n",
      "Epoch:  800 | loss: 0.000000565129 \n",
      "Epoch:  900 | loss: 0.000000559959 \n",
      "Epoch:  1000 | loss: 0.000000557247 \n",
      "Epoch:  1100 | loss: 0.000000555756 \n",
      "Epoch:  1200 | loss: 0.000000546960 \n",
      "Epoch:  1300 | loss: 0.000000538177 \n",
      "Epoch:  1400 | loss: 0.000000528916 \n",
      "Epoch:  1500 | loss: 0.000000534249 \n",
      "Epoch:  1600 | loss: 0.000000532280 \n",
      "Epoch:  1700 | loss: 0.000000530343 \n",
      "Epoch:  1800 | loss: 0.000000578930 \n",
      "Epoch:  1900 | loss: 0.000000569299 \n",
      "Epoch:  2000 | loss: 0.000001058271 \n",
      "Epoch:  2100 | loss: 0.000000800135 \n",
      "Epoch:  2200 | loss: 0.000012530277 \n",
      "Epoch:  2300 | loss: 0.000000576391 \n",
      "Epoch:  2400 | loss: 0.000000541539 \n",
      "Epoch:  2500 | loss: 0.000000739762 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2600 | loss: 0.000001614545 \n",
      "Epoch:  2700 | loss: 0.000005977190 \n",
      "Epoch:  2800 | loss: 0.000005001262 \n",
      "Epoch:  2900 | loss: 0.000000568240 \n",
      "Epoch:  3000 | loss: 0.000000529159 \n",
      "Epoch:  3100 | loss: 0.000000524177 \n",
      "Epoch:  3200 | loss: 0.000000520909 \n",
      "Epoch:  3300 | loss: 0.000000516378 \n",
      "Epoch:  3400 | loss: 0.000000512737 \n",
      "Epoch:  3500 | loss: 0.000000509840 \n",
      "Epoch:  3600 | loss: 0.000000509952 \n",
      "Epoch:  3700 | loss: 0.000000509053 \n",
      "Epoch:  3800 | loss: 0.000000508093 \n",
      "Epoch:  3900 | loss: 0.000000506218 \n",
      "Epoch:  4000 | loss: 0.000000504931 \n",
      "Epoch:  4100 | loss: 0.000000500156 \n",
      "Epoch:  4200 | loss: 0.000000498404 \n",
      "Epoch:  4300 | loss: 0.000000496335 \n",
      "Epoch:  4400 | loss: 0.000001817982 \n",
      "Epoch:  4500 | loss: 0.000000496737 \n",
      "Epoch:  4600 | loss: 0.000000725062 \n",
      "Epoch:  4700 | loss: 0.000000495438 \n",
      "Epoch:  4800 | loss: 0.000000766311 \n",
      "Epoch:  4900 | loss: 0.000000498362 \n",
      "Epoch:  5000 | loss: 0.000006808788 \n",
      "Epoch:  5100 | loss: 0.000001008703 \n",
      "Epoch:  5200 | loss: 0.000000669878 \n",
      "Epoch:  5300 | loss: 0.000000561506 \n",
      "Epoch:  5400 | loss: 0.000000522155 \n",
      "Epoch:  5500 | loss: 0.000000502241 \n",
      "Epoch:  5600 | loss: 0.000000496059 \n",
      "Epoch:  5700 | loss: 0.000000668572 \n",
      "Epoch:  5800 | loss: 0.000001817591 \n",
      "Epoch:  5900 | loss: 0.000000645528 \n",
      "Epoch:  6000 | loss: 0.000000505259 \n",
      "Epoch:  6100 | loss: 0.000000488044 \n",
      "Epoch:  6200 | loss: 0.000000486448 \n",
      "Epoch:  6300 | loss: 0.000000488749 \n",
      "Epoch:  6400 | loss: 0.000000483599 \n",
      "Epoch:  6500 | loss: 0.000000484133 \n",
      "Epoch:  6600 | loss: 0.000000485201 \n",
      "Epoch:  6700 | loss: 0.000000482986 \n",
      "Epoch:  6800 | loss: 0.000000478731 \n",
      "Epoch:  6900 | loss: 0.000000479950 \n",
      "Epoch:  7000 | loss: 0.000000478551 \n",
      "Epoch:  7100 | loss: 0.000000473397 \n",
      "Epoch:  7200 | loss: 0.000000472276 \n",
      "Epoch:  7300 | loss: 0.000000470609 \n",
      "Epoch:  7400 | loss: 0.000000469378 \n",
      "Epoch:  7500 | loss: 0.000000491065 \n",
      "Epoch:  7600 | loss: 0.000000492018 \n",
      "Epoch:  7700 | loss: 0.000000738657 \n",
      "Epoch:  7800 | loss: 0.000001429761 \n",
      "Epoch:  7900 | loss: 0.000000534118 \n",
      "Epoch:  8000 | loss: 0.000000498129 \n",
      "Epoch:  8100 | loss: 0.000000464413 \n",
      "Epoch:  8200 | loss: 0.000000474489 \n",
      "Epoch:  8300 | loss: 0.000001345853 \n",
      "Epoch:  8400 | loss: 0.000000462283 \n",
      "Epoch:  8500 | loss: 0.000000469048 \n",
      "Epoch:  8600 | loss: 0.000000509909 \n",
      "Epoch:  8700 | loss: 0.000000457987 \n",
      "Epoch:  8800 | loss: 0.000000558275 \n",
      "Epoch:  8900 | loss: 0.000003205184 \n",
      "Epoch:  9000 | loss: 0.000000457000 \n",
      "Epoch:  9100 | loss: 0.000000456518 \n",
      "Epoch:  9200 | loss: 0.000000462932 \n",
      "Epoch:  9300 | loss: 0.000000456213 \n",
      "Epoch:  9400 | loss: 0.000000455820 \n",
      "Epoch:  9500 | loss: 0.000000455568 \n",
      "Epoch:  9600 | loss: 0.000000455426 \n",
      "Epoch:  9700 | loss: 0.000000454952 \n",
      "Epoch:  9800 | loss: 0.000000460833 \n",
      "Epoch:  9900 | loss: 0.000000454494 \n",
      "Epoch:  10000 | loss: 0.000000461107 \n",
      "Epoch:  10100 | loss: 0.000000453525 \n",
      "Epoch:  10200 | loss: 0.000000459578 \n",
      "Epoch:  10300 | loss: 0.000000453006 \n",
      "Epoch:  10400 | loss: 0.000000921926 \n",
      "Epoch:  10500 | loss: 0.000000461954 \n",
      "Epoch:  10600 | loss: 0.000001031776 \n",
      "Epoch:  10700 | loss: 0.000000767452 \n",
      "Epoch:  10800 | loss: 0.000000699024 \n",
      "Epoch:  10900 | loss: 0.000000454017 \n",
      "Epoch:  11000 | loss: 0.000000467336 \n",
      "Epoch:  11100 | loss: 0.000000459946 \n",
      "Epoch:  11200 | loss: 0.000000453947 \n",
      "Epoch:  11300 | loss: 0.000000453317 \n",
      "Epoch:  11400 | loss: 0.000000453785 \n",
      "Epoch:  11500 | loss: 0.000000451123 \n",
      "Epoch:  11600 | loss: 0.000000453923 \n",
      "Epoch:  11700 | loss: 0.000000497273 \n",
      "Epoch:  11800 | loss: 0.000000526082 \n",
      "Epoch:  11900 | loss: 0.000000450694 \n",
      "Epoch:  12000 | loss: 0.000000450126 \n",
      "Epoch:  12100 | loss: 0.000000449783 \n",
      "Epoch:  12200 | loss: 0.000000450170 \n",
      "Epoch:  12300 | loss: 0.000000449850 \n",
      "Epoch:  12400 | loss: 0.000000449692 \n",
      "Epoch:  12500 | loss: 0.000000449504 \n",
      "Epoch:  12600 | loss: 0.000000457522 \n",
      "Epoch:  12700 | loss: 0.000000449269 \n",
      "Epoch:  12800 | loss: 0.000000448436 \n",
      "Epoch:  12900 | loss: 0.000000448489 \n",
      "Epoch:  13000 | loss: 0.000000447888 \n",
      "Epoch:  13100 | loss: 0.000000456413 \n",
      "Epoch:  13200 | loss: 0.000000447435 \n",
      "Epoch:  13300 | loss: 0.000000447355 \n",
      "Epoch:  13400 | loss: 0.000000448220 \n",
      "Epoch:  13500 | loss: 0.000000447982 \n",
      "Epoch:  13600 | loss: 0.000000450249 \n",
      "Epoch:  13700 | loss: 0.000000457507 \n",
      "Epoch:  13800 | loss: 0.000000446797 \n",
      "Epoch:  13900 | loss: 0.000000460290 \n",
      "Epoch:  14000 | loss: 0.000000452500 \n",
      "Epoch:  14100 | loss: 0.000000446814 \n",
      "Epoch:  14200 | loss: 0.000000449071 \n",
      "Epoch:  14300 | loss: 0.000000445598 \n",
      "Epoch:  14400 | loss: 0.000000548391 \n",
      "Epoch:  14500 | loss: 0.000000445377 \n",
      "Epoch:  14600 | loss: 0.000000444799 \n",
      "Epoch:  14700 | loss: 0.000000445103 \n",
      "Epoch:  14800 | loss: 0.000000515342 \n",
      "Epoch:  14900 | loss: 0.000000445256 \n",
      "time=456.9875268936157\n",
      "best_train_loss=4.441491228135419e-07\n",
      "test_loss=7.109167086127854e-07\n",
      "best_epoch=14895\n",
      "w=45\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000444499 \n",
      "Epoch:  100 | loss: 0.000005670366 \n",
      "Epoch:  200 | loss: 0.000001755257 \n",
      "Epoch:  300 | loss: 0.000000793457 \n",
      "Epoch:  400 | loss: 0.000000613541 \n",
      "Epoch:  500 | loss: 0.000000562383 \n",
      "Epoch:  600 | loss: 0.000000540272 \n",
      "Epoch:  700 | loss: 0.000000528806 \n",
      "Epoch:  800 | loss: 0.000000521167 \n",
      "Epoch:  900 | loss: 0.000000514184 \n",
      "Epoch:  1000 | loss: 0.000000503709 \n",
      "Epoch:  1100 | loss: 0.000000497333 \n",
      "Epoch:  1200 | loss: 0.000000497305 \n",
      "Epoch:  1300 | loss: 0.000000504377 \n",
      "Epoch:  1400 | loss: 0.000000492718 \n",
      "Epoch:  1500 | loss: 0.000000494877 \n",
      "Epoch:  1600 | loss: 0.000000657194 \n",
      "Epoch:  1700 | loss: 0.000000670212 \n",
      "Epoch:  1800 | loss: 0.000003373557 \n",
      "Epoch:  1900 | loss: 0.000000459915 \n",
      "Epoch:  2000 | loss: 0.000000504039 \n",
      "Epoch:  2100 | loss: 0.000000444995 \n",
      "Epoch:  2200 | loss: 0.000000500059 \n",
      "Epoch:  2300 | loss: 0.000087891647 \n",
      "Epoch:  2400 | loss: 0.000000456860 \n",
      "Epoch:  2500 | loss: 0.000001036695 \n",
      "Epoch:  2600 | loss: 0.000000509379 \n",
      "Epoch:  2700 | loss: 0.000000451703 \n",
      "Epoch:  2800 | loss: 0.000000540113 \n",
      "Epoch:  2900 | loss: 0.000000461523 \n",
      "Epoch:  3000 | loss: 0.000000654590 \n",
      "Epoch:  3100 | loss: 0.000000473380 \n",
      "Epoch:  3200 | loss: 0.000000461266 \n",
      "Epoch:  3300 | loss: 0.000000456447 \n",
      "Epoch:  3400 | loss: 0.000000449632 \n",
      "Epoch:  3500 | loss: 0.000000445498 \n",
      "Epoch:  3600 | loss: 0.000000439912 \n",
      "Epoch:  3700 | loss: 0.000000438781 \n",
      "Epoch:  3800 | loss: 0.000000434458 \n",
      "Epoch:  3900 | loss: 0.000000428905 \n",
      "Epoch:  4000 | loss: 0.000000416262 \n",
      "Epoch:  4100 | loss: 0.000000420056 \n",
      "Epoch:  4200 | loss: 0.000000405221 \n",
      "Epoch:  4300 | loss: 0.000000400474 \n",
      "Epoch:  4400 | loss: 0.000000395195 \n",
      "Epoch:  4500 | loss: 0.000001497775 \n",
      "Epoch:  4600 | loss: 0.000000391412 \n",
      "Epoch:  4700 | loss: 0.000000396427 \n",
      "Epoch:  4800 | loss: 0.000000518093 \n",
      "Epoch:  4900 | loss: 0.000000378716 \n",
      "Epoch:  5000 | loss: 0.000005524400 \n",
      "Epoch:  5100 | loss: 0.000000375310 \n",
      "Epoch:  5200 | loss: 0.000000382584 \n",
      "Epoch:  5300 | loss: 0.000000385075 \n",
      "Epoch:  5400 | loss: 0.000000368356 \n",
      "Epoch:  5500 | loss: 0.000000393819 \n",
      "Epoch:  5600 | loss: 0.000000361241 \n",
      "Epoch:  5700 | loss: 0.000000503877 \n",
      "Epoch:  5800 | loss: 0.000000367532 \n",
      "Epoch:  5900 | loss: 0.000000548728 \n",
      "Epoch:  6000 | loss: 0.000000360795 \n",
      "Epoch:  6100 | loss: 0.000000356073 \n",
      "Epoch:  6200 | loss: 0.000000355700 \n",
      "Epoch:  6300 | loss: 0.000000354231 \n",
      "Epoch:  6400 | loss: 0.000000353915 \n",
      "Epoch:  6500 | loss: 0.000000352442 \n",
      "Epoch:  6600 | loss: 0.000000350830 \n",
      "Epoch:  6700 | loss: 0.000000349421 \n",
      "Epoch:  6800 | loss: 0.000000348523 \n",
      "Epoch:  6900 | loss: 0.000000347262 \n",
      "Epoch:  7000 | loss: 0.000000347048 \n",
      "Epoch:  7100 | loss: 0.000000345853 \n",
      "Epoch:  7200 | loss: 0.000000344552 \n",
      "Epoch:  7300 | loss: 0.000000343275 \n",
      "Epoch:  7400 | loss: 0.000000342283 \n",
      "Epoch:  7500 | loss: 0.000000348977 \n",
      "Epoch:  7600 | loss: 0.000000348482 \n",
      "Epoch:  7700 | loss: 0.000005208602 \n",
      "Epoch:  7800 | loss: 0.000000338735 \n",
      "Epoch:  7900 | loss: 0.000000792553 \n",
      "Epoch:  8000 | loss: 0.000000339740 \n",
      "Epoch:  8100 | loss: 0.000003202189 \n",
      "Epoch:  8200 | loss: 0.000000341764 \n",
      "Epoch:  8300 | loss: 0.000000350541 \n",
      "Epoch:  8400 | loss: 0.000000437579 \n",
      "Epoch:  8500 | loss: 0.000000364922 \n",
      "Epoch:  8600 | loss: 0.000000337163 \n",
      "Epoch:  8700 | loss: 0.000001174610 \n",
      "Epoch:  8800 | loss: 0.000000366403 \n",
      "Epoch:  8900 | loss: 0.000000385576 \n",
      "Epoch:  9000 | loss: 0.000000333045 \n",
      "Epoch:  9100 | loss: 0.000000332472 \n",
      "Epoch:  9200 | loss: 0.000000332229 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9300 | loss: 0.000000333004 \n",
      "Epoch:  9400 | loss: 0.000000332559 \n",
      "Epoch:  9500 | loss: 0.000000332388 \n",
      "Epoch:  9600 | loss: 0.000000331849 \n",
      "Epoch:  9700 | loss: 0.000000328866 \n",
      "Epoch:  9800 | loss: 0.000000327871 \n",
      "Epoch:  9900 | loss: 0.000000327646 \n",
      "Epoch:  10000 | loss: 0.000000327118 \n",
      "Epoch:  10100 | loss: 0.000000326569 \n",
      "Epoch:  10200 | loss: 0.000000325897 \n",
      "Epoch:  10300 | loss: 0.000000325607 \n",
      "Epoch:  10400 | loss: 0.000000324808 \n",
      "Epoch:  10500 | loss: 0.000000329584 \n",
      "Epoch:  10600 | loss: 0.000000323667 \n",
      "Epoch:  10700 | loss: 0.000000660627 \n",
      "Epoch:  10800 | loss: 0.000000322474 \n",
      "Epoch:  10900 | loss: 0.000000335867 \n",
      "Epoch:  11000 | loss: 0.000000530203 \n",
      "Epoch:  11100 | loss: 0.000000320650 \n",
      "Epoch:  11200 | loss: 0.000000333953 \n",
      "Epoch:  11300 | loss: 0.000000319320 \n",
      "Epoch:  11400 | loss: 0.000000335977 \n",
      "Epoch:  11500 | loss: 0.000000318228 \n",
      "Epoch:  11600 | loss: 0.000000329181 \n",
      "Epoch:  11700 | loss: 0.000000372634 \n",
      "Epoch:  11800 | loss: 0.000000325217 \n",
      "Epoch:  11900 | loss: 0.000000318423 \n",
      "Epoch:  12000 | loss: 0.000000326634 \n",
      "Epoch:  12100 | loss: 0.000000321500 \n",
      "Epoch:  12200 | loss: 0.000000320900 \n",
      "Epoch:  12300 | loss: 0.000000319567 \n",
      "Epoch:  12400 | loss: 0.000000318658 \n",
      "Epoch:  12500 | loss: 0.000000320839 \n",
      "Epoch:  12600 | loss: 0.000000323791 \n",
      "Epoch:  12700 | loss: 0.000000323782 \n",
      "Epoch:  12800 | loss: 0.000000321605 \n",
      "Epoch:  12900 | loss: 0.000000318286 \n",
      "Epoch:  13000 | loss: 0.000000317265 \n",
      "Epoch:  13100 | loss: 0.000000317054 \n",
      "Epoch:  13200 | loss: 0.000000315762 \n",
      "Epoch:  13300 | loss: 0.000000314321 \n",
      "Epoch:  13400 | loss: 0.000000313902 \n",
      "Epoch:  13500 | loss: 0.000000318684 \n",
      "Epoch:  13600 | loss: 0.000000313108 \n",
      "Epoch:  13700 | loss: 0.000000312453 \n",
      "Epoch:  13800 | loss: 0.000000313062 \n",
      "Epoch:  13900 | loss: 0.000000312532 \n",
      "Epoch:  14000 | loss: 0.000000316881 \n",
      "Epoch:  14100 | loss: 0.000000462294 \n",
      "Epoch:  14200 | loss: 0.000000320653 \n",
      "Epoch:  14300 | loss: 0.000000345006 \n",
      "Epoch:  14400 | loss: 0.000000320494 \n",
      "Epoch:  14500 | loss: 0.000000326477 \n",
      "Epoch:  14600 | loss: 0.000000308761 \n",
      "Epoch:  14700 | loss: 0.000000317314 \n",
      "Epoch:  14800 | loss: 0.000000312677 \n",
      "Epoch:  14900 | loss: 0.000000311952 \n",
      "time=498.89105892181396\n",
      "best_train_loss=3.0650929261355486e-07\n",
      "test_loss=5.336786443876917e-07\n",
      "best_epoch=14782\n",
      "w=50\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000327225 \n",
      "Epoch:  100 | loss: 0.000002505067 \n",
      "Epoch:  200 | loss: 0.000000713432 \n",
      "Epoch:  300 | loss: 0.000000434631 \n",
      "Epoch:  400 | loss: 0.000000380029 \n",
      "Epoch:  500 | loss: 0.000000457567 \n",
      "Epoch:  600 | loss: 0.000000346719 \n",
      "Epoch:  700 | loss: 0.000000409435 \n",
      "Epoch:  800 | loss: 0.000000458107 \n",
      "Epoch:  900 | loss: 0.000000343749 \n",
      "Epoch:  1000 | loss: 0.000000409868 \n",
      "Epoch:  1100 | loss: 0.000000355319 \n",
      "Epoch:  1200 | loss: 0.000025889054 \n",
      "Epoch:  1300 | loss: 0.000000340121 \n",
      "Epoch:  1400 | loss: 0.000001203530 \n",
      "Epoch:  1500 | loss: 0.000000328878 \n",
      "Epoch:  1600 | loss: 0.000000760653 \n",
      "Epoch:  1700 | loss: 0.000000329884 \n",
      "Epoch:  1800 | loss: 0.000000428049 \n",
      "Epoch:  1900 | loss: 0.000000374497 \n",
      "Epoch:  2000 | loss: 0.000000358782 \n",
      "Epoch:  2100 | loss: 0.000001943475 \n",
      "Epoch:  2200 | loss: 0.000000343208 \n",
      "Epoch:  2300 | loss: 0.000011834164 \n",
      "Epoch:  2400 | loss: 0.000000826067 \n",
      "Epoch:  2500 | loss: 0.000000346739 \n",
      "Epoch:  2600 | loss: 0.000000556091 \n",
      "Epoch:  2700 | loss: 0.000000381738 \n",
      "Epoch:  2800 | loss: 0.000000413845 \n",
      "Epoch:  2900 | loss: 0.000000668317 \n",
      "Epoch:  3000 | loss: 0.000000351424 \n",
      "Epoch:  3100 | loss: 0.000000350215 \n",
      "Epoch:  3200 | loss: 0.000000350294 \n",
      "Epoch:  3300 | loss: 0.000000338397 \n",
      "Epoch:  3400 | loss: 0.000000338113 \n",
      "Epoch:  3500 | loss: 0.000000337898 \n",
      "Epoch:  3600 | loss: 0.000000331708 \n",
      "Epoch:  3700 | loss: 0.000000327160 \n",
      "Epoch:  3800 | loss: 0.000000323603 \n",
      "Epoch:  3900 | loss: 0.000000319460 \n",
      "Epoch:  4000 | loss: 0.000000315003 \n",
      "Epoch:  4100 | loss: 0.000000310243 \n",
      "Epoch:  4200 | loss: 0.000000309556 \n",
      "Epoch:  4300 | loss: 0.000000319589 \n",
      "Epoch:  4400 | loss: 0.000000318640 \n",
      "Epoch:  4500 | loss: 0.000000881342 \n",
      "Epoch:  4600 | loss: 0.000000339343 \n",
      "Epoch:  4700 | loss: 0.000000330724 \n",
      "Epoch:  4800 | loss: 0.000002295701 \n",
      "Epoch:  4900 | loss: 0.000000345419 \n",
      "Epoch:  5000 | loss: 0.000000329111 \n",
      "Epoch:  5100 | loss: 0.000000365097 \n",
      "Epoch:  5200 | loss: 0.000002961465 \n",
      "Epoch:  5300 | loss: 0.000000694698 \n",
      "Epoch:  5400 | loss: 0.000000445450 \n",
      "Epoch:  5500 | loss: 0.000001988940 \n",
      "Epoch:  5600 | loss: 0.000000449846 \n",
      "Epoch:  5700 | loss: 0.000001060245 \n",
      "Epoch:  5800 | loss: 0.000007031759 \n",
      "Epoch:  5900 | loss: 0.000000489582 \n",
      "Epoch:  6000 | loss: 0.000000303155 \n",
      "Epoch:  6100 | loss: 0.000000302578 \n",
      "Epoch:  6200 | loss: 0.000000301200 \n",
      "Epoch:  6300 | loss: 0.000000300219 \n",
      "Epoch:  6400 | loss: 0.000000299175 \n",
      "Epoch:  6500 | loss: 0.000000302150 \n",
      "Epoch:  6600 | loss: 0.000000296592 \n",
      "Epoch:  6700 | loss: 0.000000299159 \n",
      "Epoch:  6800 | loss: 0.000000295625 \n",
      "Epoch:  6900 | loss: 0.000000297993 \n",
      "Epoch:  7000 | loss: 0.000000296984 \n",
      "Epoch:  7100 | loss: 0.000000294990 \n",
      "Epoch:  7200 | loss: 0.000000294717 \n",
      "Epoch:  7300 | loss: 0.000000292708 \n",
      "Epoch:  7400 | loss: 0.000000303904 \n",
      "Epoch:  7500 | loss: 0.000000292265 \n",
      "Epoch:  7600 | loss: 0.000000774813 \n",
      "Epoch:  7700 | loss: 0.000000290405 \n",
      "Epoch:  7800 | loss: 0.000000312998 \n",
      "Epoch:  7900 | loss: 0.000000339559 \n",
      "Epoch:  8000 | loss: 0.000000355592 \n",
      "Epoch:  8100 | loss: 0.000000321171 \n",
      "Epoch:  8200 | loss: 0.000000308752 \n",
      "Epoch:  8300 | loss: 0.000000337370 \n",
      "Epoch:  8400 | loss: 0.000000287837 \n",
      "Epoch:  8500 | loss: 0.000000833471 \n",
      "Epoch:  8600 | loss: 0.000000680500 \n",
      "Epoch:  8700 | loss: 0.000000484195 \n",
      "Epoch:  8800 | loss: 0.000000286587 \n",
      "Epoch:  8900 | loss: 0.000000483212 \n",
      "Epoch:  9000 | loss: 0.000000282948 \n",
      "Epoch:  9100 | loss: 0.000000282086 \n",
      "Epoch:  9200 | loss: 0.000000288771 \n",
      "Epoch:  9300 | loss: 0.000000288313 \n",
      "Epoch:  9400 | loss: 0.000000287453 \n",
      "Epoch:  9500 | loss: 0.000000286831 \n",
      "Epoch:  9600 | loss: 0.000000286735 \n",
      "Epoch:  9700 | loss: 0.000000284199 \n",
      "Epoch:  9800 | loss: 0.000000285646 \n",
      "Epoch:  9900 | loss: 0.000000285437 \n",
      "Epoch:  10000 | loss: 0.000000283253 \n",
      "Epoch:  10100 | loss: 0.000000282753 \n",
      "Epoch:  10200 | loss: 0.000000282297 \n",
      "Epoch:  10300 | loss: 0.000000294364 \n",
      "Epoch:  10400 | loss: 0.000000314718 \n",
      "Epoch:  10500 | loss: 0.000000567383 \n",
      "Epoch:  10600 | loss: 0.000000285742 \n",
      "Epoch:  10700 | loss: 0.000000286112 \n",
      "Epoch:  10800 | loss: 0.000000301587 \n",
      "Epoch:  10900 | loss: 0.000000283920 \n",
      "Epoch:  11000 | loss: 0.000000284313 \n",
      "Epoch:  11100 | loss: 0.000000359736 \n",
      "Epoch:  11200 | loss: 0.000000281972 \n",
      "Epoch:  11300 | loss: 0.000000288510 \n",
      "Epoch:  11400 | loss: 0.000000283317 \n",
      "Epoch:  11500 | loss: 0.000000453109 \n",
      "Epoch:  11600 | loss: 0.000000346888 \n",
      "Epoch:  11700 | loss: 0.000000341575 \n",
      "Epoch:  11800 | loss: 0.000000348954 \n",
      "Epoch:  11900 | loss: 0.000000402428 \n",
      "Epoch:  12000 | loss: 0.000000275605 \n",
      "Epoch:  12100 | loss: 0.000000274290 \n",
      "Epoch:  12200 | loss: 0.000000274608 \n",
      "Epoch:  12300 | loss: 0.000000273871 \n",
      "Epoch:  12400 | loss: 0.000000273971 \n",
      "Epoch:  12500 | loss: 0.000000273410 \n",
      "Epoch:  12600 | loss: 0.000000272889 \n",
      "Epoch:  12700 | loss: 0.000000272842 \n",
      "Epoch:  12800 | loss: 0.000000272041 \n",
      "Epoch:  12900 | loss: 0.000000271858 \n",
      "Epoch:  13000 | loss: 0.000000271766 \n",
      "Epoch:  13100 | loss: 0.000000269588 \n",
      "Epoch:  13200 | loss: 0.000000269227 \n",
      "Epoch:  13300 | loss: 0.000000268695 \n",
      "Epoch:  13400 | loss: 0.000000275736 \n",
      "Epoch:  13500 | loss: 0.000000268191 \n",
      "Epoch:  13600 | loss: 0.000000290535 \n",
      "Epoch:  13700 | loss: 0.000000267216 \n",
      "Epoch:  13800 | loss: 0.000000266799 \n",
      "Epoch:  13900 | loss: 0.000000327643 \n",
      "Epoch:  14000 | loss: 0.000000266359 \n",
      "Epoch:  14100 | loss: 0.000000266041 \n",
      "Epoch:  14200 | loss: 0.000000268778 \n",
      "Epoch:  14300 | loss: 0.000000268985 \n",
      "Epoch:  14400 | loss: 0.000000357497 \n",
      "Epoch:  14500 | loss: 0.000000269776 \n",
      "Epoch:  14600 | loss: 0.000000270785 \n",
      "Epoch:  14700 | loss: 0.000000284191 \n",
      "Epoch:  14800 | loss: 0.000000269494 \n",
      "Epoch:  14900 | loss: 0.000000272662 \n",
      "time=501.4848461151123\n",
      "best_train_loss=2.6258072693963186e-07\n",
      "test_loss=6.150394256110303e-07\n",
      "best_epoch=14276\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# w/wo growing network\n",
    "# Tanh, Relu, Relu2 activation, last-layer act(other relu). Even: Should we use spline networks?\n",
    "# Hybrid: Adam + LBFGS\n",
    "# Possible overfitting: train & test gap\n",
    "# LBFGS usage\n",
    "\n",
    "#ws = [50,60,70,80,90,100,120,140,160,180,200,250,300,350,400]\n",
    "ws = [5,10,15,20,25,30,35,40,45,50]\n",
    "#ws = [14]\n",
    "#ws = [2,4]\n",
    "losses_w = []\n",
    "losses_w_test = []\n",
    "times = []\n",
    "\n",
    "a_s = [0.0]\n",
    "\n",
    "w_i = 0\n",
    "\n",
    "for w in ws:\n",
    "    \n",
    "    print(\"w={}\".format(w))\n",
    "    if w_i == 0:\n",
    "        t = T(w=w, a=0.0, M=1.0)\n",
    "    else:\n",
    "        sd = t.state_dict()\n",
    "        t_old = T(w=w_old, a=0.0, M=1.0)\n",
    "        t_old.load_state_dict(sd)\n",
    "        t = T(w=w, a=0.0, M=1.0)\n",
    "        t = grow(t_old, t, w_old, w)\n",
    "    w_i = w_i + 1\n",
    "\n",
    "\n",
    "    losses_a = []\n",
    "    losses_all = []\n",
    "    a_i = 0\n",
    "\n",
    "\n",
    "\n",
    "    for a_kerr in a_s:\n",
    "        M = 1.0\n",
    "        r_c = M + np.sqrt(M**2-a_kerr**2)\n",
    "        print(\"a_kerr={}\".format(a_kerr))\n",
    "        print(\"M={}\".format(M))\n",
    "        print(\"r_c={}\".format(r_c))\n",
    "        #t = T(w=400, a=a_kerr, M=M)\n",
    "        t.set_a(a_kerr)\n",
    "        a_i += 1\n",
    "\n",
    "\n",
    "        # Kerr Metric\n",
    "        def g(x_):\n",
    "            a = a_kerr\n",
    "            bs = x_.shape[0]\n",
    "            t = x_[:,0]\n",
    "            x = x_[:,1]\n",
    "            y = x_[:,2]\n",
    "            z = x_[:,3]\n",
    "            rho = torch.sqrt(x**2+y**2)\n",
    "            r = torch.sqrt(x**2+y**2+z**2)\n",
    "            costheta = z/r\n",
    "            sintheta = rho/r\n",
    "            sin2theta = 2*sintheta*costheta\n",
    "            cos2theta = 2*costheta**2 - 1\n",
    "            cosphi = x/rho\n",
    "            sinphi = y/rho\n",
    "            sigma = r**2 + a**2*costheta**2\n",
    "            zeta = torch.sqrt(r**2+a**2)\n",
    "            sq2 = torch.sqrt(torch.tensor(2., dtype=torch.float, requires_grad=False))\n",
    "\n",
    "            u1 = a**2 + 2*r**2 + a**2*cos2theta\n",
    "            zeta = torch.sqrt(a**2+r**2)\n",
    "            u2 = u1/(zeta*torch.sqrt(M*r))\n",
    "            u3 = 8*a*M/sigma\n",
    "            u4 = zeta**2 + 2*a**2*M*r*sintheta**2/sigma\n",
    "\n",
    "            g00 = -1 + 2*M*r/sigma\n",
    "            g01 = g10 = 1/4*sintheta*(sq2*u2*cosphi+u3*sinphi)\n",
    "            g02 = g20 = 1/4*sintheta*(-u3*cosphi+sq2*u2*sinphi)\n",
    "            g03 = g30 = costheta*u2/sq2**3\n",
    "            g11 = (8*costheta**2*cosphi**2*sigma-u2**2*r**2*cosphi**2*sintheta**2+8*u4*sinphi**2)/(8*r**2)\n",
    "            g12 = g21 = cosphi*(8*costheta**2*sigma-u2**2*r**2*sintheta**2-8*u4)*sinphi/(8*r**2)\n",
    "            g13 = g31 = costheta*(-8*sigma-u2**2*r**2)*cosphi*sintheta/(8*r**2)\n",
    "            g22 = (8*cosphi**2*u4+8*costheta**2*sigma*sinphi**2-u2**2*r**2*sintheta**2*sinphi**2)/(8*r**2)\n",
    "            g23 = g32 = costheta*(-8*sigma-u2**2*r**2)*sintheta*sinphi/(8*r**2)\n",
    "            g33 = sintheta**2 + costheta**2*(-u2**2*r**2+8*a**2*sintheta**2)/(8*r**2)\n",
    "\n",
    "            stack1 = torch.stack([g00, g01, g02, g03])\n",
    "            stack2 = torch.stack([g10, g11, g12, g13])\n",
    "            stack3 = torch.stack([g20, g21, g22, g23])\n",
    "            stack4 = torch.stack([g30, g31, g32, g33])\n",
    "\n",
    "            gs = - torch.stack([stack1, stack2, stack3, stack4]).permute(2,0,1)\n",
    "            return gs\n",
    "        \n",
    "        def euclidean_loss(t,inputs):\n",
    "            gp = t.transform_g(inputs)\n",
    "            bs = gp.shape[0]\n",
    "            minkowski_metric = torch.unsqueeze(torch.unsqueeze(torch.ones(bs,),dim=1),dim=2) * torch.unsqueeze(torch.diag(torch.tensor([-1.,-1.,-1.], dtype=torch.float, requires_grad=True)), dim=0)\n",
    "            return torch.mean((gp[:,1:,1:]-minkowski_metric)**2)\n",
    "\n",
    "\n",
    "\n",
    "        lr = 1e-2\n",
    "        '''if w_i == 0:\n",
    "            epochs = 2500\n",
    "            BFGS_epoch = 2000\n",
    "        else:\n",
    "            epochs = 500\n",
    "            BFGS_epoch = 0'''\n",
    "        \n",
    "        # We need to understand LBFGS better\n",
    "        epochs = 15000\n",
    "        switch_epoch = 3000\n",
    "        BFGS_epoch = 1000000\n",
    "\n",
    "        optimizer = optim.Adam(t.parameters(), lr=lr, eps=1e-8)\n",
    "        #optimizer = optim.SGD(t.parameters(),lr=lr)\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=0.1, max_iter=1e10, max_eval=1e10, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn='strong_wolfe')\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=0.1, max_iter=100, max_eval=1e10, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100)\n",
    "\n",
    "\n",
    "\n",
    "        #epochs = 100\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=1, max_iter=100, max_eval=None, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn=\"strong_wolfe\")\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n",
    "\n",
    "        log_save = 100000\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        n_train = 1000\n",
    "        \n",
    "        best_loss = 10000\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            if (epoch+1) % switch_epoch == 0:\n",
    "                for opt_param in optimizer.param_groups:\n",
    "                    lr = lr * 0.5\n",
    "                    opt_param['lr'] = lr\n",
    "\n",
    "            if epoch == BFGS_epoch:\n",
    "                # BFGS learning rate. How to set?\n",
    "                optimizer = optim.LBFGS(t.parameters(), lr=0.1, max_iter=1e10, max_eval=1e10, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn='strong_wolfe')\n",
    "\n",
    "            if epoch < BFGS_epoch:\n",
    "                log = 100\n",
    "                batch_size = n_train\n",
    "            else:\n",
    "                log = 1\n",
    "                batch_size = n_train\n",
    "            t.train()\n",
    "\n",
    "\n",
    "            choices = np.random.choice(n_train, batch_size, replace=False)\n",
    "            inputs = input_[choices]\n",
    "\n",
    "            # -------------------------------------------\n",
    "            def loss_closure():\n",
    "                if torch.is_grad_enabled():\n",
    "                    optimizer.zero_grad()\n",
    "                loss_inner = euclidean_loss(t,inputs)\n",
    "                #if loss_inner.requires_grad:\n",
    "                    #loss_inner.backward(retain_graph=True)\n",
    "                    #loss_inner.backward()\n",
    "                loss_inner.backward(retain_graph=True)\n",
    "                return loss_inner\n",
    "            # -------------------------------------------\n",
    "            loss = loss_closure()\n",
    "            # best_loss is trick for better scaling laws\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_epoch = epoch\n",
    "                def loss_closure_test():\n",
    "                    if torch.is_grad_enabled():\n",
    "                        optimizer.zero_grad()\n",
    "                    loss_inner = euclidean_loss(t,input_test_)\n",
    "                    return loss_inner\n",
    "                loss_test = loss_closure_test()\n",
    "            optimizer.step(loss_closure)  # get loss, use to update wts\n",
    "\n",
    "            losses.append(loss.detach().numpy())\n",
    "            losses_all.append(loss.detach().numpy())\n",
    "            '''loss = euclidean_loss(g,t,inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()'''\n",
    "            \n",
    "\n",
    "            if epoch%log == 0:\n",
    "                print('Epoch:  %d | loss: %.12f ' %(epoch, loss))\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    print(\"time={}\".format(duration))\n",
    "    times.append(duration)\n",
    "\n",
    "\n",
    "                \n",
    "    w_old = w\n",
    "    losses_w.append(best_loss.detach().numpy())\n",
    "    losses_w_test.append(loss_test.detach().numpy())\n",
    "    print(\"best_train_loss={}\".format(best_loss.detach().numpy()))\n",
    "    print(\"test_loss={}\".format(loss_test.detach().numpy()))\n",
    "    print(\"best_epoch={}\".format(best_epoch))\n",
    "    \n",
    "np.save('./results_nn/grow_relu2last_adam_nolrdecay',np.array([ws, losses_w, times, losses_w_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.00000000e+00, 1.00000000e+01, 1.50000000e+01, 2.00000000e+01,\n",
       "        2.50000000e+01, 3.00000000e+01, 3.50000000e+01, 4.00000000e+01,\n",
       "        4.50000000e+01, 5.00000000e+01],\n",
       "       [8.59807406e-05, 7.77709283e-06, 1.85453587e-06, 1.28538647e-06,\n",
       "        7.84932354e-07, 6.53617008e-07, 4.89080833e-07, 4.44149123e-07,\n",
       "        3.06509293e-07, 2.62580727e-07],\n",
       "       [3.07229544e+02, 3.27110143e+02, 3.59988416e+02, 3.67166559e+02,\n",
       "        3.89903650e+02, 3.87977752e+02, 4.64365361e+02, 4.56987527e+02,\n",
       "        4.98891059e+02, 5.01484846e+02],\n",
       "       [9.11724128e-05, 1.01527148e-05, 2.49219374e-06, 1.92109724e-06,\n",
       "        1.26929706e-06, 1.05274319e-06, 7.78115748e-07, 7.10916709e-07,\n",
       "        5.33678644e-07, 6.15039426e-07]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./results_nn/grow_relu2last_adam_nolrdecay.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next try: relu2 (not just last layer)\n",
    "\n",
    "plt.plot(ws, losses_w, marker=\"o\")\n",
    "#plt.plot(ws, losses_w_test, marker=\"o\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('NN width',fontsize=15)\n",
    "plt.ylabel('MSE',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "# Doubt: NN may have bad landscapes. BFGS may perform worse than Adam at high loss.\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Define Transformer\n",
    "\n",
    "\n",
    "# (t,rho,z) -> (t',rho',z')\n",
    "class T(nn.Module):\n",
    "    def __init__(self,w=256,a=0.,M=1.):\n",
    "        super(T, self).__init__()\n",
    "        self.l1 = nn.Linear(2,w)\n",
    "        self.l2 = nn.Linear(w,w)\n",
    "        self.l3 = nn.Linear(w,4)\n",
    "        self.a = a\n",
    "        self.M = torch.nn.Parameter(torch.ones(1,)*1., requires_grad=False)\n",
    "        self.eps = torch.nn.Parameter(torch.ones(1,)*0.01, requires_grad=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        # These non-polynomial activation function may not lead to power laws\n",
    "        #f = nn.Tanh()\n",
    "        #f = nn.SiLU()\n",
    "        #f = Rational()\n",
    "        f = nn.ReLU()\n",
    "        self.t = x[:,[0]]\n",
    "        self.x = x[:,[1]]\n",
    "        self.y = x[:,[2]]\n",
    "        self.z = x[:,[3]]\n",
    "        self.r = torch.sqrt(self.x**2+self.y**2+self.z**2)\n",
    "        self.u = torch.sqrt(self.r/(2*self.M))\n",
    "\n",
    "        self.rho = torch.unsqueeze(torch.sqrt(x[:,1]**2+x[:,2]**2),dim=1)\n",
    "        self.rhoz = torch.transpose(torch.stack([self.rho,self.z]),0,1)[:,:,0]\n",
    "        \n",
    "        self.x1 = f(self.l1(self.rhoz))\n",
    "        self.x2 = f(self.l2(self.x1))**2\n",
    "        self.x3 = self.l3(self.x2)\n",
    "\n",
    "        self.dt = self.x3[:,[0]]\n",
    "        self.drho = self.x3[:,[1]]\n",
    "        self.dphi = self.x3[:,[2]]\n",
    "        self.dz = self.x3[:,[3]]\n",
    "        nn_out = torch.empty((x.shape[0], 4), requires_grad=False)\n",
    "        nn_out[:,[0]] = self.dt\n",
    "        nn_out[:,[1]] = (-self.y*self.dphi+self.x*self.drho)\n",
    "        nn_out[:,[2]] = (self.x*self.dphi+self.y*self.drho)\n",
    "        nn_out[:,[3]] = self.dz*self.z\n",
    "\n",
    "        return x + self.eps.unsqueeze(dim=0)*nn_out\n",
    "    \n",
    "    def set_a(self,a):\n",
    "        self.a = a\n",
    "        \n",
    "    def batch_jacobian(self, func, x, create_graph=False):\n",
    "        # x in shape (Batch, Length)\n",
    "        def _func_sum(x):\n",
    "            return func(x).sum(dim=0)\n",
    "        return torch.autograd.functional.jacobian(_func_sum, x, create_graph=create_graph).permute(1,0,2)\n",
    "    \n",
    "    def transform_g(self, x):\n",
    "        jac_ts = self.batch_jacobian(self.forward, x, create_graph=True)\n",
    "        jac_inv_ts = torch.inverse(jac_ts)\n",
    "        return torch.matmul(torch.matmul(jac_inv_ts.permute(0,2,1), g(x)),jac_inv_ts)\n",
    "        \n",
    "    def jac(self, x):\n",
    "        jac_ts = self.batch_jacobian(self.forward, x, create_graph=True)\n",
    "        return jac_ts\n",
    "    \n",
    "\n",
    "def grow(t1, t2, w_s, w_l):\n",
    "\n",
    "    w_mask = torch.zeros(w_l,w_l)\n",
    "    w_mask[:w_s,:w_s] = torch.ones(w_s,w_s)\n",
    "\n",
    "    b_mask = torch.zeros(w_l,)\n",
    "    b_mask[:w_s] = torch.ones(w_s,)\n",
    "\n",
    "    t2.l2.weight.data = t2.l2.weight.data*w_mask\n",
    "    t2.l2.weight.data[:w_s,:w_s] = t1.l2.weight.data\n",
    "    t2.l2.bias.data = t2.l2.bias.data*b_mask\n",
    "    t2.l2.bias.data[:w_s] = t1.l2.bias.data\n",
    "\n",
    "    t2.l1.weight.data[:w_s,:] = t1.l1.weight.data\n",
    "    t2.l1.bias.data[:w_s] = t1.l1.bias.data\n",
    "\n",
    "    t2.l3.weight.data[:,:w_s] = t1.l3.weight.data\n",
    "    t2.l3.bias.data = t1.l3.bias.data\n",
    "    return t2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "n_train = 1000\n",
    "\n",
    "W = torch.normal(0,1,size=(n_train,4),requires_grad=True)\n",
    "input_ = torch.empty(n_train,4, requires_grad=False)\n",
    "input_[:,0] = (torch.rand(n_train, requires_grad=True)-0.5)*3.0 + 1.5\n",
    "rs = torch.linspace(3,4,steps=n_train+1)[:n_train]\n",
    "input_[:,1:] = W[:,1:]/torch.norm(W[:,1:], dim=1, keepdim=True)*torch.unsqueeze(rs, dim=1)\n",
    "\n",
    "n_test = 1000\n",
    "\n",
    "W_test = torch.normal(0,1,size=(n_test,4),requires_grad=True)\n",
    "input_test_ = torch.empty(n_test,4, requires_grad=False)\n",
    "input_test_[:,0] = (torch.rand(n_test, requires_grad=True)-0.5)*3.0 + 1.5\n",
    "rs_test = torch.linspace(3,4,steps=n_test+1)[:n_test]\n",
    "input_test_[:,1:] = W_test[:,1:]/torch.norm(W_test[:,1:], dim=1, keepdim=True)*torch.unsqueeze(rs_test, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=5\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.840038895607 \n",
      "Epoch:  1 | loss: 0.030007967725 \n",
      "Epoch:  2 | loss: 0.027235690504 \n",
      "Epoch:  3 | loss: 0.027235690504 \n",
      "Epoch:  4 | loss: 0.027235692367 \n",
      "Epoch:  5 | loss: 0.027235694230 \n",
      "Epoch:  6 | loss: 0.027235692367 \n",
      "Epoch:  7 | loss: 0.027235692367 \n",
      "Epoch:  8 | loss: 0.027235688642 \n",
      "Epoch:  9 | loss: 0.027235690504 \n",
      "Epoch:  10 | loss: 0.027235690504 \n",
      "Epoch:  11 | loss: 0.027235692367 \n",
      "Epoch:  12 | loss: 0.027235692367 \n",
      "Epoch:  13 | loss: 0.027235690504 \n",
      "Epoch:  14 | loss: 0.027235694230 \n",
      "Epoch:  15 | loss: 0.027235694230 \n",
      "Epoch:  16 | loss: 0.027235692367 \n",
      "Epoch:  17 | loss: 0.027235692367 \n",
      "Epoch:  18 | loss: 0.027235694230 \n",
      "Epoch:  19 | loss: 0.027235694230 \n",
      "Epoch:  20 | loss: 0.027235692367 \n",
      "Epoch:  21 | loss: 0.027235692367 \n",
      "Epoch:  22 | loss: 0.027235690504 \n",
      "Epoch:  23 | loss: 0.027235694230 \n",
      "Epoch:  24 | loss: 0.027235690504 \n",
      "Epoch:  25 | loss: 0.027235694230 \n",
      "Epoch:  26 | loss: 0.027235692367 \n",
      "Epoch:  27 | loss: 0.027235690504 \n",
      "Epoch:  28 | loss: 0.027235692367 \n",
      "Epoch:  29 | loss: 0.027235694230 \n",
      "Epoch:  30 | loss: 0.027235694230 \n",
      "Epoch:  31 | loss: 0.027235692367 \n",
      "Epoch:  32 | loss: 0.027235690504 \n",
      "Epoch:  33 | loss: 0.027235692367 \n",
      "Epoch:  34 | loss: 0.027235692367 \n",
      "Epoch:  35 | loss: 0.027235692367 \n",
      "Epoch:  36 | loss: 0.027235692367 \n",
      "Epoch:  37 | loss: 0.027235690504 \n",
      "Epoch:  38 | loss: 0.027235692367 \n",
      "Epoch:  39 | loss: 0.027235694230 \n",
      "Epoch:  40 | loss: 0.027235690504 \n",
      "Epoch:  41 | loss: 0.027235692367 \n",
      "Epoch:  42 | loss: 0.027235690504 \n",
      "Epoch:  43 | loss: 0.027235694230 \n",
      "Epoch:  44 | loss: 0.027235692367 \n",
      "Epoch:  45 | loss: 0.027235690504 \n",
      "Epoch:  46 | loss: 0.027235694230 \n",
      "Epoch:  47 | loss: 0.027235690504 \n",
      "Epoch:  48 | loss: 0.027235690504 \n",
      "Epoch:  49 | loss: 0.027235690504 \n",
      "Epoch:  50 | loss: 0.027235694230 \n",
      "Epoch:  51 | loss: 0.027235694230 \n",
      "Epoch:  52 | loss: 0.027235692367 \n",
      "Epoch:  53 | loss: 0.027235692367 \n",
      "Epoch:  54 | loss: 0.027235692367 \n",
      "Epoch:  55 | loss: 0.027235692367 \n",
      "Epoch:  56 | loss: 0.027235690504 \n",
      "Epoch:  57 | loss: 0.027235692367 \n",
      "Epoch:  58 | loss: 0.027235692367 \n",
      "Epoch:  59 | loss: 0.027235696092 \n",
      "Epoch:  60 | loss: 0.027235692367 \n",
      "Epoch:  61 | loss: 0.027235692367 \n",
      "Epoch:  62 | loss: 0.027235690504 \n",
      "Epoch:  63 | loss: 0.027235692367 \n",
      "Epoch:  64 | loss: 0.027235692367 \n",
      "Epoch:  65 | loss: 0.027235694230 \n",
      "Epoch:  66 | loss: 0.027235692367 \n",
      "Epoch:  67 | loss: 0.027235690504 \n",
      "Epoch:  68 | loss: 0.027235692367 \n",
      "Epoch:  69 | loss: 0.027235694230 \n",
      "Epoch:  70 | loss: 0.027235694230 \n",
      "Epoch:  71 | loss: 0.027235692367 \n",
      "Epoch:  72 | loss: 0.027235692367 \n",
      "Epoch:  73 | loss: 0.027235692367 \n",
      "Epoch:  74 | loss: 0.027235692367 \n",
      "Epoch:  75 | loss: 0.027235692367 \n",
      "Epoch:  76 | loss: 0.027235692367 \n",
      "Epoch:  77 | loss: 0.027235692367 \n",
      "Epoch:  78 | loss: 0.027235690504 \n",
      "Epoch:  79 | loss: 0.027235692367 \n",
      "Epoch:  80 | loss: 0.027235692367 \n",
      "Epoch:  81 | loss: 0.027235694230 \n",
      "Epoch:  82 | loss: 0.027235690504 \n",
      "Epoch:  83 | loss: 0.027235690504 \n",
      "Epoch:  84 | loss: 0.027235690504 \n",
      "Epoch:  85 | loss: 0.027235690504 \n",
      "Epoch:  86 | loss: 0.027235692367 \n",
      "Epoch:  87 | loss: 0.027235692367 \n",
      "Epoch:  88 | loss: 0.027235690504 \n",
      "Epoch:  89 | loss: 0.027235692367 \n",
      "Epoch:  90 | loss: 0.027235694230 \n",
      "Epoch:  91 | loss: 0.027235694230 \n",
      "Epoch:  92 | loss: 0.027235692367 \n",
      "Epoch:  93 | loss: 0.027235692367 \n",
      "Epoch:  94 | loss: 0.027235692367 \n",
      "Epoch:  95 | loss: 0.027235692367 \n",
      "Epoch:  96 | loss: 0.027235694230 \n",
      "Epoch:  97 | loss: 0.027235692367 \n",
      "Epoch:  98 | loss: 0.027235692367 \n",
      "Epoch:  99 | loss: 0.027235690504 \n",
      "Epoch:  100 | loss: 0.027235694230 \n",
      "Epoch:  101 | loss: 0.027235692367 \n",
      "Epoch:  102 | loss: 0.027235692367 \n",
      "Epoch:  103 | loss: 0.027235692367 \n",
      "Epoch:  104 | loss: 0.027235694230 \n",
      "Epoch:  105 | loss: 0.027235692367 \n",
      "Epoch:  106 | loss: 0.027235692367 \n",
      "Epoch:  107 | loss: 0.027235694230 \n",
      "Epoch:  108 | loss: 0.027235694230 \n",
      "Epoch:  109 | loss: 0.027235694230 \n",
      "Epoch:  110 | loss: 0.027235690504 \n",
      "Epoch:  111 | loss: 0.027235692367 \n",
      "Epoch:  112 | loss: 0.027235692367 \n",
      "Epoch:  113 | loss: 0.027235690504 \n",
      "Epoch:  114 | loss: 0.027235692367 \n",
      "Epoch:  115 | loss: 0.027235692367 \n",
      "Epoch:  116 | loss: 0.027235690504 \n",
      "Epoch:  117 | loss: 0.027235692367 \n",
      "Epoch:  118 | loss: 0.027235694230 \n",
      "Epoch:  119 | loss: 0.027235690504 \n",
      "Epoch:  120 | loss: 0.027235690504 \n",
      "Epoch:  121 | loss: 0.027235690504 \n",
      "Epoch:  122 | loss: 0.027235690504 \n",
      "Epoch:  123 | loss: 0.027235692367 \n",
      "Epoch:  124 | loss: 0.027235690504 \n",
      "Epoch:  125 | loss: 0.027235692367 \n",
      "Epoch:  126 | loss: 0.027235690504 \n",
      "Epoch:  127 | loss: 0.027235692367 \n",
      "Epoch:  128 | loss: 0.027235690504 \n",
      "Epoch:  129 | loss: 0.027235690504 \n",
      "Epoch:  130 | loss: 0.027235692367 \n",
      "Epoch:  131 | loss: 0.027235692367 \n",
      "Epoch:  132 | loss: 0.027235692367 \n",
      "Epoch:  133 | loss: 0.027235690504 \n",
      "Epoch:  134 | loss: 0.027235692367 \n",
      "Epoch:  135 | loss: 0.027235690504 \n",
      "Epoch:  136 | loss: 0.027235690504 \n",
      "Epoch:  137 | loss: 0.027235690504 \n",
      "Epoch:  138 | loss: 0.027235692367 \n",
      "Epoch:  139 | loss: 0.027235690504 \n",
      "Epoch:  140 | loss: 0.027235692367 \n",
      "Epoch:  141 | loss: 0.027235692367 \n",
      "Epoch:  142 | loss: 0.027235690504 \n",
      "Epoch:  143 | loss: 0.027235690504 \n",
      "Epoch:  144 | loss: 0.027235694230 \n",
      "Epoch:  145 | loss: 0.027235692367 \n",
      "Epoch:  146 | loss: 0.027235692367 \n",
      "Epoch:  147 | loss: 0.027235694230 \n",
      "Epoch:  148 | loss: 0.027235694230 \n",
      "Epoch:  149 | loss: 0.027235692367 \n",
      "Epoch:  150 | loss: 0.027235694230 \n",
      "Epoch:  151 | loss: 0.027235690504 \n",
      "Epoch:  152 | loss: 0.027235692367 \n",
      "Epoch:  153 | loss: 0.027235690504 \n",
      "Epoch:  154 | loss: 0.027235694230 \n",
      "Epoch:  155 | loss: 0.027235690504 \n",
      "Epoch:  156 | loss: 0.027235694230 \n",
      "Epoch:  157 | loss: 0.027235690504 \n",
      "Epoch:  158 | loss: 0.027235690504 \n",
      "Epoch:  159 | loss: 0.027235694230 \n",
      "Epoch:  160 | loss: 0.027235692367 \n",
      "Epoch:  161 | loss: 0.027235694230 \n",
      "Epoch:  162 | loss: 0.027235690504 \n",
      "Epoch:  163 | loss: 0.027235692367 \n",
      "Epoch:  164 | loss: 0.027235690504 \n",
      "Epoch:  165 | loss: 0.027235692367 \n",
      "Epoch:  166 | loss: 0.027235692367 \n",
      "Epoch:  167 | loss: 0.027235694230 \n",
      "Epoch:  168 | loss: 0.027235690504 \n",
      "Epoch:  169 | loss: 0.027235692367 \n",
      "Epoch:  170 | loss: 0.027235694230 \n",
      "Epoch:  171 | loss: 0.027235690504 \n",
      "Epoch:  172 | loss: 0.027235690504 \n",
      "Epoch:  173 | loss: 0.027235690504 \n",
      "Epoch:  174 | loss: 0.027235692367 \n",
      "Epoch:  175 | loss: 0.027235690504 \n",
      "Epoch:  176 | loss: 0.027235690504 \n",
      "Epoch:  177 | loss: 0.027235690504 \n",
      "Epoch:  178 | loss: 0.027235692367 \n",
      "Epoch:  179 | loss: 0.027235690504 \n",
      "Epoch:  180 | loss: 0.027235690504 \n",
      "Epoch:  181 | loss: 0.027235692367 \n",
      "Epoch:  182 | loss: 0.027235690504 \n",
      "Epoch:  183 | loss: 0.027235690504 \n",
      "Epoch:  184 | loss: 0.027235690504 \n",
      "Epoch:  185 | loss: 0.027235692367 \n",
      "Epoch:  186 | loss: 0.027235692367 \n",
      "Epoch:  187 | loss: 0.027235690504 \n",
      "Epoch:  188 | loss: 0.027235692367 \n",
      "Epoch:  189 | loss: 0.027235690504 \n",
      "Epoch:  190 | loss: 0.027235690504 \n",
      "Epoch:  191 | loss: 0.027235690504 \n",
      "Epoch:  192 | loss: 0.027235694230 \n",
      "Epoch:  193 | loss: 0.027235690504 \n",
      "Epoch:  194 | loss: 0.027235694230 \n",
      "Epoch:  195 | loss: 0.027235690504 \n",
      "Epoch:  196 | loss: 0.027235692367 \n",
      "Epoch:  197 | loss: 0.027235692367 \n",
      "Epoch:  198 | loss: 0.027235690504 \n",
      "Epoch:  199 | loss: 0.027235692367 \n",
      "Epoch:  200 | loss: 0.027235694230 \n",
      "Epoch:  201 | loss: 0.027235690504 \n",
      "Epoch:  202 | loss: 0.027235690504 \n",
      "Epoch:  203 | loss: 0.027235690504 \n",
      "Epoch:  204 | loss: 0.027235690504 \n",
      "Epoch:  205 | loss: 0.027235694230 \n",
      "Epoch:  206 | loss: 0.027235690504 \n",
      "Epoch:  207 | loss: 0.027235690504 \n",
      "Epoch:  208 | loss: 0.027235692367 \n",
      "Epoch:  209 | loss: 0.027235692367 \n",
      "Epoch:  210 | loss: 0.027235690504 \n",
      "Epoch:  211 | loss: 0.027235692367 \n",
      "Epoch:  212 | loss: 0.027235690504 \n",
      "Epoch:  213 | loss: 0.027235690504 \n",
      "Epoch:  214 | loss: 0.027235692367 \n",
      "Epoch:  215 | loss: 0.027235692367 \n",
      "Epoch:  216 | loss: 0.027235690504 \n",
      "Epoch:  217 | loss: 0.027235690504 \n",
      "Epoch:  218 | loss: 0.027235690504 \n",
      "Epoch:  219 | loss: 0.027235690504 \n",
      "Epoch:  220 | loss: 0.027235692367 \n",
      "Epoch:  221 | loss: 0.027235690504 \n",
      "Epoch:  222 | loss: 0.027235690504 \n",
      "Epoch:  223 | loss: 0.027235690504 \n",
      "Epoch:  224 | loss: 0.027235690504 \n",
      "Epoch:  225 | loss: 0.027235690504 \n",
      "Epoch:  226 | loss: 0.027235690504 \n",
      "Epoch:  227 | loss: 0.027235690504 \n",
      "Epoch:  228 | loss: 0.027235692367 \n",
      "Epoch:  229 | loss: 0.027235692367 \n",
      "Epoch:  230 | loss: 0.027235690504 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  231 | loss: 0.027235692367 \n",
      "Epoch:  232 | loss: 0.027235692367 \n",
      "Epoch:  233 | loss: 0.027235690504 \n",
      "Epoch:  234 | loss: 0.027235692367 \n",
      "Epoch:  235 | loss: 0.027235690504 \n",
      "Epoch:  236 | loss: 0.027235690504 \n",
      "Epoch:  237 | loss: 0.027235690504 \n",
      "Epoch:  238 | loss: 0.027235690504 \n",
      "Epoch:  239 | loss: 0.027235694230 \n",
      "Epoch:  240 | loss: 0.027235692367 \n",
      "Epoch:  241 | loss: 0.027235690504 \n",
      "Epoch:  242 | loss: 0.027235692367 \n",
      "Epoch:  243 | loss: 0.027235694230 \n",
      "Epoch:  244 | loss: 0.027235692367 \n",
      "Epoch:  245 | loss: 0.027235690504 \n",
      "Epoch:  246 | loss: 0.027235692367 \n",
      "Epoch:  247 | loss: 0.027235690504 \n",
      "Epoch:  248 | loss: 0.027235692367 \n",
      "Epoch:  249 | loss: 0.027235692367 \n",
      "Epoch:  250 | loss: 0.027235690504 \n",
      "Epoch:  251 | loss: 0.027235692367 \n",
      "Epoch:  252 | loss: 0.027235690504 \n",
      "Epoch:  253 | loss: 0.027235692367 \n",
      "Epoch:  254 | loss: 0.027235692367 \n",
      "Epoch:  255 | loss: 0.027235688642 \n",
      "Epoch:  256 | loss: 0.027235690504 \n",
      "Epoch:  257 | loss: 0.027235692367 \n",
      "Epoch:  258 | loss: 0.027235694230 \n",
      "Epoch:  259 | loss: 0.027235690504 \n",
      "Epoch:  260 | loss: 0.027235690504 \n",
      "Epoch:  261 | loss: 0.027235688642 \n",
      "Epoch:  262 | loss: 0.027235692367 \n",
      "Epoch:  263 | loss: 0.027235690504 \n",
      "Epoch:  264 | loss: 0.027235690504 \n",
      "Epoch:  265 | loss: 0.027235690504 \n",
      "Epoch:  266 | loss: 0.027235690504 \n",
      "Epoch:  267 | loss: 0.027235690504 \n",
      "Epoch:  268 | loss: 0.027235692367 \n",
      "Epoch:  269 | loss: 0.027235690504 \n",
      "Epoch:  270 | loss: 0.027235692367 \n",
      "Epoch:  271 | loss: 0.027235690504 \n",
      "Epoch:  272 | loss: 0.027235692367 \n",
      "Epoch:  273 | loss: 0.027235692367 \n",
      "Epoch:  274 | loss: 0.027235692367 \n",
      "Epoch:  275 | loss: 0.027235690504 \n",
      "Epoch:  276 | loss: 0.027235690504 \n",
      "Epoch:  277 | loss: 0.027235692367 \n",
      "Epoch:  278 | loss: 0.027235692367 \n",
      "Epoch:  279 | loss: 0.027235692367 \n",
      "Epoch:  280 | loss: 0.027235692367 \n",
      "Epoch:  281 | loss: 0.027235692367 \n",
      "Epoch:  282 | loss: 0.027235692367 \n",
      "Epoch:  283 | loss: 0.027235692367 \n",
      "Epoch:  284 | loss: 0.027235694230 \n",
      "Epoch:  285 | loss: 0.027235690504 \n",
      "Epoch:  286 | loss: 0.027235690504 \n",
      "Epoch:  287 | loss: 0.027235692367 \n",
      "Epoch:  288 | loss: 0.027235690504 \n",
      "Epoch:  289 | loss: 0.027235694230 \n",
      "Epoch:  290 | loss: 0.027235690504 \n",
      "Epoch:  291 | loss: 0.027235692367 \n",
      "Epoch:  292 | loss: 0.027235690504 \n",
      "Epoch:  293 | loss: 0.027235692367 \n",
      "Epoch:  294 | loss: 0.027235690504 \n",
      "Epoch:  295 | loss: 0.027235688642 \n",
      "Epoch:  296 | loss: 0.027235692367 \n",
      "Epoch:  297 | loss: 0.027235692367 \n",
      "Epoch:  298 | loss: 0.027235690504 \n",
      "Epoch:  299 | loss: 0.027235692367 \n",
      "time=25.159472227096558\n",
      "best_train_loss=0.027235688641667366\n",
      "test_loss=0.02617640607059002\n",
      "best_epoch=8\n",
      "w=10\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.027235692367 \n",
      "Epoch:  1 | loss: 0.027235379443 \n",
      "Epoch:  2 | loss: 0.027235377580 \n",
      "Epoch:  3 | loss: 0.027235379443 \n",
      "Epoch:  4 | loss: 0.027235377580 \n",
      "Epoch:  5 | loss: 0.027235377580 \n",
      "Epoch:  6 | loss: 0.027235379443 \n",
      "Epoch:  7 | loss: 0.027235379443 \n",
      "Epoch:  8 | loss: 0.027235377580 \n",
      "Epoch:  9 | loss: 0.027235381305 \n",
      "Epoch:  10 | loss: 0.027235379443 \n",
      "Epoch:  11 | loss: 0.027235379443 \n",
      "Epoch:  12 | loss: 0.027235379443 \n",
      "Epoch:  13 | loss: 0.027235381305 \n",
      "Epoch:  14 | loss: 0.027235381305 \n",
      "Epoch:  15 | loss: 0.027235379443 \n",
      "Epoch:  16 | loss: 0.027235379443 \n",
      "Epoch:  17 | loss: 0.027235379443 \n",
      "Epoch:  18 | loss: 0.027235377580 \n",
      "Epoch:  19 | loss: 0.027235377580 \n",
      "Epoch:  20 | loss: 0.027235379443 \n",
      "Epoch:  21 | loss: 0.027235375717 \n",
      "Epoch:  22 | loss: 0.027235379443 \n",
      "Epoch:  23 | loss: 0.027235375717 \n",
      "Epoch:  24 | loss: 0.027235379443 \n",
      "Epoch:  25 | loss: 0.027235377580 \n",
      "Epoch:  26 | loss: 0.027235377580 \n",
      "Epoch:  27 | loss: 0.027235381305 \n",
      "Epoch:  28 | loss: 0.027235379443 \n",
      "Epoch:  29 | loss: 0.027235377580 \n",
      "Epoch:  30 | loss: 0.027235375717 \n",
      "Epoch:  31 | loss: 0.027235379443 \n",
      "Epoch:  32 | loss: 0.027235379443 \n",
      "Epoch:  33 | loss: 0.027235373855 \n",
      "Epoch:  34 | loss: 0.027235377580 \n",
      "Epoch:  35 | loss: 0.027235377580 \n",
      "Epoch:  36 | loss: 0.027235379443 \n",
      "Epoch:  37 | loss: 0.027235379443 \n",
      "Epoch:  38 | loss: 0.027235379443 \n",
      "Epoch:  39 | loss: 0.027235379443 \n",
      "Epoch:  40 | loss: 0.027235379443 \n",
      "Epoch:  41 | loss: 0.027235379443 \n",
      "Epoch:  42 | loss: 0.027235377580 \n",
      "Epoch:  43 | loss: 0.027235379443 \n",
      "Epoch:  44 | loss: 0.027235377580 \n",
      "Epoch:  45 | loss: 0.027235377580 \n",
      "Epoch:  46 | loss: 0.027235379443 \n",
      "Epoch:  47 | loss: 0.027235377580 \n",
      "Epoch:  48 | loss: 0.027235375717 \n",
      "Epoch:  49 | loss: 0.027235379443 \n",
      "Epoch:  50 | loss: 0.027235377580 \n",
      "Epoch:  51 | loss: 0.027235377580 \n",
      "Epoch:  52 | loss: 0.027235379443 \n",
      "Epoch:  53 | loss: 0.027235379443 \n",
      "Epoch:  54 | loss: 0.027235379443 \n",
      "Epoch:  55 | loss: 0.027235377580 \n",
      "Epoch:  56 | loss: 0.027235379443 \n",
      "Epoch:  57 | loss: 0.027235379443 \n",
      "Epoch:  58 | loss: 0.027235377580 \n",
      "Epoch:  59 | loss: 0.027235379443 \n",
      "Epoch:  60 | loss: 0.027235379443 \n",
      "Epoch:  61 | loss: 0.027235377580 \n",
      "Epoch:  62 | loss: 0.027235379443 \n",
      "Epoch:  63 | loss: 0.027235377580 \n",
      "Epoch:  64 | loss: 0.027235379443 \n",
      "Epoch:  65 | loss: 0.027235377580 \n",
      "Epoch:  66 | loss: 0.027235379443 \n",
      "Epoch:  67 | loss: 0.027235379443 \n",
      "Epoch:  68 | loss: 0.027235379443 \n",
      "Epoch:  69 | loss: 0.027235379443 \n",
      "Epoch:  70 | loss: 0.027235379443 \n",
      "Epoch:  71 | loss: 0.027235379443 \n",
      "Epoch:  72 | loss: 0.027235377580 \n",
      "Epoch:  73 | loss: 0.027235377580 \n",
      "Epoch:  74 | loss: 0.027235379443 \n",
      "Epoch:  75 | loss: 0.027235379443 \n",
      "Epoch:  76 | loss: 0.027235379443 \n",
      "Epoch:  77 | loss: 0.027235377580 \n",
      "Epoch:  78 | loss: 0.027235379443 \n",
      "Epoch:  79 | loss: 0.027235379443 \n",
      "Epoch:  80 | loss: 0.027235381305 \n",
      "Epoch:  81 | loss: 0.027235379443 \n",
      "Epoch:  82 | loss: 0.027235377580 \n",
      "Epoch:  83 | loss: 0.027235379443 \n",
      "Epoch:  84 | loss: 0.027235379443 \n",
      "Epoch:  85 | loss: 0.027235379443 \n",
      "Epoch:  86 | loss: 0.027235377580 \n",
      "Epoch:  87 | loss: 0.027235377580 \n",
      "Epoch:  88 | loss: 0.027235377580 \n",
      "Epoch:  89 | loss: 0.027235379443 \n",
      "Epoch:  90 | loss: 0.027235379443 \n",
      "Epoch:  91 | loss: 0.027235379443 \n",
      "Epoch:  92 | loss: 0.027235379443 \n",
      "Epoch:  93 | loss: 0.027235377580 \n",
      "Epoch:  94 | loss: 0.027235377580 \n",
      "Epoch:  95 | loss: 0.027235377580 \n",
      "Epoch:  96 | loss: 0.027235379443 \n",
      "Epoch:  97 | loss: 0.027235379443 \n",
      "Epoch:  98 | loss: 0.027235377580 \n",
      "Epoch:  99 | loss: 0.027235375717 \n",
      "Epoch:  100 | loss: 0.027235195041 \n",
      "Epoch:  101 | loss: 0.027235010639 \n",
      "Epoch:  102 | loss: 0.027234980837 \n",
      "Epoch:  103 | loss: 0.027234800160 \n",
      "Epoch:  104 | loss: 0.027234649286 \n",
      "Epoch:  105 | loss: 0.027234476060 \n",
      "Epoch:  106 | loss: 0.027234397829 \n",
      "Epoch:  107 | loss: 0.027234228328 \n",
      "Epoch:  108 | loss: 0.027234058827 \n",
      "Epoch:  109 | loss: 0.027233889326 \n",
      "Epoch:  110 | loss: 0.027233714238 \n",
      "Epoch:  111 | loss: 0.027233544737 \n",
      "Epoch:  112 | loss: 0.027233380824 \n",
      "Epoch:  113 | loss: 0.027233218774 \n",
      "Epoch:  114 | loss: 0.027233054861 \n",
      "Epoch:  115 | loss: 0.027232892811 \n",
      "Epoch:  116 | loss: 0.027232732624 \n",
      "Epoch:  117 | loss: 0.027232564986 \n",
      "Epoch:  118 | loss: 0.027232524008 \n",
      "Epoch:  119 | loss: 0.027232358232 \n",
      "Epoch:  120 | loss: 0.027232203633 \n",
      "Epoch:  121 | loss: 0.027232043445 \n",
      "Epoch:  122 | loss: 0.027231883258 \n",
      "Epoch:  123 | loss: 0.027231873944 \n",
      "Epoch:  124 | loss: 0.027231717482 \n",
      "Epoch:  125 | loss: 0.027231564745 \n",
      "Epoch:  126 | loss: 0.027231412008 \n",
      "Epoch:  127 | loss: 0.027231261134 \n",
      "Epoch:  128 | loss: 0.027231112123 \n",
      "Epoch:  129 | loss: 0.027230991051 \n",
      "Epoch:  130 | loss: 0.027230877429 \n",
      "Epoch:  131 | loss: 0.027230830863 \n",
      "Epoch:  132 | loss: 0.027230747044 \n",
      "Epoch:  133 | loss: 0.027230717242 \n",
      "Epoch:  134 | loss: 0.027230611071 \n",
      "Epoch:  135 | loss: 0.027230542153 \n",
      "Epoch:  136 | loss: 0.027230396867 \n",
      "Epoch:  137 | loss: 0.027230255306 \n",
      "Epoch:  138 | loss: 0.027230111882 \n",
      "Epoch:  139 | loss: 0.027230115607 \n",
      "Epoch:  140 | loss: 0.027229981497 \n",
      "Epoch:  141 | loss: 0.027229838073 \n",
      "Epoch:  142 | loss: 0.027229750529 \n",
      "Epoch:  143 | loss: 0.027229607105 \n",
      "Epoch:  144 | loss: 0.027229465544 \n",
      "Epoch:  145 | loss: 0.027229329571 \n",
      "Epoch:  146 | loss: 0.027229206637 \n",
      "Epoch:  147 | loss: 0.027229065076 \n",
      "Epoch:  148 | loss: 0.027229042724 \n",
      "Epoch:  149 | loss: 0.027228947729 \n",
      "Epoch:  150 | loss: 0.027228940278 \n",
      "Epoch:  151 | loss: 0.027228888124 \n",
      "Epoch:  152 | loss: 0.027228862047 \n",
      "Epoch:  153 | loss: 0.027228733525 \n",
      "Epoch:  154 | loss: 0.027228601277 \n",
      "Epoch:  155 | loss: 0.027228603140 \n",
      "Epoch:  156 | loss: 0.027228577062 \n",
      "Epoch:  157 | loss: 0.027228487656 \n",
      "Epoch:  158 | loss: 0.027228487656 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  159 | loss: 0.027228489518 \n",
      "Epoch:  160 | loss: 0.027228454128 \n",
      "Epoch:  161 | loss: 0.027228416875 \n",
      "Epoch:  162 | loss: 0.027228336781 \n",
      "Epoch:  163 | loss: 0.027228288352 \n",
      "Epoch:  164 | loss: 0.027228279039 \n",
      "Epoch:  165 | loss: 0.027228256688 \n",
      "Epoch:  166 | loss: 0.027228141204 \n",
      "Epoch:  167 | loss: 0.027228133753 \n",
      "Epoch:  168 | loss: 0.027228074148 \n",
      "Epoch:  169 | loss: 0.027228018269 \n",
      "Epoch:  170 | loss: 0.027227954939 \n",
      "Epoch:  171 | loss: 0.027227908373 \n",
      "Epoch:  172 | loss: 0.027227776125 \n",
      "Epoch:  173 | loss: 0.027227774262 \n",
      "Epoch:  174 | loss: 0.027227718383 \n",
      "Epoch:  175 | loss: 0.027227601036 \n",
      "Epoch:  176 | loss: 0.027227569371 \n",
      "Epoch:  177 | loss: 0.027227448300 \n",
      "Epoch:  178 | loss: 0.027227383107 \n",
      "Epoch:  179 | loss: 0.027227260172 \n",
      "Epoch:  180 | loss: 0.027227241546 \n",
      "Epoch:  181 | loss: 0.027227120474 \n",
      "Epoch:  182 | loss: 0.027227098122 \n",
      "Epoch:  183 | loss: 0.027227053419 \n",
      "Epoch:  184 | loss: 0.027227018028 \n",
      "Epoch:  185 | loss: 0.027226969600 \n",
      "Epoch:  186 | loss: 0.027226923034 \n",
      "Epoch:  187 | loss: 0.027226893231 \n",
      "Epoch:  188 | loss: 0.027226788923 \n",
      "Epoch:  189 | loss: 0.027226693928 \n",
      "Epoch:  190 | loss: 0.027226665989 \n",
      "Epoch:  191 | loss: 0.027226543054 \n",
      "Epoch:  192 | loss: 0.027226520702 \n",
      "Epoch:  193 | loss: 0.027226397768 \n",
      "Epoch:  194 | loss: 0.027226392180 \n",
      "Epoch:  195 | loss: 0.027226308361 \n",
      "Epoch:  196 | loss: 0.027226282284 \n",
      "Epoch:  197 | loss: 0.027226248756 \n",
      "Epoch:  198 | loss: 0.027226239443 \n",
      "Epoch:  199 | loss: 0.027226185426 \n",
      "Epoch:  200 | loss: 0.027225958183 \n",
      "Epoch:  201 | loss: 0.027225732803 \n",
      "Epoch:  202 | loss: 0.027225503698 \n",
      "Epoch:  203 | loss: 0.027225276455 \n",
      "Epoch:  204 | loss: 0.027225052938 \n",
      "Epoch:  205 | loss: 0.027224838734 \n",
      "Epoch:  206 | loss: 0.027224618942 \n",
      "Epoch:  207 | loss: 0.027224408463 \n",
      "Epoch:  208 | loss: 0.027224199846 \n",
      "Epoch:  209 | loss: 0.027223985642 \n",
      "Epoch:  210 | loss: 0.027223784477 \n",
      "Epoch:  211 | loss: 0.027223579586 \n",
      "Epoch:  212 | loss: 0.027223385870 \n",
      "Epoch:  213 | loss: 0.027223179117 \n",
      "Epoch:  214 | loss: 0.027222983539 \n",
      "Epoch:  215 | loss: 0.027222787961 \n",
      "Epoch:  216 | loss: 0.027222597972 \n",
      "Epoch:  217 | loss: 0.027222398669 \n",
      "Epoch:  218 | loss: 0.027222212404 \n",
      "Epoch:  219 | loss: 0.027222024277 \n",
      "Epoch:  220 | loss: 0.027221832424 \n",
      "Epoch:  221 | loss: 0.027221642435 \n",
      "Epoch:  222 | loss: 0.027221461758 \n",
      "Epoch:  223 | loss: 0.027221282944 \n",
      "Epoch:  224 | loss: 0.027221104130 \n",
      "Epoch:  225 | loss: 0.027220919728 \n",
      "Epoch:  226 | loss: 0.027220744640 \n",
      "Epoch:  227 | loss: 0.027220569551 \n",
      "Epoch:  228 | loss: 0.027220388874 \n",
      "Epoch:  229 | loss: 0.027220215648 \n",
      "Epoch:  230 | loss: 0.027220046148 \n",
      "Epoch:  231 | loss: 0.027219871059 \n",
      "Epoch:  232 | loss: 0.027219701558 \n",
      "Epoch:  233 | loss: 0.027219533920 \n",
      "Epoch:  234 | loss: 0.027219364420 \n",
      "Epoch:  235 | loss: 0.027219202369 \n",
      "Epoch:  236 | loss: 0.027219042182 \n",
      "Epoch:  237 | loss: 0.027218887582 \n",
      "Epoch:  238 | loss: 0.027218723670 \n",
      "Epoch:  239 | loss: 0.027218561620 \n",
      "Epoch:  240 | loss: 0.027218401432 \n",
      "Epoch:  241 | loss: 0.027218248695 \n",
      "Epoch:  242 | loss: 0.027218202129 \n",
      "Epoch:  243 | loss: 0.027218051255 \n",
      "Epoch:  244 | loss: 0.027217898518 \n",
      "Epoch:  245 | loss: 0.027217742056 \n",
      "Epoch:  246 | loss: 0.027217591181 \n",
      "Epoch:  247 | loss: 0.027217440307 \n",
      "Epoch:  248 | loss: 0.027217291296 \n",
      "Epoch:  249 | loss: 0.027217153460 \n",
      "Epoch:  250 | loss: 0.027217056602 \n",
      "Epoch:  251 | loss: 0.027216989547 \n",
      "Epoch:  252 | loss: 0.027216846123 \n",
      "Epoch:  253 | loss: 0.027216702700 \n",
      "Epoch:  254 | loss: 0.027216564864 \n",
      "Epoch:  255 | loss: 0.027216551825 \n",
      "Epoch:  256 | loss: 0.027216413990 \n",
      "Epoch:  257 | loss: 0.027216274291 \n",
      "Epoch:  258 | loss: 0.027216136456 \n",
      "Epoch:  259 | loss: 0.027216004208 \n",
      "Epoch:  260 | loss: 0.027215868235 \n",
      "Epoch:  261 | loss: 0.027215763927 \n",
      "Epoch:  262 | loss: 0.027215635404 \n",
      "Epoch:  263 | loss: 0.027215499431 \n",
      "Epoch:  264 | loss: 0.027215363458 \n",
      "Epoch:  265 | loss: 0.027215231210 \n",
      "Epoch:  266 | loss: 0.027215097100 \n",
      "Epoch:  267 | loss: 0.027214964852 \n",
      "Epoch:  268 | loss: 0.027214840055 \n",
      "Epoch:  269 | loss: 0.027214709669 \n",
      "Epoch:  270 | loss: 0.027214583009 \n",
      "Epoch:  271 | loss: 0.027214452624 \n",
      "Epoch:  272 | loss: 0.027214329690 \n",
      "Epoch:  273 | loss: 0.027214210480 \n",
      "Epoch:  274 | loss: 0.027214100584 \n",
      "Epoch:  275 | loss: 0.027214000002 \n",
      "Epoch:  276 | loss: 0.027213929221 \n",
      "Epoch:  277 | loss: 0.027213811874 \n",
      "Epoch:  278 | loss: 0.027213778347 \n",
      "Epoch:  279 | loss: 0.027213742957 \n",
      "Epoch:  280 | loss: 0.027213649824 \n",
      "Epoch:  281 | loss: 0.027213528752 \n",
      "Epoch:  282 | loss: 0.027213409543 \n",
      "Epoch:  283 | loss: 0.027213290334 \n",
      "Epoch:  284 | loss: 0.027213176712 \n",
      "Epoch:  285 | loss: 0.027213063091 \n",
      "Epoch:  286 | loss: 0.027212951332 \n",
      "Epoch:  287 | loss: 0.027212873101 \n",
      "Epoch:  288 | loss: 0.027212813497 \n",
      "Epoch:  289 | loss: 0.027212815359 \n",
      "Epoch:  290 | loss: 0.027212701738 \n",
      "Epoch:  291 | loss: 0.027212630957 \n",
      "Epoch:  292 | loss: 0.027212519199 \n",
      "Epoch:  293 | loss: 0.027212405577 \n",
      "Epoch:  294 | loss: 0.027212323621 \n",
      "Epoch:  295 | loss: 0.027212228626 \n",
      "Epoch:  296 | loss: 0.027212198824 \n",
      "Epoch:  297 | loss: 0.027212090790 \n",
      "Epoch:  298 | loss: 0.027212059125 \n",
      "Epoch:  299 | loss: 0.027212003246 \n",
      "time=213.17715311050415\n",
      "best_train_loss=0.027212003245949745\n",
      "test_loss=0.026158949360251427\n",
      "best_epoch=299\n",
      "w=15\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.027212001383 \n",
      "Epoch:  1 | loss: 0.027211710811 \n",
      "Epoch:  2 | loss: 0.027211423963 \n",
      "Epoch:  3 | loss: 0.027211150154 \n",
      "Epoch:  4 | loss: 0.027210880071 \n",
      "Epoch:  5 | loss: 0.027210619301 \n",
      "Epoch:  6 | loss: 0.027210364118 \n",
      "Epoch:  7 | loss: 0.027210116386 \n",
      "Epoch:  8 | loss: 0.027209887281 \n",
      "Epoch:  9 | loss: 0.027209654450 \n",
      "Epoch:  10 | loss: 0.027209388092 \n",
      "Epoch:  11 | loss: 0.027209134772 \n",
      "Epoch:  12 | loss: 0.027208885178 \n",
      "Epoch:  13 | loss: 0.027208643034 \n",
      "Epoch:  14 | loss: 0.027208408341 \n",
      "Epoch:  15 | loss: 0.027208168060 \n",
      "Epoch:  16 | loss: 0.027207944542 \n",
      "Epoch:  17 | loss: 0.027207713574 \n",
      "Epoch:  18 | loss: 0.027207491919 \n",
      "Epoch:  19 | loss: 0.027207279578 \n",
      "Epoch:  20 | loss: 0.027207074687 \n",
      "Epoch:  21 | loss: 0.027206866071 \n",
      "Epoch:  22 | loss: 0.027206668630 \n",
      "Epoch:  23 | loss: 0.027206476778 \n",
      "Epoch:  24 | loss: 0.027206286788 \n",
      "Epoch:  25 | loss: 0.027206109837 \n",
      "Epoch:  26 | loss: 0.027205927297 \n",
      "Epoch:  27 | loss: 0.027205746621 \n",
      "Epoch:  28 | loss: 0.027205569670 \n",
      "Epoch:  29 | loss: 0.027205398306 \n",
      "Epoch:  30 | loss: 0.027205221355 \n",
      "Epoch:  31 | loss: 0.027205055580 \n",
      "Epoch:  32 | loss: 0.027204891667 \n",
      "Epoch:  33 | loss: 0.027204807848 \n",
      "Epoch:  34 | loss: 0.027204714715 \n",
      "Epoch:  35 | loss: 0.027204617858 \n",
      "Epoch:  36 | loss: 0.027204453945 \n",
      "Epoch:  37 | loss: 0.027204293758 \n",
      "Epoch:  38 | loss: 0.027204141021 \n",
      "Epoch:  39 | loss: 0.027203982696 \n",
      "Epoch:  40 | loss: 0.027203837410 \n",
      "Epoch:  41 | loss: 0.027203686535 \n",
      "Epoch:  42 | loss: 0.027203543112 \n",
      "Epoch:  43 | loss: 0.027203394100 \n",
      "Epoch:  44 | loss: 0.027203252539 \n",
      "Epoch:  45 | loss: 0.027203114703 \n",
      "Epoch:  46 | loss: 0.027202973142 \n",
      "Epoch:  47 | loss: 0.027202833444 \n",
      "Epoch:  48 | loss: 0.027202697471 \n",
      "Epoch:  49 | loss: 0.027202561498 \n",
      "Epoch:  50 | loss: 0.027202427387 \n",
      "Epoch:  51 | loss: 0.027202317491 \n",
      "Epoch:  52 | loss: 0.027202188969 \n",
      "Epoch:  53 | loss: 0.027202054858 \n",
      "Epoch:  54 | loss: 0.027201928198 \n",
      "Epoch:  55 | loss: 0.027201807126 \n",
      "Epoch:  56 | loss: 0.027201691642 \n",
      "Epoch:  57 | loss: 0.027201564983 \n",
      "Epoch:  58 | loss: 0.027201445773 \n",
      "Epoch:  59 | loss: 0.027201334015 \n",
      "Epoch:  60 | loss: 0.027201218531 \n",
      "Epoch:  61 | loss: 0.027201134712 \n",
      "Epoch:  62 | loss: 0.027201021090 \n",
      "Epoch:  63 | loss: 0.027200903744 \n",
      "Epoch:  64 | loss: 0.027200898156 \n",
      "Epoch:  65 | loss: 0.027200844139 \n",
      "Epoch:  66 | loss: 0.027200728655 \n",
      "Epoch:  67 | loss: 0.027200726792 \n",
      "Epoch:  68 | loss: 0.027200611308 \n",
      "Epoch:  69 | loss: 0.027200520039 \n",
      "Epoch:  70 | loss: 0.027200408280 \n",
      "Epoch:  71 | loss: 0.027200298384 \n",
      "Epoch:  72 | loss: 0.027200184762 \n",
      "Epoch:  73 | loss: 0.027200082317 \n",
      "Epoch:  74 | loss: 0.027200048789 \n",
      "Epoch:  75 | loss: 0.027199972421 \n",
      "Epoch:  76 | loss: 0.027199957520 \n",
      "Epoch:  77 | loss: 0.027199855074 \n",
      "Epoch:  78 | loss: 0.027199745178 \n",
      "Epoch:  79 | loss: 0.027199635282 \n",
      "Epoch:  80 | loss: 0.027199566364 \n",
      "Epoch:  81 | loss: 0.027199557051 \n",
      "Epoch:  82 | loss: 0.027199560776 \n",
      "Epoch:  83 | loss: 0.027199514210 \n",
      "Epoch:  84 | loss: 0.027199501172 \n",
      "Epoch:  85 | loss: 0.027199484408 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  86 | loss: 0.027199406177 \n",
      "Epoch:  87 | loss: 0.027199368924 \n",
      "Epoch:  88 | loss: 0.027199346572 \n",
      "Epoch:  89 | loss: 0.027199311182 \n",
      "Epoch:  90 | loss: 0.027199216187 \n",
      "Epoch:  91 | loss: 0.027199199423 \n",
      "Epoch:  92 | loss: 0.027199104428 \n",
      "Epoch:  93 | loss: 0.027199046686 \n",
      "Epoch:  94 | loss: 0.027198994532 \n",
      "Epoch:  95 | loss: 0.027198990807 \n",
      "Epoch:  96 | loss: 0.027198895812 \n",
      "Epoch:  97 | loss: 0.027198897675 \n",
      "Epoch:  98 | loss: 0.027198882774 \n",
      "Epoch:  99 | loss: 0.027198791504 \n",
      "Epoch:  100 | loss: 0.027198791504 \n",
      "Epoch:  101 | loss: 0.027198791504 \n",
      "Epoch:  102 | loss: 0.027198793367 \n",
      "Epoch:  103 | loss: 0.027198791504 \n",
      "Epoch:  104 | loss: 0.027198791504 \n",
      "Epoch:  105 | loss: 0.027198793367 \n",
      "Epoch:  106 | loss: 0.027198791504 \n",
      "Epoch:  107 | loss: 0.027198791504 \n",
      "Epoch:  108 | loss: 0.027198793367 \n",
      "Epoch:  109 | loss: 0.027198791504 \n",
      "Epoch:  110 | loss: 0.027198795229 \n",
      "Epoch:  111 | loss: 0.027198793367 \n",
      "Epoch:  112 | loss: 0.027198791504 \n",
      "Epoch:  113 | loss: 0.027198791504 \n",
      "Epoch:  114 | loss: 0.027198789641 \n",
      "Epoch:  115 | loss: 0.027198789641 \n",
      "Epoch:  116 | loss: 0.027198791504 \n",
      "Epoch:  117 | loss: 0.027198791504 \n",
      "Epoch:  118 | loss: 0.027198795229 \n",
      "Epoch:  119 | loss: 0.027198789641 \n",
      "Epoch:  120 | loss: 0.027198791504 \n",
      "Epoch:  121 | loss: 0.027198789641 \n",
      "Epoch:  122 | loss: 0.027198791504 \n",
      "Epoch:  123 | loss: 0.027198791504 \n",
      "Epoch:  124 | loss: 0.027198791504 \n",
      "Epoch:  125 | loss: 0.027198791504 \n",
      "Epoch:  126 | loss: 0.027198793367 \n",
      "Epoch:  127 | loss: 0.027198791504 \n",
      "Epoch:  128 | loss: 0.027198791504 \n",
      "Epoch:  129 | loss: 0.027198793367 \n",
      "Epoch:  130 | loss: 0.027198789641 \n",
      "Epoch:  131 | loss: 0.027198793367 \n",
      "Epoch:  132 | loss: 0.027198791504 \n",
      "Epoch:  133 | loss: 0.027198793367 \n",
      "Epoch:  134 | loss: 0.027198791504 \n",
      "Epoch:  135 | loss: 0.027198791504 \n",
      "Epoch:  136 | loss: 0.027198791504 \n",
      "Epoch:  137 | loss: 0.027198791504 \n",
      "Epoch:  138 | loss: 0.027198791504 \n",
      "Epoch:  139 | loss: 0.027198791504 \n",
      "Epoch:  140 | loss: 0.027198791504 \n",
      "Epoch:  141 | loss: 0.027198791504 \n",
      "Epoch:  142 | loss: 0.027198791504 \n",
      "Epoch:  143 | loss: 0.027198793367 \n",
      "Epoch:  144 | loss: 0.027198791504 \n",
      "Epoch:  145 | loss: 0.027198793367 \n",
      "Epoch:  146 | loss: 0.027198791504 \n",
      "Epoch:  147 | loss: 0.027198789641 \n",
      "Epoch:  148 | loss: 0.027198791504 \n",
      "Epoch:  149 | loss: 0.027198791504 \n",
      "Epoch:  150 | loss: 0.027198789641 \n",
      "Epoch:  151 | loss: 0.027198791504 \n",
      "Epoch:  152 | loss: 0.027198789641 \n",
      "Epoch:  153 | loss: 0.027198791504 \n",
      "Epoch:  154 | loss: 0.027198791504 \n",
      "Epoch:  155 | loss: 0.027198791504 \n",
      "Epoch:  156 | loss: 0.027198791504 \n",
      "Epoch:  157 | loss: 0.027198793367 \n",
      "Epoch:  158 | loss: 0.027198793367 \n",
      "Epoch:  159 | loss: 0.027198791504 \n",
      "Epoch:  160 | loss: 0.027198791504 \n",
      "Epoch:  161 | loss: 0.027198793367 \n",
      "Epoch:  162 | loss: 0.027198791504 \n",
      "Epoch:  163 | loss: 0.027198789641 \n",
      "Epoch:  164 | loss: 0.027198791504 \n",
      "Epoch:  165 | loss: 0.027198789641 \n",
      "Epoch:  166 | loss: 0.027198789641 \n",
      "Epoch:  167 | loss: 0.027198793367 \n",
      "Epoch:  168 | loss: 0.027198793367 \n",
      "Epoch:  169 | loss: 0.027198791504 \n",
      "Epoch:  170 | loss: 0.027198789641 \n",
      "Epoch:  171 | loss: 0.027198791504 \n",
      "Epoch:  172 | loss: 0.027198789641 \n",
      "Epoch:  173 | loss: 0.027198791504 \n",
      "Epoch:  174 | loss: 0.027198791504 \n",
      "Epoch:  175 | loss: 0.027198791504 \n",
      "Epoch:  176 | loss: 0.027198789641 \n",
      "Epoch:  177 | loss: 0.027198791504 \n",
      "Epoch:  178 | loss: 0.027198791504 \n",
      "Epoch:  179 | loss: 0.027198789641 \n",
      "Epoch:  180 | loss: 0.027198791504 \n",
      "Epoch:  181 | loss: 0.027198791504 \n",
      "Epoch:  182 | loss: 0.027198789641 \n",
      "Epoch:  183 | loss: 0.027198791504 \n",
      "Epoch:  184 | loss: 0.027198791504 \n",
      "Epoch:  185 | loss: 0.027198791504 \n",
      "Epoch:  186 | loss: 0.027198791504 \n",
      "Epoch:  187 | loss: 0.027198795229 \n",
      "Epoch:  188 | loss: 0.027198793367 \n",
      "Epoch:  189 | loss: 0.027198791504 \n",
      "Epoch:  190 | loss: 0.027198791504 \n",
      "Epoch:  191 | loss: 0.027198791504 \n",
      "Epoch:  192 | loss: 0.027198793367 \n",
      "Epoch:  193 | loss: 0.027198791504 \n",
      "Epoch:  194 | loss: 0.027198789641 \n",
      "Epoch:  195 | loss: 0.027198789641 \n",
      "Epoch:  196 | loss: 0.027198793367 \n",
      "Epoch:  197 | loss: 0.027198791504 \n",
      "Epoch:  198 | loss: 0.027198791504 \n",
      "Epoch:  199 | loss: 0.027198793367 \n",
      "Epoch:  200 | loss: 0.027198791504 \n",
      "Epoch:  201 | loss: 0.027198793367 \n",
      "Epoch:  202 | loss: 0.027198791504 \n",
      "Epoch:  203 | loss: 0.027198793367 \n",
      "Epoch:  204 | loss: 0.027198791504 \n",
      "Epoch:  205 | loss: 0.027198791504 \n",
      "Epoch:  206 | loss: 0.027198791504 \n",
      "Epoch:  207 | loss: 0.027198791504 \n",
      "Epoch:  208 | loss: 0.027198791504 \n",
      "Epoch:  209 | loss: 0.027198789641 \n",
      "Epoch:  210 | loss: 0.027198793367 \n",
      "Epoch:  211 | loss: 0.027198789641 \n",
      "Epoch:  212 | loss: 0.027198791504 \n",
      "Epoch:  213 | loss: 0.027198791504 \n",
      "Epoch:  214 | loss: 0.027198791504 \n",
      "Epoch:  215 | loss: 0.027198789641 \n",
      "Epoch:  216 | loss: 0.027198787779 \n",
      "Epoch:  217 | loss: 0.027198791504 \n",
      "Epoch:  218 | loss: 0.027198791504 \n",
      "Epoch:  219 | loss: 0.027198793367 \n",
      "Epoch:  220 | loss: 0.027198789641 \n",
      "Epoch:  221 | loss: 0.027198793367 \n",
      "Epoch:  222 | loss: 0.027198791504 \n",
      "Epoch:  223 | loss: 0.027198791504 \n",
      "Epoch:  224 | loss: 0.027198791504 \n",
      "Epoch:  225 | loss: 0.027198791504 \n",
      "Epoch:  226 | loss: 0.027198791504 \n",
      "Epoch:  227 | loss: 0.027198791504 \n",
      "Epoch:  228 | loss: 0.027198793367 \n",
      "Epoch:  229 | loss: 0.027198791504 \n",
      "Epoch:  230 | loss: 0.027198789641 \n",
      "Epoch:  231 | loss: 0.027198791504 \n",
      "Epoch:  232 | loss: 0.027198791504 \n",
      "Epoch:  233 | loss: 0.027198791504 \n",
      "Epoch:  234 | loss: 0.027198791504 \n",
      "Epoch:  235 | loss: 0.027198791504 \n",
      "Epoch:  236 | loss: 0.027198791504 \n",
      "Epoch:  237 | loss: 0.027198791504 \n",
      "Epoch:  238 | loss: 0.027198793367 \n",
      "Epoch:  239 | loss: 0.027198787779 \n",
      "Epoch:  240 | loss: 0.027198789641 \n",
      "Epoch:  241 | loss: 0.027198791504 \n",
      "Epoch:  242 | loss: 0.027198793367 \n",
      "Epoch:  243 | loss: 0.027198791504 \n",
      "Epoch:  244 | loss: 0.027198789641 \n",
      "Epoch:  245 | loss: 0.027198791504 \n",
      "Epoch:  246 | loss: 0.027198791504 \n",
      "Epoch:  247 | loss: 0.027198791504 \n",
      "Epoch:  248 | loss: 0.027198791504 \n",
      "Epoch:  249 | loss: 0.027198791504 \n",
      "Epoch:  250 | loss: 0.027198789641 \n",
      "Epoch:  251 | loss: 0.027198793367 \n",
      "Epoch:  252 | loss: 0.027198789641 \n",
      "Epoch:  253 | loss: 0.027198795229 \n",
      "Epoch:  254 | loss: 0.027198793367 \n",
      "Epoch:  255 | loss: 0.027198791504 \n",
      "Epoch:  256 | loss: 0.027198791504 \n",
      "Epoch:  257 | loss: 0.027198789641 \n",
      "Epoch:  258 | loss: 0.027198791504 \n",
      "Epoch:  259 | loss: 0.027198791504 \n",
      "Epoch:  260 | loss: 0.027198793367 \n",
      "Epoch:  261 | loss: 0.027198791504 \n",
      "Epoch:  262 | loss: 0.027198793367 \n",
      "Epoch:  263 | loss: 0.027198791504 \n",
      "Epoch:  264 | loss: 0.027198793367 \n",
      "Epoch:  265 | loss: 0.027198791504 \n",
      "Epoch:  266 | loss: 0.027198793367 \n",
      "Epoch:  267 | loss: 0.027198789641 \n",
      "Epoch:  268 | loss: 0.027198793367 \n",
      "Epoch:  269 | loss: 0.027198793367 \n",
      "Epoch:  270 | loss: 0.027198791504 \n",
      "Epoch:  271 | loss: 0.027198789641 \n",
      "Epoch:  272 | loss: 0.027198791504 \n",
      "Epoch:  273 | loss: 0.027198791504 \n",
      "Epoch:  274 | loss: 0.027198791504 \n",
      "Epoch:  275 | loss: 0.027198791504 \n",
      "Epoch:  276 | loss: 0.027198791504 \n",
      "Epoch:  277 | loss: 0.027198791504 \n",
      "Epoch:  278 | loss: 0.027198791504 \n",
      "Epoch:  279 | loss: 0.027198793367 \n",
      "Epoch:  280 | loss: 0.027198791504 \n",
      "Epoch:  281 | loss: 0.027198791504 \n",
      "Epoch:  282 | loss: 0.027198791504 \n",
      "Epoch:  283 | loss: 0.027198791504 \n",
      "Epoch:  284 | loss: 0.027198789641 \n",
      "Epoch:  285 | loss: 0.027198791504 \n",
      "Epoch:  286 | loss: 0.027198791504 \n",
      "Epoch:  287 | loss: 0.027198791504 \n",
      "Epoch:  288 | loss: 0.027198789641 \n",
      "Epoch:  289 | loss: 0.027198791504 \n",
      "Epoch:  290 | loss: 0.027198791504 \n",
      "Epoch:  291 | loss: 0.027198791504 \n",
      "Epoch:  292 | loss: 0.027198791504 \n",
      "Epoch:  293 | loss: 0.027198791504 \n",
      "Epoch:  294 | loss: 0.027198791504 \n",
      "Epoch:  295 | loss: 0.027198791504 \n",
      "Epoch:  296 | loss: 0.027198791504 \n",
      "Epoch:  297 | loss: 0.027198791504 \n",
      "Epoch:  298 | loss: 0.027198791504 \n",
      "Epoch:  299 | loss: 0.027198791504 \n",
      "time=131.37678694725037\n",
      "best_train_loss=0.02719878777861595\n",
      "test_loss=0.026149477809667587\n",
      "best_epoch=216\n",
      "w=20\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.027198631316 \n",
      "Epoch:  1 | loss: 0.027198629454 \n",
      "Epoch:  2 | loss: 0.027198629454 \n",
      "Epoch:  3 | loss: 0.027198627591 \n",
      "Epoch:  4 | loss: 0.027198629454 \n",
      "Epoch:  5 | loss: 0.027198631316 \n",
      "Epoch:  6 | loss: 0.027198629454 \n",
      "Epoch:  7 | loss: 0.027198629454 \n",
      "Epoch:  8 | loss: 0.027198631316 \n",
      "Epoch:  9 | loss: 0.027198631316 \n",
      "Epoch:  10 | loss: 0.027198629454 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 | loss: 0.027198629454 \n",
      "Epoch:  12 | loss: 0.027198631316 \n",
      "Epoch:  13 | loss: 0.027198629454 \n",
      "Epoch:  14 | loss: 0.027198629454 \n",
      "Epoch:  15 | loss: 0.027198627591 \n",
      "Epoch:  16 | loss: 0.027198629454 \n",
      "Epoch:  17 | loss: 0.027198629454 \n",
      "Epoch:  18 | loss: 0.027198629454 \n",
      "Epoch:  19 | loss: 0.027198631316 \n",
      "Epoch:  20 | loss: 0.027198631316 \n",
      "Epoch:  21 | loss: 0.027198629454 \n",
      "Epoch:  22 | loss: 0.027198631316 \n",
      "Epoch:  23 | loss: 0.027198629454 \n",
      "Epoch:  24 | loss: 0.027198631316 \n",
      "Epoch:  25 | loss: 0.027198629454 \n",
      "Epoch:  26 | loss: 0.027198629454 \n",
      "Epoch:  27 | loss: 0.027198629454 \n",
      "Epoch:  28 | loss: 0.027198629454 \n",
      "Epoch:  29 | loss: 0.027198629454 \n",
      "Epoch:  30 | loss: 0.027198631316 \n",
      "Epoch:  31 | loss: 0.027198629454 \n",
      "Epoch:  32 | loss: 0.027198627591 \n",
      "Epoch:  33 | loss: 0.027198629454 \n",
      "Epoch:  34 | loss: 0.027198629454 \n",
      "Epoch:  35 | loss: 0.027198629454 \n",
      "Epoch:  36 | loss: 0.027198629454 \n",
      "Epoch:  37 | loss: 0.027198629454 \n",
      "Epoch:  38 | loss: 0.027198627591 \n",
      "Epoch:  39 | loss: 0.027198629454 \n",
      "Epoch:  40 | loss: 0.027198631316 \n",
      "Epoch:  41 | loss: 0.027198631316 \n",
      "Epoch:  42 | loss: 0.027198629454 \n",
      "Epoch:  43 | loss: 0.027198629454 \n",
      "Epoch:  44 | loss: 0.027198629454 \n",
      "Epoch:  45 | loss: 0.027198631316 \n",
      "Epoch:  46 | loss: 0.027198629454 \n",
      "Epoch:  47 | loss: 0.027198629454 \n",
      "Epoch:  48 | loss: 0.027198629454 \n",
      "Epoch:  49 | loss: 0.027198629454 \n",
      "Epoch:  50 | loss: 0.027198629454 \n",
      "Epoch:  51 | loss: 0.027198629454 \n",
      "Epoch:  52 | loss: 0.027198629454 \n",
      "Epoch:  53 | loss: 0.027198629454 \n",
      "Epoch:  54 | loss: 0.027198629454 \n",
      "Epoch:  55 | loss: 0.027198629454 \n",
      "Epoch:  56 | loss: 0.027198629454 \n",
      "Epoch:  57 | loss: 0.027198629454 \n",
      "Epoch:  58 | loss: 0.027198629454 \n",
      "Epoch:  59 | loss: 0.027198629454 \n",
      "Epoch:  60 | loss: 0.027198631316 \n",
      "Epoch:  61 | loss: 0.027198627591 \n",
      "Epoch:  62 | loss: 0.027198629454 \n",
      "Epoch:  63 | loss: 0.027198629454 \n",
      "Epoch:  64 | loss: 0.027198629454 \n",
      "Epoch:  65 | loss: 0.027198629454 \n",
      "Epoch:  66 | loss: 0.027198629454 \n",
      "Epoch:  67 | loss: 0.027198629454 \n",
      "Epoch:  68 | loss: 0.027198629454 \n",
      "Epoch:  69 | loss: 0.027198627591 \n",
      "Epoch:  70 | loss: 0.027198629454 \n",
      "Epoch:  71 | loss: 0.027198629454 \n",
      "Epoch:  72 | loss: 0.027198631316 \n",
      "Epoch:  73 | loss: 0.027198629454 \n",
      "Epoch:  74 | loss: 0.027198629454 \n",
      "Epoch:  75 | loss: 0.027198631316 \n",
      "Epoch:  76 | loss: 0.027198629454 \n",
      "Epoch:  77 | loss: 0.027198627591 \n",
      "Epoch:  78 | loss: 0.027198629454 \n",
      "Epoch:  79 | loss: 0.027198629454 \n",
      "Epoch:  80 | loss: 0.027198629454 \n",
      "Epoch:  81 | loss: 0.027198629454 \n",
      "Epoch:  82 | loss: 0.027198629454 \n",
      "Epoch:  83 | loss: 0.027198629454 \n",
      "Epoch:  84 | loss: 0.027198631316 \n",
      "Epoch:  85 | loss: 0.027198629454 \n",
      "Epoch:  86 | loss: 0.027198627591 \n",
      "Epoch:  87 | loss: 0.027198627591 \n",
      "Epoch:  88 | loss: 0.027198627591 \n",
      "Epoch:  89 | loss: 0.027198629454 \n",
      "Epoch:  90 | loss: 0.027198629454 \n",
      "Epoch:  91 | loss: 0.027198627591 \n",
      "Epoch:  92 | loss: 0.027198627591 \n",
      "Epoch:  93 | loss: 0.027198627591 \n",
      "Epoch:  94 | loss: 0.027198629454 \n",
      "Epoch:  95 | loss: 0.027198629454 \n",
      "Epoch:  96 | loss: 0.027198631316 \n",
      "Epoch:  97 | loss: 0.027198629454 \n",
      "Epoch:  98 | loss: 0.027198625728 \n",
      "Epoch:  99 | loss: 0.027198629454 \n",
      "Epoch:  100 | loss: 0.027198627591 \n",
      "Epoch:  101 | loss: 0.027198629454 \n",
      "Epoch:  102 | loss: 0.027198629454 \n",
      "Epoch:  103 | loss: 0.027198631316 \n",
      "Epoch:  104 | loss: 0.027198629454 \n",
      "Epoch:  105 | loss: 0.027198629454 \n",
      "Epoch:  106 | loss: 0.027198631316 \n",
      "Epoch:  107 | loss: 0.027198629454 \n",
      "Epoch:  108 | loss: 0.027198627591 \n",
      "Epoch:  109 | loss: 0.027198629454 \n",
      "Epoch:  110 | loss: 0.027198631316 \n",
      "Epoch:  111 | loss: 0.027198625728 \n",
      "Epoch:  112 | loss: 0.027198627591 \n",
      "Epoch:  113 | loss: 0.027198629454 \n",
      "Epoch:  114 | loss: 0.027198627591 \n",
      "Epoch:  115 | loss: 0.027198629454 \n",
      "Epoch:  116 | loss: 0.027198629454 \n",
      "Epoch:  117 | loss: 0.027198629454 \n",
      "Epoch:  118 | loss: 0.027198631316 \n",
      "Epoch:  119 | loss: 0.027198629454 \n",
      "Epoch:  120 | loss: 0.027198629454 \n",
      "Epoch:  121 | loss: 0.027198629454 \n",
      "Epoch:  122 | loss: 0.027198627591 \n",
      "Epoch:  123 | loss: 0.027198629454 \n",
      "Epoch:  124 | loss: 0.027198631316 \n",
      "Epoch:  125 | loss: 0.027198627591 \n",
      "Epoch:  126 | loss: 0.027198629454 \n",
      "Epoch:  127 | loss: 0.027198627591 \n",
      "Epoch:  128 | loss: 0.027198629454 \n",
      "Epoch:  129 | loss: 0.027198627591 \n",
      "Epoch:  130 | loss: 0.027198629454 \n",
      "Epoch:  131 | loss: 0.027198627591 \n",
      "Epoch:  132 | loss: 0.027198627591 \n",
      "Epoch:  133 | loss: 0.027198627591 \n",
      "Epoch:  134 | loss: 0.027198627591 \n",
      "Epoch:  135 | loss: 0.027198629454 \n",
      "Epoch:  136 | loss: 0.027198629454 \n",
      "Epoch:  137 | loss: 0.027198629454 \n",
      "Epoch:  138 | loss: 0.027198629454 \n",
      "Epoch:  139 | loss: 0.027198629454 \n",
      "Epoch:  140 | loss: 0.027198629454 \n",
      "Epoch:  141 | loss: 0.027198631316 \n",
      "Epoch:  142 | loss: 0.027198631316 \n",
      "Epoch:  143 | loss: 0.027198627591 \n",
      "Epoch:  144 | loss: 0.027198629454 \n",
      "Epoch:  145 | loss: 0.027198629454 \n",
      "Epoch:  146 | loss: 0.027198629454 \n",
      "Epoch:  147 | loss: 0.027198627591 \n",
      "Epoch:  148 | loss: 0.027198629454 \n",
      "Epoch:  149 | loss: 0.027198627591 \n",
      "Epoch:  150 | loss: 0.027198627591 \n",
      "Epoch:  151 | loss: 0.027198629454 \n",
      "Epoch:  152 | loss: 0.027198627591 \n",
      "Epoch:  153 | loss: 0.027198629454 \n",
      "Epoch:  154 | loss: 0.027198627591 \n",
      "Epoch:  155 | loss: 0.027198627591 \n",
      "Epoch:  156 | loss: 0.027198629454 \n",
      "Epoch:  157 | loss: 0.027198629454 \n",
      "Epoch:  158 | loss: 0.027198629454 \n",
      "Epoch:  159 | loss: 0.027198629454 \n",
      "Epoch:  160 | loss: 0.027198627591 \n",
      "Epoch:  161 | loss: 0.027198627591 \n",
      "Epoch:  162 | loss: 0.027198629454 \n",
      "Epoch:  163 | loss: 0.027198627591 \n",
      "Epoch:  164 | loss: 0.027198625728 \n",
      "Epoch:  165 | loss: 0.027198627591 \n",
      "Epoch:  166 | loss: 0.027198629454 \n",
      "Epoch:  167 | loss: 0.027198629454 \n",
      "Epoch:  168 | loss: 0.027198629454 \n",
      "Epoch:  169 | loss: 0.027198627591 \n",
      "Epoch:  170 | loss: 0.027198629454 \n",
      "Epoch:  171 | loss: 0.027198627591 \n",
      "Epoch:  172 | loss: 0.027198627591 \n",
      "Epoch:  173 | loss: 0.027198625728 \n",
      "Epoch:  174 | loss: 0.027198629454 \n",
      "Epoch:  175 | loss: 0.027198629454 \n",
      "Epoch:  176 | loss: 0.027198629454 \n",
      "Epoch:  177 | loss: 0.027198627591 \n",
      "Epoch:  178 | loss: 0.027198629454 \n",
      "Epoch:  179 | loss: 0.027198627591 \n",
      "Epoch:  180 | loss: 0.027198627591 \n",
      "Epoch:  181 | loss: 0.027198627591 \n",
      "Epoch:  182 | loss: 0.027198627591 \n",
      "Epoch:  183 | loss: 0.027198627591 \n",
      "Epoch:  184 | loss: 0.027198631316 \n",
      "Epoch:  185 | loss: 0.027198627591 \n",
      "Epoch:  186 | loss: 0.027198627591 \n",
      "Epoch:  187 | loss: 0.027198629454 \n",
      "Epoch:  188 | loss: 0.027198627591 \n",
      "Epoch:  189 | loss: 0.027198625728 \n",
      "Epoch:  190 | loss: 0.027198629454 \n",
      "Epoch:  191 | loss: 0.027198627591 \n",
      "Epoch:  192 | loss: 0.027198627591 \n",
      "Epoch:  193 | loss: 0.027198627591 \n",
      "Epoch:  194 | loss: 0.027198627591 \n",
      "Epoch:  195 | loss: 0.027198625728 \n",
      "Epoch:  196 | loss: 0.027198629454 \n",
      "Epoch:  197 | loss: 0.027198627591 \n",
      "Epoch:  198 | loss: 0.027198625728 \n",
      "Epoch:  199 | loss: 0.027198627591 \n",
      "Epoch:  200 | loss: 0.027198627591 \n",
      "Epoch:  201 | loss: 0.027198631316 \n",
      "Epoch:  202 | loss: 0.027198627591 \n",
      "Epoch:  203 | loss: 0.027198629454 \n",
      "Epoch:  204 | loss: 0.027198627591 \n",
      "Epoch:  205 | loss: 0.027198625728 \n",
      "Epoch:  206 | loss: 0.027198629454 \n",
      "Epoch:  207 | loss: 0.027198625728 \n",
      "Epoch:  208 | loss: 0.027198627591 \n",
      "Epoch:  209 | loss: 0.027198629454 \n",
      "Epoch:  210 | loss: 0.027198629454 \n",
      "Epoch:  211 | loss: 0.027198627591 \n",
      "Epoch:  212 | loss: 0.027198627591 \n",
      "Epoch:  213 | loss: 0.027198627591 \n",
      "Epoch:  214 | loss: 0.027198627591 \n",
      "Epoch:  215 | loss: 0.027198629454 \n",
      "Epoch:  216 | loss: 0.027198627591 \n",
      "Epoch:  217 | loss: 0.027198631316 \n",
      "Epoch:  218 | loss: 0.027198627591 \n",
      "Epoch:  219 | loss: 0.027198629454 \n",
      "Epoch:  220 | loss: 0.027198629454 \n",
      "Epoch:  221 | loss: 0.027198627591 \n",
      "Epoch:  222 | loss: 0.027198629454 \n",
      "Epoch:  223 | loss: 0.027198625728 \n",
      "Epoch:  224 | loss: 0.027198629454 \n",
      "Epoch:  225 | loss: 0.027198627591 \n",
      "Epoch:  226 | loss: 0.027198627591 \n",
      "Epoch:  227 | loss: 0.027198627591 \n",
      "Epoch:  228 | loss: 0.027198631316 \n",
      "Epoch:  229 | loss: 0.027198627591 \n",
      "Epoch:  230 | loss: 0.027198627591 \n",
      "Epoch:  231 | loss: 0.027198631316 \n",
      "Epoch:  232 | loss: 0.027198627591 \n",
      "Epoch:  233 | loss: 0.027198627591 \n",
      "Epoch:  234 | loss: 0.027198629454 \n",
      "Epoch:  235 | loss: 0.027198627591 \n",
      "Epoch:  236 | loss: 0.027198629454 \n",
      "Epoch:  237 | loss: 0.027198625728 \n",
      "Epoch:  238 | loss: 0.027198627591 \n",
      "Epoch:  239 | loss: 0.027198627591 \n",
      "Epoch:  240 | loss: 0.027198629454 \n",
      "Epoch:  241 | loss: 0.027198627591 \n",
      "Epoch:  242 | loss: 0.027198625728 \n",
      "Epoch:  243 | loss: 0.027198629454 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  244 | loss: 0.027198627591 \n",
      "Epoch:  245 | loss: 0.027198627591 \n",
      "Epoch:  246 | loss: 0.027198625728 \n",
      "Epoch:  247 | loss: 0.027198629454 \n",
      "Epoch:  248 | loss: 0.027198623866 \n",
      "Epoch:  249 | loss: 0.027198627591 \n",
      "Epoch:  250 | loss: 0.027198627591 \n",
      "Epoch:  251 | loss: 0.027198625728 \n",
      "Epoch:  252 | loss: 0.027198627591 \n",
      "Epoch:  253 | loss: 0.027198625728 \n",
      "Epoch:  254 | loss: 0.027198629454 \n",
      "Epoch:  255 | loss: 0.027198627591 \n",
      "Epoch:  256 | loss: 0.027198631316 \n",
      "Epoch:  257 | loss: 0.027198627591 \n",
      "Epoch:  258 | loss: 0.027198629454 \n",
      "Epoch:  259 | loss: 0.027198629454 \n",
      "Epoch:  260 | loss: 0.027198629454 \n",
      "Epoch:  261 | loss: 0.027198629454 \n",
      "Epoch:  262 | loss: 0.027198627591 \n",
      "Epoch:  263 | loss: 0.027198625728 \n",
      "Epoch:  264 | loss: 0.027198627591 \n",
      "Epoch:  265 | loss: 0.027198627591 \n",
      "Epoch:  266 | loss: 0.027198627591 \n",
      "Epoch:  267 | loss: 0.027198627591 \n",
      "Epoch:  268 | loss: 0.027198629454 \n",
      "Epoch:  269 | loss: 0.027198627591 \n",
      "Epoch:  270 | loss: 0.027198629454 \n",
      "Epoch:  271 | loss: 0.027198627591 \n",
      "Epoch:  272 | loss: 0.027198627591 \n",
      "Epoch:  273 | loss: 0.027198627591 \n",
      "Epoch:  274 | loss: 0.027198629454 \n",
      "Epoch:  275 | loss: 0.027198627591 \n",
      "Epoch:  276 | loss: 0.027198629454 \n",
      "Epoch:  277 | loss: 0.027198629454 \n",
      "Epoch:  278 | loss: 0.027198627591 \n",
      "Epoch:  279 | loss: 0.027198627591 \n",
      "Epoch:  280 | loss: 0.027198629454 \n",
      "Epoch:  281 | loss: 0.027198627591 \n",
      "Epoch:  282 | loss: 0.027198627591 \n",
      "Epoch:  283 | loss: 0.027198627591 \n",
      "Epoch:  284 | loss: 0.027198627591 \n",
      "Epoch:  285 | loss: 0.027198625728 \n",
      "Epoch:  286 | loss: 0.027198629454 \n",
      "Epoch:  287 | loss: 0.027198627591 \n",
      "Epoch:  288 | loss: 0.027198627591 \n",
      "Epoch:  289 | loss: 0.027198629454 \n",
      "Epoch:  290 | loss: 0.027198625728 \n",
      "Epoch:  291 | loss: 0.027198627591 \n",
      "Epoch:  292 | loss: 0.027198625728 \n",
      "Epoch:  293 | loss: 0.027198627591 \n",
      "Epoch:  294 | loss: 0.027198629454 \n",
      "Epoch:  295 | loss: 0.027198625728 \n",
      "Epoch:  296 | loss: 0.027198627591 \n",
      "Epoch:  297 | loss: 0.027198629454 \n",
      "Epoch:  298 | loss: 0.027198629454 \n",
      "Epoch:  299 | loss: 0.027198627591 \n",
      "time=25.23037600517273\n",
      "best_train_loss=0.02719862386584282\n",
      "test_loss=0.026149358600378036\n",
      "best_epoch=248\n",
      "w=25\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.027198329568 \n",
      "Epoch:  1 | loss: 0.027198331431 \n",
      "Epoch:  2 | loss: 0.027198331431 \n",
      "Epoch:  3 | loss: 0.027198331431 \n",
      "Epoch:  4 | loss: 0.027198329568 \n",
      "Epoch:  5 | loss: 0.027198329568 \n",
      "Epoch:  6 | loss: 0.027198331431 \n",
      "Epoch:  7 | loss: 0.027198333293 \n",
      "Epoch:  8 | loss: 0.027198331431 \n",
      "Epoch:  9 | loss: 0.027198329568 \n",
      "Epoch:  10 | loss: 0.027198329568 \n",
      "Epoch:  11 | loss: 0.027198331431 \n",
      "Epoch:  12 | loss: 0.027198333293 \n",
      "Epoch:  13 | loss: 0.027198331431 \n",
      "Epoch:  14 | loss: 0.027198331431 \n",
      "Epoch:  15 | loss: 0.027198331431 \n",
      "Epoch:  16 | loss: 0.027198329568 \n",
      "Epoch:  17 | loss: 0.027198333293 \n",
      "Epoch:  18 | loss: 0.027198331431 \n",
      "Epoch:  19 | loss: 0.027198333293 \n",
      "Epoch:  20 | loss: 0.027198333293 \n",
      "Epoch:  21 | loss: 0.027198329568 \n",
      "Epoch:  22 | loss: 0.027198333293 \n",
      "Epoch:  23 | loss: 0.027198329568 \n",
      "Epoch:  24 | loss: 0.027198331431 \n",
      "Epoch:  25 | loss: 0.027198331431 \n",
      "Epoch:  26 | loss: 0.027198331431 \n",
      "Epoch:  27 | loss: 0.027198329568 \n",
      "Epoch:  28 | loss: 0.027198329568 \n",
      "Epoch:  29 | loss: 0.027198329568 \n",
      "Epoch:  30 | loss: 0.027198331431 \n",
      "Epoch:  31 | loss: 0.027198333293 \n",
      "Epoch:  32 | loss: 0.027198331431 \n",
      "Epoch:  33 | loss: 0.027198329568 \n",
      "Epoch:  34 | loss: 0.027198331431 \n",
      "Epoch:  35 | loss: 0.027198331431 \n",
      "Epoch:  36 | loss: 0.027198333293 \n",
      "Epoch:  37 | loss: 0.027198329568 \n",
      "Epoch:  38 | loss: 0.027198329568 \n",
      "Epoch:  39 | loss: 0.027198331431 \n",
      "Epoch:  40 | loss: 0.027198331431 \n",
      "Epoch:  41 | loss: 0.027198331431 \n",
      "Epoch:  42 | loss: 0.027198331431 \n",
      "Epoch:  43 | loss: 0.027198329568 \n",
      "Epoch:  44 | loss: 0.027198331431 \n",
      "Epoch:  45 | loss: 0.027198333293 \n",
      "Epoch:  46 | loss: 0.027198329568 \n",
      "Epoch:  47 | loss: 0.027198331431 \n",
      "Epoch:  48 | loss: 0.027198331431 \n",
      "Epoch:  49 | loss: 0.027198329568 \n",
      "Epoch:  50 | loss: 0.027198333293 \n",
      "Epoch:  51 | loss: 0.027198331431 \n",
      "Epoch:  52 | loss: 0.027198329568 \n",
      "Epoch:  53 | loss: 0.027198331431 \n",
      "Epoch:  54 | loss: 0.027198329568 \n",
      "Epoch:  55 | loss: 0.027198329568 \n",
      "Epoch:  56 | loss: 0.027198331431 \n",
      "Epoch:  57 | loss: 0.027198329568 \n",
      "Epoch:  58 | loss: 0.027198329568 \n",
      "Epoch:  59 | loss: 0.027198331431 \n",
      "Epoch:  60 | loss: 0.027198333293 \n",
      "Epoch:  61 | loss: 0.027198329568 \n",
      "Epoch:  62 | loss: 0.027198329568 \n",
      "Epoch:  63 | loss: 0.027198333293 \n",
      "Epoch:  64 | loss: 0.027198331431 \n",
      "Epoch:  65 | loss: 0.027198329568 \n",
      "Epoch:  66 | loss: 0.027198331431 \n",
      "Epoch:  67 | loss: 0.027198329568 \n",
      "Epoch:  68 | loss: 0.027198331431 \n",
      "Epoch:  69 | loss: 0.027198329568 \n",
      "Epoch:  70 | loss: 0.027198333293 \n",
      "Epoch:  71 | loss: 0.027198331431 \n",
      "Epoch:  72 | loss: 0.027198329568 \n",
      "Epoch:  73 | loss: 0.027198331431 \n",
      "Epoch:  74 | loss: 0.027198329568 \n",
      "Epoch:  75 | loss: 0.027198331431 \n",
      "Epoch:  76 | loss: 0.027198333293 \n",
      "Epoch:  77 | loss: 0.027198331431 \n",
      "Epoch:  78 | loss: 0.027198331431 \n",
      "Epoch:  79 | loss: 0.027198331431 \n",
      "Epoch:  80 | loss: 0.027198331431 \n",
      "Epoch:  81 | loss: 0.027198329568 \n",
      "Epoch:  82 | loss: 0.027198333293 \n",
      "Epoch:  83 | loss: 0.027198331431 \n",
      "Epoch:  84 | loss: 0.027198329568 \n",
      "Epoch:  85 | loss: 0.027198331431 \n",
      "Epoch:  86 | loss: 0.027198329568 \n",
      "Epoch:  87 | loss: 0.027198329568 \n",
      "Epoch:  88 | loss: 0.027198331431 \n",
      "Epoch:  89 | loss: 0.027198331431 \n",
      "Epoch:  90 | loss: 0.027198329568 \n",
      "Epoch:  91 | loss: 0.027198333293 \n",
      "Epoch:  92 | loss: 0.027198331431 \n",
      "Epoch:  93 | loss: 0.027198329568 \n",
      "Epoch:  94 | loss: 0.027198329568 \n",
      "Epoch:  95 | loss: 0.027198333293 \n",
      "Epoch:  96 | loss: 0.027198331431 \n",
      "Epoch:  97 | loss: 0.027198331431 \n",
      "Epoch:  98 | loss: 0.027198329568 \n",
      "Epoch:  99 | loss: 0.027198329568 \n",
      "Epoch:  100 | loss: 0.027198329568 \n",
      "Epoch:  101 | loss: 0.027198329568 \n",
      "Epoch:  102 | loss: 0.027198331431 \n",
      "Epoch:  103 | loss: 0.027198329568 \n",
      "Epoch:  104 | loss: 0.027198329568 \n",
      "Epoch:  105 | loss: 0.027198331431 \n",
      "Epoch:  106 | loss: 0.027198329568 \n",
      "Epoch:  107 | loss: 0.027198329568 \n",
      "Epoch:  108 | loss: 0.027198331431 \n",
      "Epoch:  109 | loss: 0.027198331431 \n",
      "Epoch:  110 | loss: 0.027198331431 \n",
      "Epoch:  111 | loss: 0.027198331431 \n",
      "Epoch:  112 | loss: 0.027198333293 \n",
      "Epoch:  113 | loss: 0.027198331431 \n",
      "Epoch:  114 | loss: 0.027198333293 \n",
      "Epoch:  115 | loss: 0.027198329568 \n",
      "Epoch:  116 | loss: 0.027198333293 \n",
      "Epoch:  117 | loss: 0.027198329568 \n",
      "Epoch:  118 | loss: 0.027198329568 \n",
      "Epoch:  119 | loss: 0.027198331431 \n",
      "Epoch:  120 | loss: 0.027198331431 \n",
      "Epoch:  121 | loss: 0.027198331431 \n",
      "Epoch:  122 | loss: 0.027198329568 \n",
      "Epoch:  123 | loss: 0.027198329568 \n",
      "Epoch:  124 | loss: 0.027198329568 \n",
      "Epoch:  125 | loss: 0.027198331431 \n",
      "Epoch:  126 | loss: 0.027198329568 \n",
      "Epoch:  127 | loss: 0.027198331431 \n",
      "Epoch:  128 | loss: 0.027198333293 \n",
      "Epoch:  129 | loss: 0.027198333293 \n",
      "Epoch:  130 | loss: 0.027198329568 \n",
      "Epoch:  131 | loss: 0.027198329568 \n",
      "Epoch:  132 | loss: 0.027198329568 \n",
      "Epoch:  133 | loss: 0.027198329568 \n",
      "Epoch:  134 | loss: 0.027198331431 \n",
      "Epoch:  135 | loss: 0.027198329568 \n",
      "Epoch:  136 | loss: 0.027198329568 \n",
      "Epoch:  137 | loss: 0.027198331431 \n",
      "Epoch:  138 | loss: 0.027198329568 \n",
      "Epoch:  139 | loss: 0.027198331431 \n",
      "Epoch:  140 | loss: 0.027198329568 \n",
      "Epoch:  141 | loss: 0.027198329568 \n",
      "Epoch:  142 | loss: 0.027198329568 \n",
      "Epoch:  143 | loss: 0.027198329568 \n",
      "Epoch:  144 | loss: 0.027198331431 \n",
      "Epoch:  145 | loss: 0.027198329568 \n",
      "Epoch:  146 | loss: 0.027198329568 \n",
      "Epoch:  147 | loss: 0.027198329568 \n",
      "Epoch:  148 | loss: 0.027198329568 \n",
      "Epoch:  149 | loss: 0.027198329568 \n",
      "Epoch:  150 | loss: 0.027198329568 \n",
      "Epoch:  151 | loss: 0.027198329568 \n",
      "Epoch:  152 | loss: 0.027198329568 \n",
      "Epoch:  153 | loss: 0.027198331431 \n",
      "Epoch:  154 | loss: 0.027198329568 \n",
      "Epoch:  155 | loss: 0.027198331431 \n",
      "Epoch:  156 | loss: 0.027198329568 \n",
      "Epoch:  157 | loss: 0.027198329568 \n",
      "Epoch:  158 | loss: 0.027198329568 \n",
      "Epoch:  159 | loss: 0.027198329568 \n",
      "Epoch:  160 | loss: 0.027198329568 \n",
      "Epoch:  161 | loss: 0.027198331431 \n",
      "Epoch:  162 | loss: 0.027198329568 \n",
      "Epoch:  163 | loss: 0.027198329568 \n",
      "Epoch:  164 | loss: 0.027198329568 \n",
      "Epoch:  165 | loss: 0.027198329568 \n",
      "Epoch:  166 | loss: 0.027198329568 \n",
      "Epoch:  167 | loss: 0.027198329568 \n",
      "Epoch:  168 | loss: 0.027198329568 \n",
      "Epoch:  169 | loss: 0.027198329568 \n",
      "Epoch:  170 | loss: 0.027198329568 \n",
      "Epoch:  171 | loss: 0.027198329568 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  172 | loss: 0.027198329568 \n",
      "Epoch:  173 | loss: 0.027198329568 \n",
      "Epoch:  174 | loss: 0.027198329568 \n",
      "Epoch:  175 | loss: 0.027198329568 \n",
      "Epoch:  176 | loss: 0.027198329568 \n",
      "Epoch:  177 | loss: 0.027198329568 \n",
      "Epoch:  178 | loss: 0.027198331431 \n",
      "Epoch:  179 | loss: 0.027198329568 \n",
      "Epoch:  180 | loss: 0.027198329568 \n",
      "Epoch:  181 | loss: 0.027198329568 \n",
      "Epoch:  182 | loss: 0.027198331431 \n",
      "Epoch:  183 | loss: 0.027198329568 \n",
      "Epoch:  184 | loss: 0.027198329568 \n",
      "Epoch:  185 | loss: 0.027198329568 \n",
      "Epoch:  186 | loss: 0.027198329568 \n",
      "Epoch:  187 | loss: 0.027198331431 \n",
      "Epoch:  188 | loss: 0.027198329568 \n",
      "Epoch:  189 | loss: 0.027198329568 \n",
      "Epoch:  190 | loss: 0.027198329568 \n",
      "Epoch:  191 | loss: 0.027198329568 \n",
      "Epoch:  192 | loss: 0.027198329568 \n",
      "Epoch:  193 | loss: 0.027198331431 \n",
      "Epoch:  194 | loss: 0.027198329568 \n",
      "Epoch:  195 | loss: 0.027198331431 \n",
      "Epoch:  196 | loss: 0.027198329568 \n",
      "Epoch:  197 | loss: 0.027198329568 \n",
      "Epoch:  198 | loss: 0.027198329568 \n",
      "Epoch:  199 | loss: 0.027198329568 \n",
      "Epoch:  200 | loss: 0.027198327705 \n",
      "Epoch:  201 | loss: 0.027198329568 \n",
      "Epoch:  202 | loss: 0.027198329568 \n",
      "Epoch:  203 | loss: 0.027198329568 \n",
      "Epoch:  204 | loss: 0.027198329568 \n",
      "Epoch:  205 | loss: 0.027198329568 \n",
      "Epoch:  206 | loss: 0.027198329568 \n",
      "Epoch:  207 | loss: 0.027198329568 \n",
      "Epoch:  208 | loss: 0.027198329568 \n",
      "Epoch:  209 | loss: 0.027198331431 \n",
      "Epoch:  210 | loss: 0.027198329568 \n",
      "Epoch:  211 | loss: 0.027198329568 \n",
      "Epoch:  212 | loss: 0.027198329568 \n",
      "Epoch:  213 | loss: 0.027198331431 \n",
      "Epoch:  214 | loss: 0.027198329568 \n",
      "Epoch:  215 | loss: 0.027198329568 \n",
      "Epoch:  216 | loss: 0.027198329568 \n",
      "Epoch:  217 | loss: 0.027198329568 \n",
      "Epoch:  218 | loss: 0.027198329568 \n",
      "Epoch:  219 | loss: 0.027198329568 \n",
      "Epoch:  220 | loss: 0.027198333293 \n",
      "Epoch:  221 | loss: 0.027198329568 \n",
      "Epoch:  222 | loss: 0.027198329568 \n",
      "Epoch:  223 | loss: 0.027198329568 \n",
      "Epoch:  224 | loss: 0.027198329568 \n",
      "Epoch:  225 | loss: 0.027198329568 \n",
      "Epoch:  226 | loss: 0.027198329568 \n",
      "Epoch:  227 | loss: 0.027198331431 \n",
      "Epoch:  228 | loss: 0.027198329568 \n",
      "Epoch:  229 | loss: 0.027198329568 \n",
      "Epoch:  230 | loss: 0.027198329568 \n",
      "Epoch:  231 | loss: 0.027198329568 \n",
      "Epoch:  232 | loss: 0.027198329568 \n",
      "Epoch:  233 | loss: 0.027198329568 \n",
      "Epoch:  234 | loss: 0.027198329568 \n",
      "Epoch:  235 | loss: 0.027198329568 \n",
      "Epoch:  236 | loss: 0.027198329568 \n",
      "Epoch:  237 | loss: 0.027198329568 \n",
      "Epoch:  238 | loss: 0.027198329568 \n",
      "Epoch:  239 | loss: 0.027198329568 \n",
      "Epoch:  240 | loss: 0.027198329568 \n",
      "Epoch:  241 | loss: 0.027198329568 \n",
      "Epoch:  242 | loss: 0.027198329568 \n",
      "Epoch:  243 | loss: 0.027198331431 \n",
      "Epoch:  244 | loss: 0.027198329568 \n",
      "Epoch:  245 | loss: 0.027198331431 \n",
      "Epoch:  246 | loss: 0.027198329568 \n",
      "Epoch:  247 | loss: 0.027198329568 \n",
      "Epoch:  248 | loss: 0.027198329568 \n",
      "Epoch:  249 | loss: 0.027198329568 \n",
      "Epoch:  250 | loss: 0.027198329568 \n",
      "Epoch:  251 | loss: 0.027198331431 \n",
      "Epoch:  252 | loss: 0.027198329568 \n",
      "Epoch:  253 | loss: 0.027198329568 \n",
      "Epoch:  254 | loss: 0.027198329568 \n",
      "Epoch:  255 | loss: 0.027198329568 \n",
      "Epoch:  256 | loss: 0.027198329568 \n",
      "Epoch:  257 | loss: 0.027198329568 \n",
      "Epoch:  258 | loss: 0.027198329568 \n",
      "Epoch:  259 | loss: 0.027198329568 \n",
      "Epoch:  260 | loss: 0.027198329568 \n",
      "Epoch:  261 | loss: 0.027198329568 \n",
      "Epoch:  262 | loss: 0.027198331431 \n",
      "Epoch:  263 | loss: 0.027198329568 \n",
      "Epoch:  264 | loss: 0.027198329568 \n",
      "Epoch:  265 | loss: 0.027198329568 \n",
      "Epoch:  266 | loss: 0.027198329568 \n",
      "Epoch:  267 | loss: 0.027198329568 \n",
      "Epoch:  268 | loss: 0.027198329568 \n",
      "Epoch:  269 | loss: 0.027198331431 \n",
      "Epoch:  270 | loss: 0.027198329568 \n",
      "Epoch:  271 | loss: 0.027198329568 \n",
      "Epoch:  272 | loss: 0.027198329568 \n",
      "Epoch:  273 | loss: 0.027198329568 \n",
      "Epoch:  274 | loss: 0.027198329568 \n",
      "Epoch:  275 | loss: 0.027198329568 \n",
      "Epoch:  276 | loss: 0.027198329568 \n",
      "Epoch:  277 | loss: 0.027198329568 \n",
      "Epoch:  278 | loss: 0.027198329568 \n",
      "Epoch:  279 | loss: 0.027198329568 \n",
      "Epoch:  280 | loss: 0.027198329568 \n",
      "Epoch:  281 | loss: 0.027198331431 \n",
      "Epoch:  282 | loss: 0.027198329568 \n",
      "Epoch:  283 | loss: 0.027198329568 \n",
      "Epoch:  284 | loss: 0.027198329568 \n",
      "Epoch:  285 | loss: 0.027198329568 \n",
      "Epoch:  286 | loss: 0.027198329568 \n",
      "Epoch:  287 | loss: 0.027198329568 \n",
      "Epoch:  288 | loss: 0.027198329568 \n",
      "Epoch:  289 | loss: 0.027198329568 \n",
      "Epoch:  290 | loss: 0.027198329568 \n",
      "Epoch:  291 | loss: 0.027198329568 \n",
      "Epoch:  292 | loss: 0.027198329568 \n",
      "Epoch:  293 | loss: 0.027198329568 \n",
      "Epoch:  294 | loss: 0.027198329568 \n",
      "Epoch:  295 | loss: 0.027198329568 \n",
      "Epoch:  296 | loss: 0.027198329568 \n",
      "Epoch:  297 | loss: 0.027198329568 \n",
      "Epoch:  298 | loss: 0.027198329568 \n",
      "Epoch:  299 | loss: 0.027198329568 \n",
      "time=25.60825800895691\n",
      "best_train_loss=0.02719832770526409\n",
      "test_loss=0.02614913322031498\n",
      "best_epoch=200\n",
      "w=30\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.027198333293 \n",
      "Epoch:  1 | loss: 0.027198331431 \n",
      "Epoch:  2 | loss: 0.027198329568 \n",
      "Epoch:  3 | loss: 0.027198329568 \n",
      "Epoch:  4 | loss: 0.027198329568 \n",
      "Epoch:  5 | loss: 0.027198329568 \n",
      "Epoch:  6 | loss: 0.027198329568 \n",
      "Epoch:  7 | loss: 0.027198329568 \n",
      "Epoch:  8 | loss: 0.027198329568 \n",
      "Epoch:  9 | loss: 0.027198329568 \n",
      "Epoch:  10 | loss: 0.027198329568 \n",
      "Epoch:  11 | loss: 0.027198329568 \n",
      "Epoch:  12 | loss: 0.027198329568 \n",
      "Epoch:  13 | loss: 0.027198329568 \n",
      "Epoch:  14 | loss: 0.027198329568 \n",
      "Epoch:  15 | loss: 0.027198329568 \n",
      "Epoch:  16 | loss: 0.027198329568 \n",
      "Epoch:  17 | loss: 0.027198329568 \n",
      "Epoch:  18 | loss: 0.027198331431 \n",
      "Epoch:  19 | loss: 0.027198331431 \n",
      "Epoch:  20 | loss: 0.027198329568 \n",
      "Epoch:  21 | loss: 0.027198333293 \n",
      "Epoch:  22 | loss: 0.027198329568 \n",
      "Epoch:  23 | loss: 0.027198329568 \n",
      "Epoch:  24 | loss: 0.027198331431 \n",
      "Epoch:  25 | loss: 0.027198329568 \n",
      "Epoch:  26 | loss: 0.027198329568 \n",
      "Epoch:  27 | loss: 0.027198329568 \n",
      "Epoch:  28 | loss: 0.027198329568 \n",
      "Epoch:  29 | loss: 0.027198329568 \n",
      "Epoch:  30 | loss: 0.027198329568 \n",
      "Epoch:  31 | loss: 0.027198329568 \n",
      "Epoch:  32 | loss: 0.027198329568 \n",
      "Epoch:  33 | loss: 0.027198329568 \n",
      "Epoch:  34 | loss: 0.027198329568 \n",
      "Epoch:  35 | loss: 0.027198329568 \n",
      "Epoch:  36 | loss: 0.027198329568 \n",
      "Epoch:  37 | loss: 0.027198329568 \n",
      "Epoch:  38 | loss: 0.027198329568 \n",
      "Epoch:  39 | loss: 0.027198329568 \n",
      "Epoch:  40 | loss: 0.027198329568 \n",
      "Epoch:  41 | loss: 0.027198329568 \n",
      "Epoch:  42 | loss: 0.027198331431 \n",
      "Epoch:  43 | loss: 0.027198329568 \n",
      "Epoch:  44 | loss: 0.027198329568 \n",
      "Epoch:  45 | loss: 0.027198329568 \n",
      "Epoch:  46 | loss: 0.027198329568 \n",
      "Epoch:  47 | loss: 0.027198329568 \n",
      "Epoch:  48 | loss: 0.027198331431 \n",
      "Epoch:  49 | loss: 0.027198329568 \n",
      "Epoch:  50 | loss: 0.027198329568 \n",
      "Epoch:  51 | loss: 0.027198329568 \n",
      "Epoch:  52 | loss: 0.027198329568 \n",
      "Epoch:  53 | loss: 0.027198331431 \n",
      "Epoch:  54 | loss: 0.027198329568 \n",
      "Epoch:  55 | loss: 0.027198329568 \n",
      "Epoch:  56 | loss: 0.027198329568 \n",
      "Epoch:  57 | loss: 0.027198329568 \n",
      "Epoch:  58 | loss: 0.027198329568 \n",
      "Epoch:  59 | loss: 0.027198329568 \n",
      "Epoch:  60 | loss: 0.027198331431 \n",
      "Epoch:  61 | loss: 0.027198331431 \n",
      "Epoch:  62 | loss: 0.027198331431 \n",
      "Epoch:  63 | loss: 0.027198329568 \n",
      "Epoch:  64 | loss: 0.027198329568 \n",
      "Epoch:  65 | loss: 0.027198329568 \n",
      "Epoch:  66 | loss: 0.027198329568 \n",
      "Epoch:  67 | loss: 0.027198329568 \n",
      "Epoch:  68 | loss: 0.027198329568 \n",
      "Epoch:  69 | loss: 0.027198329568 \n",
      "Epoch:  70 | loss: 0.027198329568 \n",
      "Epoch:  71 | loss: 0.027198331431 \n",
      "Epoch:  72 | loss: 0.027198329568 \n",
      "Epoch:  73 | loss: 0.027198329568 \n",
      "Epoch:  74 | loss: 0.027198329568 \n",
      "Epoch:  75 | loss: 0.027198329568 \n",
      "Epoch:  76 | loss: 0.027198329568 \n",
      "Epoch:  77 | loss: 0.027198329568 \n",
      "Epoch:  78 | loss: 0.027198329568 \n",
      "Epoch:  79 | loss: 0.027198329568 \n",
      "Epoch:  80 | loss: 0.027198329568 \n",
      "Epoch:  81 | loss: 0.027198329568 \n",
      "Epoch:  82 | loss: 0.027198329568 \n",
      "Epoch:  83 | loss: 0.027198329568 \n",
      "Epoch:  84 | loss: 0.027198329568 \n",
      "Epoch:  85 | loss: 0.027198331431 \n",
      "Epoch:  86 | loss: 0.027198329568 \n",
      "Epoch:  87 | loss: 0.027198329568 \n",
      "Epoch:  88 | loss: 0.027198329568 \n",
      "Epoch:  89 | loss: 0.027198329568 \n",
      "Epoch:  90 | loss: 0.027198329568 \n",
      "Epoch:  91 | loss: 0.027198331431 \n",
      "Epoch:  92 | loss: 0.027198329568 \n",
      "Epoch:  93 | loss: 0.027198329568 \n",
      "Epoch:  94 | loss: 0.027198329568 \n",
      "Epoch:  95 | loss: 0.027198329568 \n",
      "Epoch:  96 | loss: 0.027198329568 \n",
      "Epoch:  97 | loss: 0.027198329568 \n",
      "Epoch:  98 | loss: 0.027198329568 \n",
      "Epoch:  99 | loss: 0.027198329568 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  100 | loss: 0.027198329568 \n",
      "Epoch:  101 | loss: 0.027198329568 \n",
      "Epoch:  102 | loss: 0.027198329568 \n",
      "Epoch:  103 | loss: 0.027198329568 \n",
      "Epoch:  104 | loss: 0.027198329568 \n",
      "Epoch:  105 | loss: 0.027198329568 \n",
      "Epoch:  106 | loss: 0.027198329568 \n",
      "Epoch:  107 | loss: 0.027198329568 \n",
      "Epoch:  108 | loss: 0.027198331431 \n",
      "Epoch:  109 | loss: 0.027198329568 \n",
      "Epoch:  110 | loss: 0.027198329568 \n",
      "Epoch:  111 | loss: 0.027198329568 \n",
      "Epoch:  112 | loss: 0.027198329568 \n",
      "Epoch:  113 | loss: 0.027198329568 \n",
      "Epoch:  114 | loss: 0.027198327705 \n",
      "Epoch:  115 | loss: 0.027198329568 \n",
      "Epoch:  116 | loss: 0.027198329568 \n",
      "Epoch:  117 | loss: 0.027198327705 \n",
      "Epoch:  118 | loss: 0.027198329568 \n",
      "Epoch:  119 | loss: 0.027198329568 \n",
      "Epoch:  120 | loss: 0.027198329568 \n",
      "Epoch:  121 | loss: 0.027198329568 \n",
      "Epoch:  122 | loss: 0.027198329568 \n",
      "Epoch:  123 | loss: 0.027198329568 \n",
      "Epoch:  124 | loss: 0.027198329568 \n",
      "Epoch:  125 | loss: 0.027198329568 \n",
      "Epoch:  126 | loss: 0.027198329568 \n",
      "Epoch:  127 | loss: 0.027198331431 \n",
      "Epoch:  128 | loss: 0.027198331431 \n",
      "Epoch:  129 | loss: 0.027198327705 \n",
      "Epoch:  130 | loss: 0.027198329568 \n",
      "Epoch:  131 | loss: 0.027198329568 \n",
      "Epoch:  132 | loss: 0.027198331431 \n",
      "Epoch:  133 | loss: 0.027198329568 \n",
      "Epoch:  134 | loss: 0.027198327705 \n",
      "Epoch:  135 | loss: 0.027198329568 \n",
      "Epoch:  136 | loss: 0.027198329568 \n",
      "Epoch:  137 | loss: 0.027198329568 \n",
      "Epoch:  138 | loss: 0.027198327705 \n",
      "Epoch:  139 | loss: 0.027198327705 \n",
      "Epoch:  140 | loss: 0.027198327705 \n",
      "Epoch:  141 | loss: 0.027198327705 \n",
      "Epoch:  142 | loss: 0.027198327705 \n",
      "Epoch:  143 | loss: 0.027198329568 \n",
      "Epoch:  144 | loss: 0.027198329568 \n",
      "Epoch:  145 | loss: 0.027198327705 \n",
      "Epoch:  146 | loss: 0.027198327705 \n",
      "Epoch:  147 | loss: 0.027198327705 \n",
      "Epoch:  148 | loss: 0.027198329568 \n",
      "Epoch:  149 | loss: 0.027198329568 \n",
      "Epoch:  150 | loss: 0.027198329568 \n",
      "Epoch:  151 | loss: 0.027198329568 \n",
      "Epoch:  152 | loss: 0.027198329568 \n",
      "Epoch:  153 | loss: 0.027198327705 \n",
      "Epoch:  154 | loss: 0.027198327705 \n",
      "Epoch:  155 | loss: 0.027198327705 \n",
      "Epoch:  156 | loss: 0.027198329568 \n",
      "Epoch:  157 | loss: 0.027198327705 \n",
      "Epoch:  158 | loss: 0.027198325843 \n",
      "Epoch:  159 | loss: 0.027198327705 \n",
      "Epoch:  160 | loss: 0.027198329568 \n",
      "Epoch:  161 | loss: 0.027198327705 \n",
      "Epoch:  162 | loss: 0.027198327705 \n",
      "Epoch:  163 | loss: 0.027198327705 \n",
      "Epoch:  164 | loss: 0.027198327705 \n",
      "Epoch:  165 | loss: 0.027198327705 \n",
      "Epoch:  166 | loss: 0.027198327705 \n",
      "Epoch:  167 | loss: 0.027198327705 \n",
      "Epoch:  168 | loss: 0.027198329568 \n",
      "Epoch:  169 | loss: 0.027198327705 \n",
      "Epoch:  170 | loss: 0.027198327705 \n",
      "Epoch:  171 | loss: 0.027198327705 \n",
      "Epoch:  172 | loss: 0.027198327705 \n",
      "Epoch:  173 | loss: 0.027198329568 \n",
      "Epoch:  174 | loss: 0.027198327705 \n",
      "Epoch:  175 | loss: 0.027198325843 \n",
      "Epoch:  176 | loss: 0.027198327705 \n",
      "Epoch:  177 | loss: 0.027198325843 \n",
      "Epoch:  178 | loss: 0.027198325843 \n",
      "Epoch:  179 | loss: 0.027198327705 \n",
      "Epoch:  180 | loss: 0.027198327705 \n",
      "Epoch:  181 | loss: 0.027198327705 \n",
      "Epoch:  182 | loss: 0.027198327705 \n",
      "Epoch:  183 | loss: 0.027198325843 \n",
      "Epoch:  184 | loss: 0.027198325843 \n",
      "Epoch:  185 | loss: 0.027198327705 \n",
      "Epoch:  186 | loss: 0.027198329568 \n",
      "Epoch:  187 | loss: 0.027198325843 \n",
      "Epoch:  188 | loss: 0.027198323980 \n",
      "Epoch:  189 | loss: 0.027198327705 \n",
      "Epoch:  190 | loss: 0.027198325843 \n",
      "Epoch:  191 | loss: 0.027198325843 \n",
      "Epoch:  192 | loss: 0.027198327705 \n",
      "Epoch:  193 | loss: 0.027198325843 \n",
      "Epoch:  194 | loss: 0.027198323980 \n",
      "Epoch:  195 | loss: 0.027198325843 \n",
      "Epoch:  196 | loss: 0.027198325843 \n",
      "Epoch:  197 | loss: 0.027198323980 \n",
      "Epoch:  198 | loss: 0.027198325843 \n",
      "Epoch:  199 | loss: 0.027198325843 \n",
      "Epoch:  200 | loss: 0.027198323980 \n",
      "Epoch:  201 | loss: 0.027198327705 \n",
      "Epoch:  202 | loss: 0.027198327705 \n",
      "Epoch:  203 | loss: 0.027198325843 \n",
      "Epoch:  204 | loss: 0.027198327705 \n",
      "Epoch:  205 | loss: 0.027198323980 \n",
      "Epoch:  206 | loss: 0.027198325843 \n",
      "Epoch:  207 | loss: 0.027198325843 \n",
      "Epoch:  208 | loss: 0.027198325843 \n",
      "Epoch:  209 | loss: 0.027198323980 \n",
      "Epoch:  210 | loss: 0.027198323980 \n",
      "Epoch:  211 | loss: 0.027198325843 \n",
      "Epoch:  212 | loss: 0.027198325843 \n",
      "Epoch:  213 | loss: 0.027198325843 \n",
      "Epoch:  214 | loss: 0.027198327705 \n",
      "Epoch:  215 | loss: 0.027198325843 \n",
      "Epoch:  216 | loss: 0.027198325843 \n",
      "Epoch:  217 | loss: 0.027198325843 \n",
      "Epoch:  218 | loss: 0.027198327705 \n",
      "Epoch:  219 | loss: 0.027198325843 \n",
      "Epoch:  220 | loss: 0.027198323980 \n",
      "Epoch:  221 | loss: 0.027198325843 \n",
      "Epoch:  222 | loss: 0.027198323980 \n",
      "Epoch:  223 | loss: 0.027198327705 \n",
      "Epoch:  224 | loss: 0.027198325843 \n",
      "Epoch:  225 | loss: 0.027198323980 \n",
      "Epoch:  226 | loss: 0.027198325843 \n",
      "Epoch:  227 | loss: 0.027198320255 \n",
      "Epoch:  228 | loss: 0.027198320255 \n",
      "Epoch:  229 | loss: 0.027198320255 \n",
      "Epoch:  230 | loss: 0.027198320255 \n",
      "Epoch:  231 | loss: 0.027198322117 \n",
      "Epoch:  232 | loss: 0.027198310941 \n",
      "Epoch:  233 | loss: 0.027198312804 \n",
      "Epoch:  234 | loss: 0.027198312804 \n",
      "Epoch:  235 | loss: 0.027198310941 \n",
      "Epoch:  236 | loss: 0.027198312804 \n",
      "Epoch:  237 | loss: 0.027198312804 \n",
      "Epoch:  238 | loss: 0.027198310941 \n",
      "Epoch:  239 | loss: 0.027198310941 \n",
      "Epoch:  240 | loss: 0.027198310941 \n",
      "Epoch:  241 | loss: 0.027198310941 \n",
      "Epoch:  242 | loss: 0.027198312804 \n",
      "Epoch:  243 | loss: 0.027198312804 \n",
      "Epoch:  244 | loss: 0.027198310941 \n",
      "Epoch:  245 | loss: 0.027198310941 \n",
      "Epoch:  246 | loss: 0.027198310941 \n",
      "Epoch:  247 | loss: 0.027198312804 \n",
      "Epoch:  248 | loss: 0.027198307216 \n",
      "Epoch:  249 | loss: 0.027198307216 \n",
      "Epoch:  250 | loss: 0.027198309079 \n",
      "Epoch:  251 | loss: 0.027198303491 \n",
      "Epoch:  252 | loss: 0.027198305354 \n",
      "Epoch:  253 | loss: 0.027198307216 \n",
      "Epoch:  254 | loss: 0.027198307216 \n",
      "Epoch:  255 | loss: 0.027198303491 \n",
      "Epoch:  256 | loss: 0.027198305354 \n",
      "Epoch:  257 | loss: 0.027198307216 \n",
      "Epoch:  258 | loss: 0.027198307216 \n",
      "Epoch:  259 | loss: 0.027198303491 \n",
      "Epoch:  260 | loss: 0.027198305354 \n",
      "Epoch:  261 | loss: 0.027198305354 \n",
      "Epoch:  262 | loss: 0.027198307216 \n",
      "Epoch:  263 | loss: 0.027198307216 \n",
      "Epoch:  264 | loss: 0.027198307216 \n",
      "Epoch:  265 | loss: 0.027198303491 \n",
      "Epoch:  266 | loss: 0.027198305354 \n",
      "Epoch:  267 | loss: 0.027198303491 \n",
      "Epoch:  268 | loss: 0.027198307216 \n",
      "Epoch:  269 | loss: 0.027198305354 \n",
      "Epoch:  270 | loss: 0.027198305354 \n",
      "Epoch:  271 | loss: 0.027198307216 \n",
      "Epoch:  272 | loss: 0.027198307216 \n",
      "Epoch:  273 | loss: 0.027198307216 \n",
      "Epoch:  274 | loss: 0.027198305354 \n",
      "Epoch:  275 | loss: 0.027198307216 \n",
      "Epoch:  276 | loss: 0.027198305354 \n",
      "Epoch:  277 | loss: 0.027198303491 \n",
      "Epoch:  278 | loss: 0.027198307216 \n",
      "Epoch:  279 | loss: 0.027198301628 \n",
      "Epoch:  280 | loss: 0.027198299766 \n",
      "Epoch:  281 | loss: 0.027198299766 \n",
      "Epoch:  282 | loss: 0.027198297903 \n",
      "Epoch:  283 | loss: 0.027198301628 \n",
      "Epoch:  284 | loss: 0.027198301628 \n",
      "Epoch:  285 | loss: 0.027198301628 \n",
      "Epoch:  286 | loss: 0.027198299766 \n",
      "Epoch:  287 | loss: 0.027198299766 \n",
      "Epoch:  288 | loss: 0.027198299766 \n",
      "Epoch:  289 | loss: 0.027198299766 \n",
      "Epoch:  290 | loss: 0.027198299766 \n",
      "Epoch:  291 | loss: 0.027198301628 \n",
      "Epoch:  292 | loss: 0.027198297903 \n",
      "Epoch:  293 | loss: 0.027198301628 \n",
      "Epoch:  294 | loss: 0.027198301628 \n",
      "Epoch:  295 | loss: 0.027198301628 \n",
      "Epoch:  296 | loss: 0.027198297903 \n",
      "Epoch:  297 | loss: 0.027198299766 \n",
      "Epoch:  298 | loss: 0.027198299766 \n",
      "Epoch:  299 | loss: 0.027198303491 \n",
      "time=27.658246994018555\n",
      "best_train_loss=0.027198297902941704\n",
      "test_loss=0.02614910714328289\n",
      "best_epoch=282\n",
      "w=35\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.027198299766 \n",
      "Epoch:  1 | loss: 0.005991064012 \n",
      "Epoch:  2 | loss: 0.005091689061 \n",
      "Epoch:  3 | loss: 0.005091689527 \n",
      "Epoch:  4 | loss: 0.005091688596 \n",
      "Epoch:  5 | loss: 0.005091689061 \n",
      "Epoch:  6 | loss: 0.005091689061 \n",
      "Epoch:  7 | loss: 0.005091689061 \n",
      "Epoch:  8 | loss: 0.005091688596 \n",
      "Epoch:  9 | loss: 0.005091688596 \n",
      "Epoch:  10 | loss: 0.005091689061 \n",
      "Epoch:  11 | loss: 0.005091688596 \n",
      "Epoch:  12 | loss: 0.005091689061 \n",
      "Epoch:  13 | loss: 0.005091688596 \n",
      "Epoch:  14 | loss: 0.005091689061 \n",
      "Epoch:  15 | loss: 0.005091689061 \n",
      "Epoch:  16 | loss: 0.005091689061 \n",
      "Epoch:  17 | loss: 0.005091689061 \n",
      "Epoch:  18 | loss: 0.005091689061 \n",
      "Epoch:  19 | loss: 0.005091688596 \n",
      "Epoch:  20 | loss: 0.005091689061 \n",
      "Epoch:  21 | loss: 0.005091689061 \n",
      "Epoch:  22 | loss: 0.005091689061 \n",
      "Epoch:  23 | loss: 0.005091688596 \n",
      "Epoch:  24 | loss: 0.005091688596 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25 | loss: 0.005091688596 \n",
      "Epoch:  26 | loss: 0.005091689061 \n",
      "Epoch:  27 | loss: 0.005091688596 \n",
      "Epoch:  28 | loss: 0.005091689061 \n",
      "Epoch:  29 | loss: 0.005091688596 \n",
      "Epoch:  30 | loss: 0.005091689061 \n",
      "Epoch:  31 | loss: 0.005091688596 \n",
      "Epoch:  32 | loss: 0.005091689061 \n",
      "Epoch:  33 | loss: 0.005091689061 \n",
      "Epoch:  34 | loss: 0.005091689061 \n",
      "Epoch:  35 | loss: 0.005091689061 \n",
      "Epoch:  36 | loss: 0.005091689061 \n",
      "Epoch:  37 | loss: 0.005091689061 \n",
      "Epoch:  38 | loss: 0.005091689061 \n",
      "Epoch:  39 | loss: 0.005091689061 \n",
      "Epoch:  40 | loss: 0.005091688596 \n",
      "Epoch:  41 | loss: 0.005091689061 \n",
      "Epoch:  42 | loss: 0.005091689061 \n",
      "Epoch:  43 | loss: 0.005091689061 \n",
      "Epoch:  44 | loss: 0.005091688596 \n",
      "Epoch:  45 | loss: 0.005091688596 \n",
      "Epoch:  46 | loss: 0.005091688596 \n",
      "Epoch:  47 | loss: 0.005091689061 \n",
      "Epoch:  48 | loss: 0.005091689061 \n",
      "Epoch:  49 | loss: 0.005091689061 \n",
      "Epoch:  50 | loss: 0.005091689061 \n",
      "Epoch:  51 | loss: 0.005091688596 \n",
      "Epoch:  52 | loss: 0.005091689061 \n",
      "Epoch:  53 | loss: 0.005091689061 \n",
      "Epoch:  54 | loss: 0.005091689061 \n",
      "Epoch:  55 | loss: 0.005091689061 \n",
      "Epoch:  56 | loss: 0.005091689061 \n",
      "Epoch:  57 | loss: 0.005091689061 \n",
      "Epoch:  58 | loss: 0.005091689061 \n",
      "Epoch:  59 | loss: 0.005091689527 \n",
      "Epoch:  60 | loss: 0.005091688596 \n",
      "Epoch:  61 | loss: 0.005091688596 \n",
      "Epoch:  62 | loss: 0.005091688596 \n",
      "Epoch:  63 | loss: 0.005091689061 \n",
      "Epoch:  64 | loss: 0.005091688596 \n",
      "Epoch:  65 | loss: 0.005091689061 \n",
      "Epoch:  66 | loss: 0.005091689061 \n",
      "Epoch:  67 | loss: 0.005091688596 \n",
      "Epoch:  68 | loss: 0.005091689061 \n",
      "Epoch:  69 | loss: 0.005091689061 \n",
      "Epoch:  70 | loss: 0.005091689061 \n",
      "Epoch:  71 | loss: 0.005091689061 \n",
      "Epoch:  72 | loss: 0.005091688596 \n",
      "Epoch:  73 | loss: 0.005091688596 \n",
      "Epoch:  74 | loss: 0.005091689061 \n",
      "Epoch:  75 | loss: 0.005091689061 \n",
      "Epoch:  76 | loss: 0.005091689061 \n",
      "Epoch:  77 | loss: 0.005091689061 \n",
      "Epoch:  78 | loss: 0.005091689061 \n",
      "Epoch:  79 | loss: 0.005091689061 \n",
      "Epoch:  80 | loss: 0.005091688596 \n",
      "Epoch:  81 | loss: 0.005091688596 \n",
      "Epoch:  82 | loss: 0.005091689061 \n",
      "Epoch:  83 | loss: 0.005091689061 \n",
      "Epoch:  84 | loss: 0.005091689061 \n",
      "Epoch:  85 | loss: 0.005091688596 \n",
      "Epoch:  86 | loss: 0.005091688596 \n",
      "Epoch:  87 | loss: 0.005091689061 \n",
      "Epoch:  88 | loss: 0.005091688596 \n",
      "Epoch:  89 | loss: 0.005091689061 \n",
      "Epoch:  90 | loss: 0.005091688596 \n",
      "Epoch:  91 | loss: 0.005091689061 \n",
      "Epoch:  92 | loss: 0.005091689061 \n",
      "Epoch:  93 | loss: 0.005091688596 \n",
      "Epoch:  94 | loss: 0.005091689061 \n",
      "Epoch:  95 | loss: 0.005091689061 \n",
      "Epoch:  96 | loss: 0.005091689061 \n",
      "Epoch:  97 | loss: 0.005091689527 \n",
      "Epoch:  98 | loss: 0.005091689527 \n",
      "Epoch:  99 | loss: 0.005091689061 \n",
      "Epoch:  100 | loss: 0.005091688596 \n",
      "Epoch:  101 | loss: 0.005091689061 \n",
      "Epoch:  102 | loss: 0.005091689527 \n",
      "Epoch:  103 | loss: 0.005091688596 \n",
      "Epoch:  104 | loss: 0.005091688596 \n",
      "Epoch:  105 | loss: 0.005091689061 \n",
      "Epoch:  106 | loss: 0.005091689061 \n",
      "Epoch:  107 | loss: 0.005091689061 \n",
      "Epoch:  108 | loss: 0.005091688596 \n",
      "Epoch:  109 | loss: 0.005091688596 \n",
      "Epoch:  110 | loss: 0.005091689061 \n",
      "Epoch:  111 | loss: 0.005091688596 \n",
      "Epoch:  112 | loss: 0.005091689061 \n",
      "Epoch:  113 | loss: 0.005091688596 \n",
      "Epoch:  114 | loss: 0.005091689061 \n",
      "Epoch:  115 | loss: 0.005091688596 \n",
      "Epoch:  116 | loss: 0.005091688596 \n",
      "Epoch:  117 | loss: 0.005091689061 \n",
      "Epoch:  118 | loss: 0.005091688596 \n",
      "Epoch:  119 | loss: 0.005091689061 \n",
      "Epoch:  120 | loss: 0.005091688596 \n",
      "Epoch:  121 | loss: 0.005091688596 \n",
      "Epoch:  122 | loss: 0.005091688596 \n",
      "Epoch:  123 | loss: 0.005091688596 \n",
      "Epoch:  124 | loss: 0.005091688596 \n",
      "Epoch:  125 | loss: 0.005091688596 \n",
      "Epoch:  126 | loss: 0.005091688596 \n",
      "Epoch:  127 | loss: 0.005091688596 \n",
      "Epoch:  128 | loss: 0.005091688596 \n",
      "Epoch:  129 | loss: 0.005091688596 \n",
      "Epoch:  130 | loss: 0.005091688130 \n",
      "Epoch:  131 | loss: 0.005091688596 \n",
      "Epoch:  132 | loss: 0.005091688596 \n",
      "Epoch:  133 | loss: 0.005091688130 \n",
      "Epoch:  134 | loss: 0.005091688596 \n",
      "Epoch:  135 | loss: 0.005091688596 \n",
      "Epoch:  136 | loss: 0.005091688596 \n",
      "Epoch:  137 | loss: 0.005091688596 \n",
      "Epoch:  138 | loss: 0.005091688596 \n",
      "Epoch:  139 | loss: 0.005091688596 \n",
      "Epoch:  140 | loss: 0.005091688130 \n",
      "Epoch:  141 | loss: 0.005091688596 \n",
      "Epoch:  142 | loss: 0.005091688596 \n",
      "Epoch:  143 | loss: 0.005091689061 \n",
      "Epoch:  144 | loss: 0.005091688596 \n",
      "Epoch:  145 | loss: 0.005091688596 \n",
      "Epoch:  146 | loss: 0.005091688596 \n",
      "Epoch:  147 | loss: 0.005091688596 \n",
      "Epoch:  148 | loss: 0.005091688596 \n",
      "Epoch:  149 | loss: 0.005091688596 \n",
      "Epoch:  150 | loss: 0.005091688596 \n",
      "Epoch:  151 | loss: 0.005091688130 \n",
      "Epoch:  152 | loss: 0.005091688596 \n",
      "Epoch:  153 | loss: 0.005091688130 \n",
      "Epoch:  154 | loss: 0.005091688596 \n",
      "Epoch:  155 | loss: 0.005091688596 \n",
      "Epoch:  156 | loss: 0.005091688596 \n",
      "Epoch:  157 | loss: 0.005091688596 \n",
      "Epoch:  158 | loss: 0.005091688596 \n",
      "Epoch:  159 | loss: 0.005091688596 \n",
      "Epoch:  160 | loss: 0.005091688130 \n",
      "Epoch:  161 | loss: 0.005091688596 \n",
      "Epoch:  162 | loss: 0.005091688596 \n",
      "Epoch:  163 | loss: 0.005091688596 \n",
      "Epoch:  164 | loss: 0.005091688596 \n",
      "Epoch:  165 | loss: 0.005091688596 \n",
      "Epoch:  166 | loss: 0.005091688596 \n",
      "Epoch:  167 | loss: 0.005091688596 \n",
      "Epoch:  168 | loss: 0.005091688596 \n",
      "Epoch:  169 | loss: 0.005091688596 \n",
      "Epoch:  170 | loss: 0.005091688596 \n",
      "Epoch:  171 | loss: 0.005091688596 \n",
      "Epoch:  172 | loss: 0.005091688596 \n",
      "Epoch:  173 | loss: 0.005091688596 \n",
      "Epoch:  174 | loss: 0.005091688596 \n",
      "Epoch:  175 | loss: 0.005091688596 \n",
      "Epoch:  176 | loss: 0.005091688596 \n",
      "Epoch:  177 | loss: 0.005091688596 \n",
      "Epoch:  178 | loss: 0.005091688596 \n",
      "Epoch:  179 | loss: 0.005091688596 \n",
      "Epoch:  180 | loss: 0.005091688596 \n",
      "Epoch:  181 | loss: 0.005091688596 \n",
      "Epoch:  182 | loss: 0.005091688130 \n",
      "Epoch:  183 | loss: 0.005091688596 \n",
      "Epoch:  184 | loss: 0.005091688596 \n",
      "Epoch:  185 | loss: 0.005091688596 \n",
      "Epoch:  186 | loss: 0.005091688596 \n",
      "Epoch:  187 | loss: 0.005091688596 \n",
      "Epoch:  188 | loss: 0.005091688596 \n",
      "Epoch:  189 | loss: 0.005091688596 \n",
      "Epoch:  190 | loss: 0.005091688596 \n",
      "Epoch:  191 | loss: 0.005091688596 \n",
      "Epoch:  192 | loss: 0.005091688596 \n",
      "Epoch:  193 | loss: 0.005091688596 \n",
      "Epoch:  194 | loss: 0.005091688596 \n",
      "Epoch:  195 | loss: 0.005091688596 \n",
      "Epoch:  196 | loss: 0.005091688596 \n",
      "Epoch:  197 | loss: 0.005091688596 \n",
      "Epoch:  198 | loss: 0.005091689061 \n",
      "Epoch:  199 | loss: 0.005091689061 \n",
      "Epoch:  200 | loss: 0.005091688596 \n",
      "Epoch:  201 | loss: 0.005091688596 \n",
      "Epoch:  202 | loss: 0.005091688596 \n",
      "Epoch:  203 | loss: 0.005091688596 \n",
      "Epoch:  204 | loss: 0.005091688596 \n",
      "Epoch:  205 | loss: 0.005091688596 \n",
      "Epoch:  206 | loss: 0.005091688596 \n",
      "Epoch:  207 | loss: 0.005091688596 \n",
      "Epoch:  208 | loss: 0.005091688596 \n",
      "Epoch:  209 | loss: 0.005091688596 \n",
      "Epoch:  210 | loss: 0.005091688596 \n",
      "Epoch:  211 | loss: 0.005091688596 \n",
      "Epoch:  212 | loss: 0.005091688596 \n",
      "Epoch:  213 | loss: 0.005091688596 \n",
      "Epoch:  214 | loss: 0.005091688596 \n",
      "Epoch:  215 | loss: 0.005091688596 \n",
      "Epoch:  216 | loss: 0.005091688596 \n",
      "Epoch:  217 | loss: 0.005091688596 \n",
      "Epoch:  218 | loss: 0.005091688596 \n",
      "Epoch:  219 | loss: 0.005091688596 \n",
      "Epoch:  220 | loss: 0.005091688130 \n",
      "Epoch:  221 | loss: 0.005091688596 \n",
      "Epoch:  222 | loss: 0.005091688596 \n",
      "Epoch:  223 | loss: 0.005091688596 \n",
      "Epoch:  224 | loss: 0.005091688596 \n",
      "Epoch:  225 | loss: 0.005091688596 \n",
      "Epoch:  226 | loss: 0.005091688596 \n",
      "Epoch:  227 | loss: 0.005091688596 \n",
      "Epoch:  228 | loss: 0.005091688596 \n",
      "Epoch:  229 | loss: 0.005091688596 \n",
      "Epoch:  230 | loss: 0.005091688596 \n",
      "Epoch:  231 | loss: 0.005091688596 \n",
      "Epoch:  232 | loss: 0.005091688596 \n",
      "Epoch:  233 | loss: 0.005091688596 \n",
      "Epoch:  234 | loss: 0.005091688596 \n",
      "Epoch:  235 | loss: 0.005091688596 \n",
      "Epoch:  236 | loss: 0.005091688596 \n",
      "Epoch:  237 | loss: 0.005091688596 \n",
      "Epoch:  238 | loss: 0.005091688596 \n",
      "Epoch:  239 | loss: 0.005091688596 \n",
      "Epoch:  240 | loss: 0.005091688596 \n",
      "Epoch:  241 | loss: 0.005091689061 \n",
      "Epoch:  242 | loss: 0.005091688596 \n",
      "Epoch:  243 | loss: 0.005091688596 \n",
      "Epoch:  244 | loss: 0.005091688596 \n",
      "Epoch:  245 | loss: 0.005091688596 \n",
      "Epoch:  246 | loss: 0.005091688596 \n",
      "Epoch:  247 | loss: 0.005091688596 \n",
      "Epoch:  248 | loss: 0.005091688596 \n",
      "Epoch:  249 | loss: 0.005091688596 \n",
      "Epoch:  250 | loss: 0.005091688596 \n",
      "Epoch:  251 | loss: 0.005091688596 \n",
      "Epoch:  252 | loss: 0.005091688596 \n",
      "Epoch:  253 | loss: 0.005091688596 \n",
      "Epoch:  254 | loss: 0.005091688596 \n",
      "Epoch:  255 | loss: 0.005091688596 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  256 | loss: 0.005091688596 \n",
      "Epoch:  257 | loss: 0.005091688596 \n",
      "Epoch:  258 | loss: 0.005091688596 \n",
      "Epoch:  259 | loss: 0.005091688596 \n",
      "Epoch:  260 | loss: 0.005091688596 \n",
      "Epoch:  261 | loss: 0.005091688596 \n",
      "Epoch:  262 | loss: 0.005091688596 \n",
      "Epoch:  263 | loss: 0.005091688596 \n",
      "Epoch:  264 | loss: 0.005091689061 \n",
      "Epoch:  265 | loss: 0.005091688596 \n",
      "Epoch:  266 | loss: 0.005091688596 \n",
      "Epoch:  267 | loss: 0.005091688596 \n",
      "Epoch:  268 | loss: 0.005091688596 \n",
      "Epoch:  269 | loss: 0.005091688596 \n",
      "Epoch:  270 | loss: 0.005091688596 \n",
      "Epoch:  271 | loss: 0.005091688596 \n",
      "Epoch:  272 | loss: 0.005091689061 \n",
      "Epoch:  273 | loss: 0.005091688596 \n",
      "Epoch:  274 | loss: 0.005091688596 \n",
      "Epoch:  275 | loss: 0.005091688596 \n",
      "Epoch:  276 | loss: 0.005091688596 \n",
      "Epoch:  277 | loss: 0.005091688596 \n",
      "Epoch:  278 | loss: 0.005091688596 \n",
      "Epoch:  279 | loss: 0.005091688596 \n",
      "Epoch:  280 | loss: 0.005091688596 \n",
      "Epoch:  281 | loss: 0.005091688596 \n",
      "Epoch:  282 | loss: 0.005091688130 \n",
      "Epoch:  283 | loss: 0.005091688596 \n",
      "Epoch:  284 | loss: 0.005091688596 \n",
      "Epoch:  285 | loss: 0.005091688596 \n",
      "Epoch:  286 | loss: 0.005091689061 \n",
      "Epoch:  287 | loss: 0.005091688596 \n",
      "Epoch:  288 | loss: 0.005091688596 \n",
      "Epoch:  289 | loss: 0.005091689061 \n",
      "Epoch:  290 | loss: 0.005091688596 \n",
      "Epoch:  291 | loss: 0.005091688596 \n",
      "Epoch:  292 | loss: 0.005091688596 \n",
      "Epoch:  293 | loss: 0.005091688596 \n",
      "Epoch:  294 | loss: 0.005091688596 \n",
      "Epoch:  295 | loss: 0.005091688596 \n",
      "Epoch:  296 | loss: 0.005091688596 \n",
      "Epoch:  297 | loss: 0.005091688596 \n",
      "Epoch:  298 | loss: 0.005091688596 \n",
      "Epoch:  299 | loss: 0.005091688596 \n",
      "time=48.684159994125366\n",
      "best_train_loss=0.005091688130050898\n",
      "test_loss=0.005193009972572327\n",
      "best_epoch=130\n",
      "w=40\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.005091688596 \n",
      "Epoch:  1 | loss: 0.003976702690 \n",
      "Epoch:  2 | loss: 0.003976702690 \n",
      "Epoch:  3 | loss: 0.003976703156 \n",
      "Epoch:  4 | loss: 0.003976703156 \n",
      "Epoch:  5 | loss: 0.003976703621 \n",
      "Epoch:  6 | loss: 0.003976703156 \n",
      "Epoch:  7 | loss: 0.003976703156 \n",
      "Epoch:  8 | loss: 0.003976703156 \n",
      "Epoch:  9 | loss: 0.003976703156 \n",
      "Epoch:  10 | loss: 0.003976703621 \n",
      "Epoch:  11 | loss: 0.003976702690 \n",
      "Epoch:  12 | loss: 0.003976702690 \n",
      "Epoch:  13 | loss: 0.003976702690 \n",
      "Epoch:  14 | loss: 0.003976702690 \n",
      "Epoch:  15 | loss: 0.003976702690 \n",
      "Epoch:  16 | loss: 0.003976702690 \n",
      "Epoch:  17 | loss: 0.003976702690 \n",
      "Epoch:  18 | loss: 0.003976703156 \n",
      "Epoch:  19 | loss: 0.003976702690 \n",
      "Epoch:  20 | loss: 0.003976703156 \n",
      "Epoch:  21 | loss: 0.003976702690 \n",
      "Epoch:  22 | loss: 0.003976702690 \n",
      "Epoch:  23 | loss: 0.003976702690 \n",
      "Epoch:  24 | loss: 0.003976703156 \n",
      "Epoch:  25 | loss: 0.003976702224 \n",
      "Epoch:  26 | loss: 0.003976703156 \n",
      "Epoch:  27 | loss: 0.003976703156 \n",
      "Epoch:  28 | loss: 0.003976702690 \n",
      "Epoch:  29 | loss: 0.003976702224 \n",
      "Epoch:  30 | loss: 0.003976703156 \n",
      "Epoch:  31 | loss: 0.003976702690 \n",
      "Epoch:  32 | loss: 0.003976702690 \n",
      "Epoch:  33 | loss: 0.003976702690 \n",
      "Epoch:  34 | loss: 0.003976702224 \n",
      "Epoch:  35 | loss: 0.003976702690 \n",
      "Epoch:  36 | loss: 0.003976702690 \n",
      "Epoch:  37 | loss: 0.003976703156 \n",
      "Epoch:  38 | loss: 0.003976703156 \n",
      "Epoch:  39 | loss: 0.003976703156 \n",
      "Epoch:  40 | loss: 0.003976703156 \n",
      "Epoch:  41 | loss: 0.003976703156 \n",
      "Epoch:  42 | loss: 0.003976702690 \n",
      "Epoch:  43 | loss: 0.003976702690 \n",
      "Epoch:  44 | loss: 0.003976703156 \n",
      "Epoch:  45 | loss: 0.003976703156 \n",
      "Epoch:  46 | loss: 0.003976702690 \n",
      "Epoch:  47 | loss: 0.003976702690 \n",
      "Epoch:  48 | loss: 0.003976702690 \n",
      "Epoch:  49 | loss: 0.003976702690 \n",
      "Epoch:  50 | loss: 0.003976703156 \n",
      "Epoch:  51 | loss: 0.003976702690 \n",
      "Epoch:  52 | loss: 0.003976702690 \n",
      "Epoch:  53 | loss: 0.003976702690 \n",
      "Epoch:  54 | loss: 0.003976702690 \n",
      "Epoch:  55 | loss: 0.003976703156 \n",
      "Epoch:  56 | loss: 0.003976703156 \n",
      "Epoch:  57 | loss: 0.003976703156 \n",
      "Epoch:  58 | loss: 0.003976703156 \n",
      "Epoch:  59 | loss: 0.003976702690 \n",
      "Epoch:  60 | loss: 0.003976703156 \n",
      "Epoch:  61 | loss: 0.003976703156 \n",
      "Epoch:  62 | loss: 0.003976702690 \n",
      "Epoch:  63 | loss: 0.003976702690 \n",
      "Epoch:  64 | loss: 0.003976702690 \n",
      "Epoch:  65 | loss: 0.003976702690 \n",
      "Epoch:  66 | loss: 0.003976702690 \n",
      "Epoch:  67 | loss: 0.003976703156 \n",
      "Epoch:  68 | loss: 0.003976702690 \n",
      "Epoch:  69 | loss: 0.003976702690 \n",
      "Epoch:  70 | loss: 0.003976702690 \n",
      "Epoch:  71 | loss: 0.003976703156 \n",
      "Epoch:  72 | loss: 0.003976702690 \n",
      "Epoch:  73 | loss: 0.003976702690 \n",
      "Epoch:  74 | loss: 0.003976702690 \n",
      "Epoch:  75 | loss: 0.003976703156 \n",
      "Epoch:  76 | loss: 0.003976702690 \n",
      "Epoch:  77 | loss: 0.003976702690 \n",
      "Epoch:  78 | loss: 0.003976702690 \n",
      "Epoch:  79 | loss: 0.003976702224 \n",
      "Epoch:  80 | loss: 0.003976702690 \n",
      "Epoch:  81 | loss: 0.003976702690 \n",
      "Epoch:  82 | loss: 0.003976702224 \n",
      "Epoch:  83 | loss: 0.003976702690 \n",
      "Epoch:  84 | loss: 0.003976702690 \n",
      "Epoch:  85 | loss: 0.003976702224 \n",
      "Epoch:  86 | loss: 0.003976702690 \n",
      "Epoch:  87 | loss: 0.003976702224 \n",
      "Epoch:  88 | loss: 0.003976703156 \n",
      "Epoch:  89 | loss: 0.003976702690 \n",
      "Epoch:  90 | loss: 0.003976702690 \n",
      "Epoch:  91 | loss: 0.003976702690 \n",
      "Epoch:  92 | loss: 0.003976702690 \n",
      "Epoch:  93 | loss: 0.003976702690 \n",
      "Epoch:  94 | loss: 0.003976702690 \n",
      "Epoch:  95 | loss: 0.003976702690 \n",
      "Epoch:  96 | loss: 0.003976702690 \n",
      "Epoch:  97 | loss: 0.003976702690 \n",
      "Epoch:  98 | loss: 0.003976702690 \n",
      "Epoch:  99 | loss: 0.003976702224 \n",
      "Epoch:  100 | loss: 0.003976703156 \n",
      "Epoch:  101 | loss: 0.003976702690 \n",
      "Epoch:  102 | loss: 0.003976702690 \n",
      "Epoch:  103 | loss: 0.003976702690 \n",
      "Epoch:  104 | loss: 0.003976702690 \n",
      "Epoch:  105 | loss: 0.003976702690 \n",
      "Epoch:  106 | loss: 0.003976703156 \n",
      "Epoch:  107 | loss: 0.003976703156 \n",
      "Epoch:  108 | loss: 0.003976702690 \n",
      "Epoch:  109 | loss: 0.003976702224 \n",
      "Epoch:  110 | loss: 0.003976702690 \n",
      "Epoch:  111 | loss: 0.003976703156 \n",
      "Epoch:  112 | loss: 0.003976703156 \n",
      "Epoch:  113 | loss: 0.003976702690 \n",
      "Epoch:  114 | loss: 0.003976702690 \n",
      "Epoch:  115 | loss: 0.003976703156 \n",
      "Epoch:  116 | loss: 0.003976702690 \n",
      "Epoch:  117 | loss: 0.003976703156 \n",
      "Epoch:  118 | loss: 0.003976702690 \n",
      "Epoch:  119 | loss: 0.003976702690 \n",
      "Epoch:  120 | loss: 0.003976702690 \n",
      "Epoch:  121 | loss: 0.003976702690 \n",
      "Epoch:  122 | loss: 0.003976702224 \n",
      "Epoch:  123 | loss: 0.003976702690 \n",
      "Epoch:  124 | loss: 0.003976703156 \n",
      "Epoch:  125 | loss: 0.003976702690 \n",
      "Epoch:  126 | loss: 0.003976703156 \n",
      "Epoch:  127 | loss: 0.003976702224 \n",
      "Epoch:  128 | loss: 0.003976702224 \n",
      "Epoch:  129 | loss: 0.003976702224 \n",
      "Epoch:  130 | loss: 0.003976702690 \n",
      "Epoch:  131 | loss: 0.003976702690 \n",
      "Epoch:  132 | loss: 0.003976702224 \n",
      "Epoch:  133 | loss: 0.003976702224 \n",
      "Epoch:  134 | loss: 0.003976702224 \n",
      "Epoch:  135 | loss: 0.003976702224 \n",
      "Epoch:  136 | loss: 0.003976702224 \n",
      "Epoch:  137 | loss: 0.003976702224 \n",
      "Epoch:  138 | loss: 0.003976702224 \n",
      "Epoch:  139 | loss: 0.003976702224 \n",
      "Epoch:  140 | loss: 0.003976702224 \n",
      "Epoch:  141 | loss: 0.003976702224 \n",
      "Epoch:  142 | loss: 0.003976702224 \n",
      "Epoch:  143 | loss: 0.003976702690 \n",
      "Epoch:  144 | loss: 0.003976702224 \n",
      "Epoch:  145 | loss: 0.003976702690 \n",
      "Epoch:  146 | loss: 0.003976702224 \n",
      "Epoch:  147 | loss: 0.003976702224 \n",
      "Epoch:  148 | loss: 0.003976702224 \n",
      "Epoch:  149 | loss: 0.003976702224 \n",
      "Epoch:  150 | loss: 0.003976702224 \n",
      "Epoch:  151 | loss: 0.003976702224 \n",
      "Epoch:  152 | loss: 0.003976702224 \n",
      "Epoch:  153 | loss: 0.003976702224 \n",
      "Epoch:  154 | loss: 0.003976702224 \n",
      "Epoch:  155 | loss: 0.003976702224 \n",
      "Epoch:  156 | loss: 0.003976702224 \n",
      "Epoch:  157 | loss: 0.003976702224 \n",
      "Epoch:  158 | loss: 0.003976702224 \n",
      "Epoch:  159 | loss: 0.003976702224 \n",
      "Epoch:  160 | loss: 0.003976701759 \n",
      "Epoch:  161 | loss: 0.003976701759 \n",
      "Epoch:  162 | loss: 0.003976701759 \n",
      "Epoch:  163 | loss: 0.003976702224 \n",
      "Epoch:  164 | loss: 0.003976701759 \n",
      "Epoch:  165 | loss: 0.003976702224 \n",
      "Epoch:  166 | loss: 0.003976701293 \n",
      "Epoch:  167 | loss: 0.003976702224 \n",
      "Epoch:  168 | loss: 0.003976701759 \n",
      "Epoch:  169 | loss: 0.003976701759 \n",
      "Epoch:  170 | loss: 0.003976701759 \n",
      "Epoch:  171 | loss: 0.003976701759 \n",
      "Epoch:  172 | loss: 0.003976701293 \n",
      "Epoch:  173 | loss: 0.003976701759 \n",
      "Epoch:  174 | loss: 0.003976701293 \n",
      "Epoch:  175 | loss: 0.003976701293 \n",
      "Epoch:  176 | loss: 0.003976701759 \n",
      "Epoch:  177 | loss: 0.003976701759 \n",
      "Epoch:  178 | loss: 0.003976701759 \n",
      "Epoch:  179 | loss: 0.003976701759 \n",
      "Epoch:  180 | loss: 0.003976701293 \n",
      "Epoch:  181 | loss: 0.003976701293 \n",
      "Epoch:  182 | loss: 0.003976701293 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  183 | loss: 0.003976701759 \n",
      "Epoch:  184 | loss: 0.003976701293 \n",
      "Epoch:  185 | loss: 0.003976701759 \n",
      "Epoch:  186 | loss: 0.003976701759 \n",
      "Epoch:  187 | loss: 0.003976701293 \n",
      "Epoch:  188 | loss: 0.003976701293 \n",
      "Epoch:  189 | loss: 0.003976701759 \n",
      "Epoch:  190 | loss: 0.003976701759 \n",
      "Epoch:  191 | loss: 0.003976701293 \n",
      "Epoch:  192 | loss: 0.003976701293 \n",
      "Epoch:  193 | loss: 0.003976701293 \n",
      "Epoch:  194 | loss: 0.003976701759 \n",
      "Epoch:  195 | loss: 0.003976701293 \n",
      "Epoch:  196 | loss: 0.003976701293 \n",
      "Epoch:  197 | loss: 0.003976701293 \n",
      "Epoch:  198 | loss: 0.003976701293 \n",
      "Epoch:  199 | loss: 0.003976701759 \n",
      "Epoch:  200 | loss: 0.003976701293 \n",
      "Epoch:  201 | loss: 0.003976701293 \n",
      "Epoch:  202 | loss: 0.003976701293 \n",
      "Epoch:  203 | loss: 0.003976701293 \n",
      "Epoch:  204 | loss: 0.003976701759 \n",
      "Epoch:  205 | loss: 0.003976701293 \n",
      "Epoch:  206 | loss: 0.003976701293 \n",
      "Epoch:  207 | loss: 0.003976702224 \n",
      "Epoch:  208 | loss: 0.003976701759 \n",
      "Epoch:  209 | loss: 0.003976701293 \n",
      "Epoch:  210 | loss: 0.003976701759 \n",
      "Epoch:  211 | loss: 0.003976701759 \n",
      "Epoch:  212 | loss: 0.003976701293 \n",
      "Epoch:  213 | loss: 0.003976701293 \n",
      "Epoch:  214 | loss: 0.003976701293 \n",
      "Epoch:  215 | loss: 0.003976701293 \n",
      "Epoch:  216 | loss: 0.003976701293 \n",
      "Epoch:  217 | loss: 0.003976701759 \n",
      "Epoch:  218 | loss: 0.003976701759 \n",
      "Epoch:  219 | loss: 0.003976701293 \n",
      "Epoch:  220 | loss: 0.003976701293 \n",
      "Epoch:  221 | loss: 0.003976701293 \n",
      "Epoch:  222 | loss: 0.003976701759 \n",
      "Epoch:  223 | loss: 0.003976701293 \n",
      "Epoch:  224 | loss: 0.003976701293 \n",
      "Epoch:  225 | loss: 0.003976701759 \n",
      "Epoch:  226 | loss: 0.003976701759 \n",
      "Epoch:  227 | loss: 0.003976701293 \n",
      "Epoch:  228 | loss: 0.003976701293 \n",
      "Epoch:  229 | loss: 0.003976701759 \n",
      "Epoch:  230 | loss: 0.003976701293 \n",
      "Epoch:  231 | loss: 0.003976701759 \n",
      "Epoch:  232 | loss: 0.003976701293 \n",
      "Epoch:  233 | loss: 0.003976701759 \n",
      "Epoch:  234 | loss: 0.003976701293 \n",
      "Epoch:  235 | loss: 0.003976701759 \n",
      "Epoch:  236 | loss: 0.003976701293 \n",
      "Epoch:  237 | loss: 0.003976701293 \n",
      "Epoch:  238 | loss: 0.003976701293 \n",
      "Epoch:  239 | loss: 0.003976701759 \n",
      "Epoch:  240 | loss: 0.003976701293 \n",
      "Epoch:  241 | loss: 0.003976701293 \n",
      "Epoch:  242 | loss: 0.003976701759 \n",
      "Epoch:  243 | loss: 0.003976701293 \n",
      "Epoch:  244 | loss: 0.003976701293 \n",
      "Epoch:  245 | loss: 0.003976701293 \n",
      "Epoch:  246 | loss: 0.003976701759 \n",
      "Epoch:  247 | loss: 0.003976701293 \n",
      "Epoch:  248 | loss: 0.003976701293 \n",
      "Epoch:  249 | loss: 0.003976701293 \n",
      "Epoch:  250 | loss: 0.003976701293 \n",
      "Epoch:  251 | loss: 0.003976701759 \n",
      "Epoch:  252 | loss: 0.003976701293 \n",
      "Epoch:  253 | loss: 0.003976701293 \n",
      "Epoch:  254 | loss: 0.003976701293 \n",
      "Epoch:  255 | loss: 0.003976701293 \n",
      "Epoch:  256 | loss: 0.003976701759 \n",
      "Epoch:  257 | loss: 0.003976701759 \n",
      "Epoch:  258 | loss: 0.003976701293 \n",
      "Epoch:  259 | loss: 0.003976701293 \n",
      "Epoch:  260 | loss: 0.003976701759 \n",
      "Epoch:  261 | loss: 0.003976701293 \n",
      "Epoch:  262 | loss: 0.003976701293 \n",
      "Epoch:  263 | loss: 0.003976701759 \n",
      "Epoch:  264 | loss: 0.003976701293 \n",
      "Epoch:  265 | loss: 0.003976701293 \n",
      "Epoch:  266 | loss: 0.003976701293 \n",
      "Epoch:  267 | loss: 0.003976701293 \n",
      "Epoch:  268 | loss: 0.003976701759 \n",
      "Epoch:  269 | loss: 0.003976701293 \n",
      "Epoch:  270 | loss: 0.003976701759 \n",
      "Epoch:  271 | loss: 0.003976701293 \n",
      "Epoch:  272 | loss: 0.003976701293 \n",
      "Epoch:  273 | loss: 0.003976701759 \n",
      "Epoch:  274 | loss: 0.003976701293 \n",
      "Epoch:  275 | loss: 0.003976701293 \n",
      "Epoch:  276 | loss: 0.003976701293 \n",
      "Epoch:  277 | loss: 0.003976701293 \n",
      "Epoch:  278 | loss: 0.003976701293 \n",
      "Epoch:  279 | loss: 0.003976701293 \n",
      "Epoch:  280 | loss: 0.003976701293 \n",
      "Epoch:  281 | loss: 0.003976701759 \n",
      "Epoch:  282 | loss: 0.003976701293 \n",
      "Epoch:  283 | loss: 0.003976701293 \n",
      "Epoch:  284 | loss: 0.003976701293 \n",
      "Epoch:  285 | loss: 0.003976701293 \n",
      "Epoch:  286 | loss: 0.003976701759 \n",
      "Epoch:  287 | loss: 0.003976701759 \n",
      "Epoch:  288 | loss: 0.003976701759 \n",
      "Epoch:  289 | loss: 0.003976701293 \n",
      "Epoch:  290 | loss: 0.003976701759 \n",
      "Epoch:  291 | loss: 0.003976701293 \n",
      "Epoch:  292 | loss: 0.003976701293 \n",
      "Epoch:  293 | loss: 0.003976701293 \n",
      "Epoch:  294 | loss: 0.003976701293 \n",
      "Epoch:  295 | loss: 0.003976701759 \n",
      "Epoch:  296 | loss: 0.003976701293 \n",
      "Epoch:  297 | loss: 0.003976701759 \n",
      "Epoch:  298 | loss: 0.003976701293 \n",
      "Epoch:  299 | loss: 0.003976701293 \n",
      "time=44.661935806274414\n",
      "best_train_loss=0.00397670129314065\n",
      "test_loss=0.004244065843522549\n",
      "best_epoch=166\n",
      "w=45\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.003976701293 \n",
      "Epoch:  1 | loss: 0.003976701293 \n",
      "Epoch:  2 | loss: 0.003976701293 \n",
      "Epoch:  3 | loss: 0.003976701293 \n",
      "Epoch:  4 | loss: 0.003976701293 \n",
      "Epoch:  5 | loss: 0.003976701293 \n",
      "Epoch:  6 | loss: 0.003976701293 \n",
      "Epoch:  7 | loss: 0.003976701293 \n",
      "Epoch:  8 | loss: 0.003976701293 \n",
      "Epoch:  9 | loss: 0.003976701293 \n",
      "Epoch:  10 | loss: 0.003976701293 \n",
      "Epoch:  11 | loss: 0.003976701293 \n",
      "Epoch:  12 | loss: 0.003976701293 \n",
      "Epoch:  13 | loss: 0.003976701759 \n",
      "Epoch:  14 | loss: 0.003976701759 \n",
      "Epoch:  15 | loss: 0.003976701759 \n",
      "Epoch:  16 | loss: 0.003976701293 \n",
      "Epoch:  17 | loss: 0.003976701293 \n",
      "Epoch:  18 | loss: 0.003976701759 \n",
      "Epoch:  19 | loss: 0.003976701293 \n",
      "Epoch:  20 | loss: 0.003976701293 \n",
      "Epoch:  21 | loss: 0.003976701759 \n",
      "Epoch:  22 | loss: 0.003976701293 \n",
      "Epoch:  23 | loss: 0.003976701293 \n",
      "Epoch:  24 | loss: 0.003976701293 \n",
      "Epoch:  25 | loss: 0.003976701293 \n",
      "Epoch:  26 | loss: 0.003976701293 \n",
      "Epoch:  27 | loss: 0.003976701293 \n",
      "Epoch:  28 | loss: 0.003976701293 \n",
      "Epoch:  29 | loss: 0.003976701293 \n",
      "Epoch:  30 | loss: 0.003976701293 \n",
      "Epoch:  31 | loss: 0.003976701293 \n",
      "Epoch:  32 | loss: 0.003976701293 \n",
      "Epoch:  33 | loss: 0.003976701293 \n",
      "Epoch:  34 | loss: 0.003976701293 \n",
      "Epoch:  35 | loss: 0.003976701293 \n",
      "Epoch:  36 | loss: 0.003976701293 \n",
      "Epoch:  37 | loss: 0.003976701293 \n",
      "Epoch:  38 | loss: 0.003976701293 \n",
      "Epoch:  39 | loss: 0.003976701293 \n",
      "Epoch:  40 | loss: 0.003976701293 \n",
      "Epoch:  41 | loss: 0.003976701293 \n",
      "Epoch:  42 | loss: 0.003976701293 \n",
      "Epoch:  43 | loss: 0.003976701293 \n",
      "Epoch:  44 | loss: 0.003976701293 \n",
      "Epoch:  45 | loss: 0.003976701293 \n",
      "Epoch:  46 | loss: 0.003976701759 \n",
      "Epoch:  47 | loss: 0.003976701293 \n",
      "Epoch:  48 | loss: 0.003976701293 \n",
      "Epoch:  49 | loss: 0.003976701293 \n",
      "Epoch:  50 | loss: 0.003976701293 \n",
      "Epoch:  51 | loss: 0.003976701293 \n",
      "Epoch:  52 | loss: 0.003976701293 \n",
      "Epoch:  53 | loss: 0.003976701293 \n",
      "Epoch:  54 | loss: 0.003976701293 \n",
      "Epoch:  55 | loss: 0.003976701293 \n",
      "Epoch:  56 | loss: 0.003976701293 \n",
      "Epoch:  57 | loss: 0.003976701293 \n",
      "Epoch:  58 | loss: 0.003976701293 \n",
      "Epoch:  59 | loss: 0.003976701293 \n",
      "Epoch:  60 | loss: 0.003976701293 \n",
      "Epoch:  61 | loss: 0.003976701759 \n",
      "Epoch:  62 | loss: 0.003976701293 \n",
      "Epoch:  63 | loss: 0.003976701293 \n",
      "Epoch:  64 | loss: 0.003976701293 \n",
      "Epoch:  65 | loss: 0.003976701759 \n",
      "Epoch:  66 | loss: 0.003976701293 \n",
      "Epoch:  67 | loss: 0.003976701759 \n",
      "Epoch:  68 | loss: 0.003976701293 \n",
      "Epoch:  69 | loss: 0.003976701293 \n",
      "Epoch:  70 | loss: 0.003976701293 \n",
      "Epoch:  71 | loss: 0.003976701293 \n",
      "Epoch:  72 | loss: 0.003976701293 \n",
      "Epoch:  73 | loss: 0.003976701293 \n",
      "Epoch:  74 | loss: 0.003976701293 \n",
      "Epoch:  75 | loss: 0.003976701293 \n",
      "Epoch:  76 | loss: 0.003976701293 \n",
      "Epoch:  77 | loss: 0.003976701293 \n",
      "Epoch:  78 | loss: 0.003976701293 \n",
      "Epoch:  79 | loss: 0.003976701759 \n",
      "Epoch:  80 | loss: 0.003976701293 \n",
      "Epoch:  81 | loss: 0.003976701293 \n",
      "Epoch:  82 | loss: 0.003976701293 \n",
      "Epoch:  83 | loss: 0.003976701293 \n",
      "Epoch:  84 | loss: 0.003976701293 \n",
      "Epoch:  85 | loss: 0.003976701293 \n",
      "Epoch:  86 | loss: 0.003976701293 \n",
      "Epoch:  87 | loss: 0.003976701759 \n",
      "Epoch:  88 | loss: 0.003976701293 \n",
      "Epoch:  89 | loss: 0.003976701293 \n",
      "Epoch:  90 | loss: 0.003976701293 \n",
      "Epoch:  91 | loss: 0.003976701293 \n",
      "Epoch:  92 | loss: 0.003976701293 \n",
      "Epoch:  93 | loss: 0.003976701293 \n",
      "Epoch:  94 | loss: 0.003976701293 \n",
      "Epoch:  95 | loss: 0.003976701293 \n",
      "Epoch:  96 | loss: 0.003976701293 \n",
      "Epoch:  97 | loss: 0.003976701293 \n",
      "Epoch:  98 | loss: 0.003976701293 \n",
      "Epoch:  99 | loss: 0.003976701293 \n",
      "Epoch:  100 | loss: 0.003976701293 \n",
      "Epoch:  101 | loss: 0.003976701293 \n",
      "Epoch:  102 | loss: 0.003976701293 \n",
      "Epoch:  103 | loss: 0.003976701293 \n",
      "Epoch:  104 | loss: 0.003976701293 \n",
      "Epoch:  105 | loss: 0.003976701293 \n",
      "Epoch:  106 | loss: 0.003976701293 \n",
      "Epoch:  107 | loss: 0.003976701293 \n",
      "Epoch:  108 | loss: 0.003976701293 \n",
      "Epoch:  109 | loss: 0.003976701293 \n",
      "Epoch:  110 | loss: 0.003976701293 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  111 | loss: 0.003976701293 \n",
      "Epoch:  112 | loss: 0.003976701293 \n",
      "Epoch:  113 | loss: 0.003976701293 \n",
      "Epoch:  114 | loss: 0.003976701293 \n",
      "Epoch:  115 | loss: 0.003976701293 \n",
      "Epoch:  116 | loss: 0.003976701293 \n",
      "Epoch:  117 | loss: 0.003976701293 \n",
      "Epoch:  118 | loss: 0.003976701293 \n",
      "Epoch:  119 | loss: 0.003976701293 \n",
      "Epoch:  120 | loss: 0.003976701293 \n",
      "Epoch:  121 | loss: 0.003976701293 \n",
      "Epoch:  122 | loss: 0.003976701293 \n",
      "Epoch:  123 | loss: 0.003976701293 \n",
      "Epoch:  124 | loss: 0.003976701293 \n",
      "Epoch:  125 | loss: 0.003976701293 \n",
      "Epoch:  126 | loss: 0.003976701293 \n",
      "Epoch:  127 | loss: 0.003976701293 \n",
      "Epoch:  128 | loss: 0.003976701293 \n",
      "Epoch:  129 | loss: 0.003976701293 \n",
      "Epoch:  130 | loss: 0.003976701293 \n",
      "Epoch:  131 | loss: 0.003976701293 \n",
      "Epoch:  132 | loss: 0.003976701293 \n",
      "Epoch:  133 | loss: 0.003976701293 \n",
      "Epoch:  134 | loss: 0.003976701293 \n",
      "Epoch:  135 | loss: 0.003976701293 \n",
      "Epoch:  136 | loss: 0.003976701293 \n",
      "Epoch:  137 | loss: 0.003976701293 \n",
      "Epoch:  138 | loss: 0.003976701293 \n",
      "Epoch:  139 | loss: 0.003976701293 \n",
      "Epoch:  140 | loss: 0.003976701293 \n",
      "Epoch:  141 | loss: 0.003976701293 \n",
      "Epoch:  142 | loss: 0.003976701293 \n",
      "Epoch:  143 | loss: 0.003976701293 \n",
      "Epoch:  144 | loss: 0.003976701293 \n",
      "Epoch:  145 | loss: 0.003976701293 \n",
      "Epoch:  146 | loss: 0.003976701293 \n",
      "Epoch:  147 | loss: 0.003976701293 \n",
      "Epoch:  148 | loss: 0.003976701293 \n",
      "Epoch:  149 | loss: 0.003976701293 \n",
      "Epoch:  150 | loss: 0.003976701293 \n",
      "Epoch:  151 | loss: 0.003976701293 \n",
      "Epoch:  152 | loss: 0.003976701293 \n",
      "Epoch:  153 | loss: 0.003976701293 \n",
      "Epoch:  154 | loss: 0.003976701293 \n",
      "Epoch:  155 | loss: 0.003976701293 \n",
      "Epoch:  156 | loss: 0.003976701293 \n",
      "Epoch:  157 | loss: 0.003976701293 \n",
      "Epoch:  158 | loss: 0.003976701293 \n",
      "Epoch:  159 | loss: 0.003976701293 \n",
      "Epoch:  160 | loss: 0.003976701293 \n",
      "Epoch:  161 | loss: 0.003976701293 \n",
      "Epoch:  162 | loss: 0.003976701293 \n",
      "Epoch:  163 | loss: 0.003976701293 \n",
      "Epoch:  164 | loss: 0.003976701759 \n",
      "Epoch:  165 | loss: 0.003976701293 \n",
      "Epoch:  166 | loss: 0.003976701293 \n",
      "Epoch:  167 | loss: 0.003976701293 \n",
      "Epoch:  168 | loss: 0.003976701293 \n",
      "Epoch:  169 | loss: 0.003976701293 \n",
      "Epoch:  170 | loss: 0.003976701293 \n",
      "Epoch:  171 | loss: 0.003976701293 \n",
      "Epoch:  172 | loss: 0.003976701293 \n",
      "Epoch:  173 | loss: 0.003976701293 \n",
      "Epoch:  174 | loss: 0.003976701293 \n",
      "Epoch:  175 | loss: 0.003976701293 \n",
      "Epoch:  176 | loss: 0.003976701293 \n",
      "Epoch:  177 | loss: 0.003976701293 \n",
      "Epoch:  178 | loss: 0.003976701293 \n",
      "Epoch:  179 | loss: 0.003976701293 \n",
      "Epoch:  180 | loss: 0.003976701293 \n",
      "Epoch:  181 | loss: 0.003976701293 \n",
      "Epoch:  182 | loss: 0.003976701293 \n",
      "Epoch:  183 | loss: 0.003976701293 \n",
      "Epoch:  184 | loss: 0.003976701293 \n",
      "Epoch:  185 | loss: 0.003976701293 \n",
      "Epoch:  186 | loss: 0.003976701293 \n",
      "Epoch:  187 | loss: 0.003976701293 \n",
      "Epoch:  188 | loss: 0.003976701293 \n",
      "Epoch:  189 | loss: 0.003976701293 \n",
      "Epoch:  190 | loss: 0.003976701293 \n",
      "Epoch:  191 | loss: 0.003976701293 \n",
      "Epoch:  192 | loss: 0.003976701293 \n",
      "Epoch:  193 | loss: 0.003976701293 \n",
      "Epoch:  194 | loss: 0.003976701293 \n",
      "Epoch:  195 | loss: 0.003976701293 \n",
      "Epoch:  196 | loss: 0.003976701293 \n",
      "Epoch:  197 | loss: 0.003976701293 \n",
      "Epoch:  198 | loss: 0.003976701293 \n",
      "Epoch:  199 | loss: 0.003976701293 \n",
      "Epoch:  200 | loss: 0.003976694774 \n",
      "Epoch:  201 | loss: 0.003976695705 \n",
      "Epoch:  202 | loss: 0.003976695240 \n",
      "Epoch:  203 | loss: 0.003976695705 \n",
      "Epoch:  204 | loss: 0.003976695240 \n",
      "Epoch:  205 | loss: 0.003976695240 \n",
      "Epoch:  206 | loss: 0.003976695240 \n",
      "Epoch:  207 | loss: 0.003976695240 \n",
      "Epoch:  208 | loss: 0.003976694774 \n",
      "Epoch:  209 | loss: 0.003976695240 \n",
      "Epoch:  210 | loss: 0.003976694774 \n",
      "Epoch:  211 | loss: 0.003976694774 \n",
      "Epoch:  212 | loss: 0.003976695705 \n",
      "Epoch:  213 | loss: 0.003976694774 \n",
      "Epoch:  214 | loss: 0.003976695240 \n",
      "Epoch:  215 | loss: 0.003976695240 \n",
      "Epoch:  216 | loss: 0.003976695240 \n",
      "Epoch:  217 | loss: 0.003976695240 \n",
      "Epoch:  218 | loss: 0.003976695240 \n",
      "Epoch:  219 | loss: 0.003976695240 \n",
      "Epoch:  220 | loss: 0.003976695240 \n",
      "Epoch:  221 | loss: 0.003976695240 \n",
      "Epoch:  222 | loss: 0.003976695240 \n",
      "Epoch:  223 | loss: 0.003976695240 \n",
      "Epoch:  224 | loss: 0.003976695240 \n",
      "Epoch:  225 | loss: 0.003976695240 \n",
      "Epoch:  226 | loss: 0.003976695240 \n",
      "Epoch:  227 | loss: 0.003976695240 \n",
      "Epoch:  228 | loss: 0.003976694774 \n",
      "Epoch:  229 | loss: 0.003976694774 \n",
      "Epoch:  230 | loss: 0.003976695705 \n",
      "Epoch:  231 | loss: 0.003976695240 \n",
      "Epoch:  232 | loss: 0.003976694774 \n",
      "Epoch:  233 | loss: 0.003976695240 \n",
      "Epoch:  234 | loss: 0.003976695705 \n",
      "Epoch:  235 | loss: 0.003976694774 \n",
      "Epoch:  236 | loss: 0.003976695240 \n",
      "Epoch:  237 | loss: 0.003976695240 \n",
      "Epoch:  238 | loss: 0.003976695240 \n",
      "Epoch:  239 | loss: 0.003976694774 \n",
      "Epoch:  240 | loss: 0.003976694774 \n",
      "Epoch:  241 | loss: 0.003976694774 \n",
      "Epoch:  242 | loss: 0.003976694774 \n",
      "Epoch:  243 | loss: 0.003976695240 \n",
      "Epoch:  244 | loss: 0.003976694774 \n",
      "Epoch:  245 | loss: 0.003976695240 \n",
      "Epoch:  246 | loss: 0.003976694774 \n",
      "Epoch:  247 | loss: 0.003976694774 \n",
      "Epoch:  248 | loss: 0.003976695240 \n",
      "Epoch:  249 | loss: 0.003976694774 \n",
      "Epoch:  250 | loss: 0.003976695240 \n",
      "Epoch:  251 | loss: 0.003976694774 \n",
      "Epoch:  252 | loss: 0.003976695240 \n",
      "Epoch:  253 | loss: 0.003976695240 \n",
      "Epoch:  254 | loss: 0.003976695240 \n",
      "Epoch:  255 | loss: 0.003976695240 \n",
      "Epoch:  256 | loss: 0.003976695240 \n",
      "Epoch:  257 | loss: 0.003976694774 \n",
      "Epoch:  258 | loss: 0.003976695240 \n",
      "Epoch:  259 | loss: 0.003976694774 \n",
      "Epoch:  260 | loss: 0.003976695240 \n",
      "Epoch:  261 | loss: 0.003976695240 \n",
      "Epoch:  262 | loss: 0.003976695240 \n",
      "Epoch:  263 | loss: 0.003976695705 \n",
      "Epoch:  264 | loss: 0.003976695240 \n",
      "Epoch:  265 | loss: 0.003976694774 \n",
      "Epoch:  266 | loss: 0.003976695240 \n",
      "Epoch:  267 | loss: 0.003976695240 \n",
      "Epoch:  268 | loss: 0.003976694774 \n",
      "Epoch:  269 | loss: 0.003976694774 \n",
      "Epoch:  270 | loss: 0.003976695240 \n",
      "Epoch:  271 | loss: 0.003976695240 \n",
      "Epoch:  272 | loss: 0.003976695240 \n",
      "Epoch:  273 | loss: 0.003976695240 \n",
      "Epoch:  274 | loss: 0.003976694774 \n",
      "Epoch:  275 | loss: 0.003976695240 \n",
      "Epoch:  276 | loss: 0.003976695240 \n",
      "Epoch:  277 | loss: 0.003976695240 \n",
      "Epoch:  278 | loss: 0.003976694774 \n",
      "Epoch:  279 | loss: 0.003976695240 \n",
      "Epoch:  280 | loss: 0.003976695240 \n",
      "Epoch:  281 | loss: 0.003976694774 \n",
      "Epoch:  282 | loss: 0.003976695240 \n",
      "Epoch:  283 | loss: 0.003976694774 \n",
      "Epoch:  284 | loss: 0.003976695240 \n",
      "Epoch:  285 | loss: 0.003976695240 \n",
      "Epoch:  286 | loss: 0.003976695240 \n",
      "Epoch:  287 | loss: 0.003976695240 \n",
      "Epoch:  288 | loss: 0.003976695240 \n",
      "Epoch:  289 | loss: 0.003976695240 \n",
      "Epoch:  290 | loss: 0.003976695240 \n",
      "Epoch:  291 | loss: 0.003976695240 \n",
      "Epoch:  292 | loss: 0.003976694774 \n",
      "Epoch:  293 | loss: 0.003976695240 \n",
      "Epoch:  294 | loss: 0.003976694774 \n",
      "Epoch:  295 | loss: 0.003976695240 \n",
      "Epoch:  296 | loss: 0.003976695240 \n",
      "Epoch:  297 | loss: 0.003976695240 \n",
      "Epoch:  298 | loss: 0.003976695240 \n",
      "Epoch:  299 | loss: 0.003976694774 \n",
      "time=37.59902095794678\n",
      "best_train_loss=0.0039766947738826275\n",
      "test_loss=0.004244058392941952\n",
      "best_epoch=200\n",
      "w=50\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.003976691980 \n",
      "Epoch:  1 | loss: 0.003976692446 \n",
      "Epoch:  2 | loss: 0.003976692911 \n",
      "Epoch:  3 | loss: 0.003976691980 \n",
      "Epoch:  4 | loss: 0.003976692446 \n",
      "Epoch:  5 | loss: 0.003976691980 \n",
      "Epoch:  6 | loss: 0.003976692446 \n",
      "Epoch:  7 | loss: 0.003976692446 \n",
      "Epoch:  8 | loss: 0.003976691980 \n",
      "Epoch:  9 | loss: 0.003976692446 \n",
      "Epoch:  10 | loss: 0.003976691980 \n",
      "Epoch:  11 | loss: 0.003976691980 \n",
      "Epoch:  12 | loss: 0.003976691980 \n",
      "Epoch:  13 | loss: 0.003976691980 \n",
      "Epoch:  14 | loss: 0.003976691980 \n",
      "Epoch:  15 | loss: 0.003976692446 \n",
      "Epoch:  16 | loss: 0.003976691980 \n",
      "Epoch:  17 | loss: 0.003976691980 \n",
      "Epoch:  18 | loss: 0.003976691980 \n",
      "Epoch:  19 | loss: 0.003976691980 \n",
      "Epoch:  20 | loss: 0.003976692446 \n",
      "Epoch:  21 | loss: 0.003976691980 \n",
      "Epoch:  22 | loss: 0.003976691980 \n",
      "Epoch:  23 | loss: 0.003976691980 \n",
      "Epoch:  24 | loss: 0.003976692446 \n",
      "Epoch:  25 | loss: 0.003976692446 \n",
      "Epoch:  26 | loss: 0.003976692446 \n",
      "Epoch:  27 | loss: 0.003976692446 \n",
      "Epoch:  28 | loss: 0.003976692446 \n",
      "Epoch:  29 | loss: 0.003976692446 \n",
      "Epoch:  30 | loss: 0.003976692446 \n",
      "Epoch:  31 | loss: 0.003976692446 \n",
      "Epoch:  32 | loss: 0.003976691980 \n",
      "Epoch:  33 | loss: 0.003976692446 \n",
      "Epoch:  34 | loss: 0.003976692446 \n",
      "Epoch:  35 | loss: 0.003976692446 \n",
      "Epoch:  36 | loss: 0.003976692911 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  37 | loss: 0.003976692446 \n",
      "Epoch:  38 | loss: 0.003976691980 \n",
      "Epoch:  39 | loss: 0.003976691980 \n",
      "Epoch:  40 | loss: 0.003976691980 \n",
      "Epoch:  41 | loss: 0.003976691980 \n",
      "Epoch:  42 | loss: 0.003976692446 \n",
      "Epoch:  43 | loss: 0.003976691980 \n",
      "Epoch:  44 | loss: 0.003976691980 \n",
      "Epoch:  45 | loss: 0.003976692446 \n",
      "Epoch:  46 | loss: 0.003976692446 \n",
      "Epoch:  47 | loss: 0.003976691980 \n",
      "Epoch:  48 | loss: 0.003976691980 \n",
      "Epoch:  49 | loss: 0.003976691980 \n",
      "Epoch:  50 | loss: 0.003976691980 \n",
      "Epoch:  51 | loss: 0.003976691980 \n",
      "Epoch:  52 | loss: 0.003976691980 \n",
      "Epoch:  53 | loss: 0.003976691980 \n",
      "Epoch:  54 | loss: 0.003976691980 \n",
      "Epoch:  55 | loss: 0.003976691980 \n",
      "Epoch:  56 | loss: 0.003976691980 \n",
      "Epoch:  57 | loss: 0.003976691980 \n",
      "Epoch:  58 | loss: 0.003976692446 \n",
      "Epoch:  59 | loss: 0.003976692446 \n",
      "Epoch:  60 | loss: 0.003976692446 \n",
      "Epoch:  61 | loss: 0.003976692446 \n",
      "Epoch:  62 | loss: 0.003976691980 \n",
      "Epoch:  63 | loss: 0.003976691980 \n",
      "Epoch:  64 | loss: 0.003976691980 \n",
      "Epoch:  65 | loss: 0.003976691980 \n",
      "Epoch:  66 | loss: 0.003976692446 \n",
      "Epoch:  67 | loss: 0.003976691980 \n",
      "Epoch:  68 | loss: 0.003976691980 \n",
      "Epoch:  69 | loss: 0.003976691980 \n",
      "Epoch:  70 | loss: 0.003976691980 \n",
      "Epoch:  71 | loss: 0.003976691980 \n",
      "Epoch:  72 | loss: 0.003976691980 \n",
      "Epoch:  73 | loss: 0.003976691980 \n",
      "Epoch:  74 | loss: 0.003976691980 \n",
      "Epoch:  75 | loss: 0.003976691980 \n",
      "Epoch:  76 | loss: 0.003976691980 \n",
      "Epoch:  77 | loss: 0.003976691980 \n",
      "Epoch:  78 | loss: 0.003976691980 \n",
      "Epoch:  79 | loss: 0.003976691980 \n",
      "Epoch:  80 | loss: 0.003976691980 \n",
      "Epoch:  81 | loss: 0.003976691980 \n",
      "Epoch:  82 | loss: 0.003976691980 \n",
      "Epoch:  83 | loss: 0.003976691980 \n",
      "Epoch:  84 | loss: 0.003976692446 \n",
      "Epoch:  85 | loss: 0.003976691980 \n",
      "Epoch:  86 | loss: 0.003976691980 \n",
      "Epoch:  87 | loss: 0.003976691980 \n",
      "Epoch:  88 | loss: 0.003976691980 \n",
      "Epoch:  89 | loss: 0.003976691980 \n",
      "Epoch:  90 | loss: 0.003976691980 \n",
      "Epoch:  91 | loss: 0.003976692446 \n",
      "Epoch:  92 | loss: 0.003976691980 \n",
      "Epoch:  93 | loss: 0.003976691980 \n",
      "Epoch:  94 | loss: 0.003976691980 \n",
      "Epoch:  95 | loss: 0.003976692446 \n",
      "Epoch:  96 | loss: 0.003976691980 \n",
      "Epoch:  97 | loss: 0.003976691980 \n",
      "Epoch:  98 | loss: 0.003976692446 \n",
      "Epoch:  99 | loss: 0.003976691980 \n",
      "Epoch:  100 | loss: 0.003976691980 \n",
      "Epoch:  101 | loss: 0.003976691980 \n",
      "Epoch:  102 | loss: 0.003976692446 \n",
      "Epoch:  103 | loss: 0.003976691980 \n",
      "Epoch:  104 | loss: 0.003976691980 \n",
      "Epoch:  105 | loss: 0.003976691980 \n",
      "Epoch:  106 | loss: 0.003976691980 \n",
      "Epoch:  107 | loss: 0.003976692446 \n",
      "Epoch:  108 | loss: 0.003976691980 \n",
      "Epoch:  109 | loss: 0.003976691980 \n",
      "Epoch:  110 | loss: 0.003976692446 \n",
      "Epoch:  111 | loss: 0.003976691980 \n",
      "Epoch:  112 | loss: 0.003976692446 \n",
      "Epoch:  113 | loss: 0.003976691980 \n",
      "Epoch:  114 | loss: 0.003976691980 \n",
      "Epoch:  115 | loss: 0.003976691980 \n",
      "Epoch:  116 | loss: 0.003976691980 \n",
      "Epoch:  117 | loss: 0.003976692446 \n",
      "Epoch:  118 | loss: 0.003976691980 \n",
      "Epoch:  119 | loss: 0.003976691980 \n",
      "Epoch:  120 | loss: 0.003976692446 \n",
      "Epoch:  121 | loss: 0.003976692446 \n",
      "Epoch:  122 | loss: 0.003976692446 \n",
      "Epoch:  123 | loss: 0.003976691980 \n",
      "Epoch:  124 | loss: 0.003976691980 \n",
      "Epoch:  125 | loss: 0.003976691980 \n",
      "Epoch:  126 | loss: 0.003976691980 \n",
      "Epoch:  127 | loss: 0.003976691980 \n",
      "Epoch:  128 | loss: 0.003976691980 \n",
      "Epoch:  129 | loss: 0.003976691980 \n",
      "Epoch:  130 | loss: 0.003976691980 \n",
      "Epoch:  131 | loss: 0.003976691980 \n",
      "Epoch:  132 | loss: 0.003976691980 \n",
      "Epoch:  133 | loss: 0.003976692446 \n",
      "Epoch:  134 | loss: 0.003976691980 \n",
      "Epoch:  135 | loss: 0.003976691980 \n",
      "Epoch:  136 | loss: 0.003976691980 \n",
      "Epoch:  137 | loss: 0.003976691980 \n",
      "Epoch:  138 | loss: 0.003976692446 \n",
      "Epoch:  139 | loss: 0.003976691980 \n",
      "Epoch:  140 | loss: 0.003976692446 \n",
      "Epoch:  141 | loss: 0.003976691980 \n",
      "Epoch:  142 | loss: 0.003976691980 \n",
      "Epoch:  143 | loss: 0.003976691980 \n",
      "Epoch:  144 | loss: 0.003976691980 \n",
      "Epoch:  145 | loss: 0.003976691980 \n",
      "Epoch:  146 | loss: 0.003976691980 \n",
      "Epoch:  147 | loss: 0.003976692446 \n",
      "Epoch:  148 | loss: 0.003976692446 \n",
      "Epoch:  149 | loss: 0.003976691980 \n",
      "Epoch:  150 | loss: 0.003976691980 \n",
      "Epoch:  151 | loss: 0.003976691980 \n",
      "Epoch:  152 | loss: 0.003976691980 \n",
      "Epoch:  153 | loss: 0.003976691980 \n",
      "Epoch:  154 | loss: 0.003976691980 \n",
      "Epoch:  155 | loss: 0.003976691980 \n",
      "Epoch:  156 | loss: 0.003976692446 \n",
      "Epoch:  157 | loss: 0.003976691980 \n",
      "Epoch:  158 | loss: 0.003976691980 \n",
      "Epoch:  159 | loss: 0.003976691980 \n",
      "Epoch:  160 | loss: 0.003976691980 \n",
      "Epoch:  161 | loss: 0.003976692446 \n",
      "Epoch:  162 | loss: 0.003976691980 \n",
      "Epoch:  163 | loss: 0.003976691980 \n",
      "Epoch:  164 | loss: 0.003976691980 \n",
      "Epoch:  165 | loss: 0.003976691980 \n",
      "Epoch:  166 | loss: 0.003976691980 \n",
      "Epoch:  167 | loss: 0.003976692446 \n",
      "Epoch:  168 | loss: 0.003976691980 \n",
      "Epoch:  169 | loss: 0.003976691980 \n",
      "Epoch:  170 | loss: 0.003976692446 \n",
      "Epoch:  171 | loss: 0.003976692446 \n",
      "Epoch:  172 | loss: 0.003976692446 \n",
      "Epoch:  173 | loss: 0.003976691980 \n",
      "Epoch:  174 | loss: 0.003976691980 \n",
      "Epoch:  175 | loss: 0.003976691980 \n",
      "Epoch:  176 | loss: 0.003976691980 \n",
      "Epoch:  177 | loss: 0.003976692446 \n",
      "Epoch:  178 | loss: 0.003976691980 \n",
      "Epoch:  179 | loss: 0.003976691980 \n",
      "Epoch:  180 | loss: 0.003976691980 \n",
      "Epoch:  181 | loss: 0.003976691980 \n",
      "Epoch:  182 | loss: 0.003976692446 \n",
      "Epoch:  183 | loss: 0.003976691980 \n",
      "Epoch:  184 | loss: 0.003976691980 \n",
      "Epoch:  185 | loss: 0.003976691980 \n",
      "Epoch:  186 | loss: 0.003976691980 \n",
      "Epoch:  187 | loss: 0.003976692446 \n",
      "Epoch:  188 | loss: 0.003976691980 \n",
      "Epoch:  189 | loss: 0.003976692446 \n",
      "Epoch:  190 | loss: 0.003976692446 \n",
      "Epoch:  191 | loss: 0.003976691980 \n",
      "Epoch:  192 | loss: 0.003976692446 \n",
      "Epoch:  193 | loss: 0.003976691980 \n",
      "Epoch:  194 | loss: 0.003976691980 \n",
      "Epoch:  195 | loss: 0.003976691980 \n",
      "Epoch:  196 | loss: 0.003976691980 \n",
      "Epoch:  197 | loss: 0.003976692446 \n",
      "Epoch:  198 | loss: 0.003976691980 \n",
      "Epoch:  199 | loss: 0.003976691980 \n",
      "Epoch:  200 | loss: 0.003976691980 \n",
      "Epoch:  201 | loss: 0.003976692446 \n",
      "Epoch:  202 | loss: 0.003976692446 \n",
      "Epoch:  203 | loss: 0.003976692446 \n",
      "Epoch:  204 | loss: 0.003976691980 \n",
      "Epoch:  205 | loss: 0.003976691980 \n",
      "Epoch:  206 | loss: 0.003976691980 \n",
      "Epoch:  207 | loss: 0.003976691980 \n",
      "Epoch:  208 | loss: 0.003976691980 \n",
      "Epoch:  209 | loss: 0.003976691980 \n",
      "Epoch:  210 | loss: 0.003976691980 \n",
      "Epoch:  211 | loss: 0.003976691980 \n",
      "Epoch:  212 | loss: 0.003976691980 \n",
      "Epoch:  213 | loss: 0.003976692446 \n",
      "Epoch:  214 | loss: 0.003976692446 \n",
      "Epoch:  215 | loss: 0.003976692911 \n",
      "Epoch:  216 | loss: 0.003976691980 \n",
      "Epoch:  217 | loss: 0.003976691980 \n",
      "Epoch:  218 | loss: 0.003976691980 \n",
      "Epoch:  219 | loss: 0.003976691980 \n",
      "Epoch:  220 | loss: 0.003976692446 \n",
      "Epoch:  221 | loss: 0.003976692446 \n",
      "Epoch:  222 | loss: 0.003976691980 \n",
      "Epoch:  223 | loss: 0.003976691980 \n",
      "Epoch:  224 | loss: 0.003976692446 \n",
      "Epoch:  225 | loss: 0.003976692446 \n",
      "Epoch:  226 | loss: 0.003976692446 \n",
      "Epoch:  227 | loss: 0.003976691980 \n",
      "Epoch:  228 | loss: 0.003976692446 \n",
      "Epoch:  229 | loss: 0.003976692446 \n",
      "Epoch:  230 | loss: 0.003976691980 \n",
      "Epoch:  231 | loss: 0.003976691980 \n",
      "Epoch:  232 | loss: 0.003976692446 \n",
      "Epoch:  233 | loss: 0.003976691980 \n",
      "Epoch:  234 | loss: 0.003976692446 \n",
      "Epoch:  235 | loss: 0.003976691980 \n",
      "Epoch:  236 | loss: 0.003976691980 \n",
      "Epoch:  237 | loss: 0.003976691980 \n",
      "Epoch:  238 | loss: 0.003976692446 \n",
      "Epoch:  239 | loss: 0.003976691980 \n",
      "Epoch:  240 | loss: 0.003976691980 \n",
      "Epoch:  241 | loss: 0.003976691980 \n",
      "Epoch:  242 | loss: 0.003976691980 \n",
      "Epoch:  243 | loss: 0.003976692446 \n",
      "Epoch:  244 | loss: 0.003976692446 \n",
      "Epoch:  245 | loss: 0.003976691980 \n",
      "Epoch:  246 | loss: 0.003976691980 \n",
      "Epoch:  247 | loss: 0.003976691980 \n",
      "Epoch:  248 | loss: 0.003976691980 \n",
      "Epoch:  249 | loss: 0.003976691980 \n",
      "Epoch:  250 | loss: 0.003976691980 \n",
      "Epoch:  251 | loss: 0.003976691980 \n",
      "Epoch:  252 | loss: 0.003976692446 \n",
      "Epoch:  253 | loss: 0.003976691980 \n",
      "Epoch:  254 | loss: 0.003976691980 \n",
      "Epoch:  255 | loss: 0.003976691980 \n",
      "Epoch:  256 | loss: 0.003976691980 \n",
      "Epoch:  257 | loss: 0.003976691980 \n",
      "Epoch:  258 | loss: 0.003976691980 \n",
      "Epoch:  259 | loss: 0.003976692446 \n",
      "Epoch:  260 | loss: 0.003976691980 \n",
      "Epoch:  261 | loss: 0.003976691980 \n",
      "Epoch:  262 | loss: 0.003976691980 \n",
      "Epoch:  263 | loss: 0.003976692446 \n",
      "Epoch:  264 | loss: 0.003976691980 \n",
      "Epoch:  265 | loss: 0.003976692446 \n",
      "Epoch:  266 | loss: 0.003976691980 \n",
      "Epoch:  267 | loss: 0.003976691980 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  268 | loss: 0.003976691980 \n",
      "Epoch:  269 | loss: 0.003976691980 \n",
      "Epoch:  270 | loss: 0.003976691980 \n",
      "Epoch:  271 | loss: 0.003976692446 \n",
      "Epoch:  272 | loss: 0.003976692446 \n",
      "Epoch:  273 | loss: 0.003976691980 \n",
      "Epoch:  274 | loss: 0.003976691980 \n",
      "Epoch:  275 | loss: 0.003976691980 \n",
      "Epoch:  276 | loss: 0.003976691980 \n",
      "Epoch:  277 | loss: 0.003976692446 \n",
      "Epoch:  278 | loss: 0.003976691980 \n",
      "Epoch:  279 | loss: 0.003976691980 \n",
      "Epoch:  280 | loss: 0.003976691980 \n",
      "Epoch:  281 | loss: 0.003976692446 \n",
      "Epoch:  282 | loss: 0.003976692446 \n",
      "Epoch:  283 | loss: 0.003976691980 \n",
      "Epoch:  284 | loss: 0.003976691980 \n",
      "Epoch:  285 | loss: 0.003976691980 \n",
      "Epoch:  286 | loss: 0.003976691980 \n",
      "Epoch:  287 | loss: 0.003976691980 \n",
      "Epoch:  288 | loss: 0.003976692446 \n",
      "Epoch:  289 | loss: 0.003976691980 \n",
      "Epoch:  290 | loss: 0.003976691980 \n",
      "Epoch:  291 | loss: 0.003976691980 \n",
      "Epoch:  292 | loss: 0.003976691980 \n",
      "Epoch:  293 | loss: 0.003976691980 \n",
      "Epoch:  294 | loss: 0.003976691980 \n",
      "Epoch:  295 | loss: 0.003976692446 \n",
      "Epoch:  296 | loss: 0.003976691980 \n",
      "Epoch:  297 | loss: 0.003976691980 \n",
      "Epoch:  298 | loss: 0.003976691980 \n",
      "Epoch:  299 | loss: 0.003976692446 \n",
      "time=38.84209108352661\n",
      "best_train_loss=0.003976691979914904\n",
      "test_loss=0.004244055133312941\n",
      "best_epoch=0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# w/wo growing network\n",
    "# Tanh, Relu, Relu2 activation, last-layer act(other relu). Even: Should we use spline networks?\n",
    "# Hybrid: Adam + LBFGS\n",
    "# Possible overfitting: train & test gap\n",
    "# LBFGS usage\n",
    "\n",
    "#ws = [50,60,70,80,90,100,120,140,160,180,200,250,300,350,400]\n",
    "ws = [5,10,15,20,25,30,35,40,45,50]\n",
    "#ws = [14]\n",
    "#ws = [2,4]\n",
    "losses_w = []\n",
    "losses_w_test = []\n",
    "times = []\n",
    "\n",
    "a_s = [0.0]\n",
    "\n",
    "w_i = 0\n",
    "\n",
    "for w in ws:\n",
    "    \n",
    "    print(\"w={}\".format(w))\n",
    "    if w_i == 0:\n",
    "        t = T(w=w, a=0.0, M=1.0)\n",
    "    else:\n",
    "        sd = t.state_dict()\n",
    "        t_old = T(w=w_old, a=0.0, M=1.0)\n",
    "        t_old.load_state_dict(sd)\n",
    "        t = T(w=w, a=0.0, M=1.0)\n",
    "        t = grow(t_old, t, w_old, w)\n",
    "    w_i = w_i + 1\n",
    "\n",
    "\n",
    "    losses_a = []\n",
    "    losses_all = []\n",
    "    a_i = 0\n",
    "\n",
    "\n",
    "\n",
    "    for a_kerr in a_s:\n",
    "        M = 1.0\n",
    "        r_c = M + np.sqrt(M**2-a_kerr**2)\n",
    "        print(\"a_kerr={}\".format(a_kerr))\n",
    "        print(\"M={}\".format(M))\n",
    "        print(\"r_c={}\".format(r_c))\n",
    "        #t = T(w=400, a=a_kerr, M=M)\n",
    "        t.set_a(a_kerr)\n",
    "        a_i += 1\n",
    "\n",
    "\n",
    "        # Kerr Metric\n",
    "        def g(x_):\n",
    "            a = a_kerr\n",
    "            bs = x_.shape[0]\n",
    "            t = x_[:,0]\n",
    "            x = x_[:,1]\n",
    "            y = x_[:,2]\n",
    "            z = x_[:,3]\n",
    "            rho = torch.sqrt(x**2+y**2)\n",
    "            r = torch.sqrt(x**2+y**2+z**2)\n",
    "            costheta = z/r\n",
    "            sintheta = rho/r\n",
    "            sin2theta = 2*sintheta*costheta\n",
    "            cos2theta = 2*costheta**2 - 1\n",
    "            cosphi = x/rho\n",
    "            sinphi = y/rho\n",
    "            sigma = r**2 + a**2*costheta**2\n",
    "            zeta = torch.sqrt(r**2+a**2)\n",
    "            sq2 = torch.sqrt(torch.tensor(2., dtype=torch.float, requires_grad=False))\n",
    "\n",
    "            u1 = a**2 + 2*r**2 + a**2*cos2theta\n",
    "            zeta = torch.sqrt(a**2+r**2)\n",
    "            u2 = u1/(zeta*torch.sqrt(M*r))\n",
    "            u3 = 8*a*M/sigma\n",
    "            u4 = zeta**2 + 2*a**2*M*r*sintheta**2/sigma\n",
    "\n",
    "            g00 = -1 + 2*M*r/sigma\n",
    "            g01 = g10 = 1/4*sintheta*(sq2*u2*cosphi+u3*sinphi)\n",
    "            g02 = g20 = 1/4*sintheta*(-u3*cosphi+sq2*u2*sinphi)\n",
    "            g03 = g30 = costheta*u2/sq2**3\n",
    "            g11 = (8*costheta**2*cosphi**2*sigma-u2**2*r**2*cosphi**2*sintheta**2+8*u4*sinphi**2)/(8*r**2)\n",
    "            g12 = g21 = cosphi*(8*costheta**2*sigma-u2**2*r**2*sintheta**2-8*u4)*sinphi/(8*r**2)\n",
    "            g13 = g31 = costheta*(-8*sigma-u2**2*r**2)*cosphi*sintheta/(8*r**2)\n",
    "            g22 = (8*cosphi**2*u4+8*costheta**2*sigma*sinphi**2-u2**2*r**2*sintheta**2*sinphi**2)/(8*r**2)\n",
    "            g23 = g32 = costheta*(-8*sigma-u2**2*r**2)*sintheta*sinphi/(8*r**2)\n",
    "            g33 = sintheta**2 + costheta**2*(-u2**2*r**2+8*a**2*sintheta**2)/(8*r**2)\n",
    "\n",
    "            stack1 = torch.stack([g00, g01, g02, g03])\n",
    "            stack2 = torch.stack([g10, g11, g12, g13])\n",
    "            stack3 = torch.stack([g20, g21, g22, g23])\n",
    "            stack4 = torch.stack([g30, g31, g32, g33])\n",
    "\n",
    "            gs = - torch.stack([stack1, stack2, stack3, stack4]).permute(2,0,1)\n",
    "            return gs\n",
    "        \n",
    "        def euclidean_loss(t,inputs):\n",
    "            gp = t.transform_g(inputs)\n",
    "            bs = gp.shape[0]\n",
    "            minkowski_metric = torch.unsqueeze(torch.unsqueeze(torch.ones(bs,),dim=1),dim=2) * torch.unsqueeze(torch.diag(torch.tensor([-1.,-1.,-1.], dtype=torch.float, requires_grad=True)), dim=0)\n",
    "            return torch.mean((gp[:,1:,1:]-minkowski_metric)**2)\n",
    "\n",
    "\n",
    "\n",
    "        lr = 0.1\n",
    "        '''if w_i == 0:\n",
    "            epochs = 2500\n",
    "            BFGS_epoch = 2000\n",
    "        else:\n",
    "            epochs = 500\n",
    "            BFGS_epoch = 0'''\n",
    "        \n",
    "        # We need to understand LBFGS better\n",
    "        epochs = 300\n",
    "        switch_epoch = 100\n",
    "        BFGS_epoch = 1000000\n",
    "\n",
    "        #optimizer = optim.Adam(t.parameters(), lr=lr, eps=1e-8)\n",
    "        #optimizer = optim.SGD(t.parameters(),lr=lr)\n",
    "        optimizer = optim.LBFGS(t.parameters(), lr=lr, max_iter=100, max_eval=None, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn='strong_wolfe')\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=0.1, max_iter=100, max_eval=1e10, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100)\n",
    "\n",
    "\n",
    "\n",
    "        #epochs = 100\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=1, max_iter=100, max_eval=None, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn=\"strong_wolfe\")\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n",
    "\n",
    "        log_save = 100000\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        n_train = 1000\n",
    "        \n",
    "        best_loss = 10000\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            if (epoch+1) % switch_epoch == 0:\n",
    "                for opt_param in optimizer.param_groups:\n",
    "                    lr = lr * 0.5\n",
    "                    opt_param['lr'] = lr\n",
    "\n",
    "            if epoch == BFGS_epoch:\n",
    "                # BFGS learning rate. How to set?\n",
    "                optimizer = optim.LBFGS(t.parameters(), lr=0.1, max_iter=1e10, max_eval=1e10, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn='strong_wolfe')\n",
    "\n",
    "            if epoch < BFGS_epoch:\n",
    "                log = 1\n",
    "                batch_size = n_train\n",
    "            else:\n",
    "                log = 1\n",
    "                batch_size = n_train\n",
    "            t.train()\n",
    "\n",
    "\n",
    "            choices = np.random.choice(n_train, batch_size, replace=False)\n",
    "            inputs = input_[choices]\n",
    "\n",
    "            # -------------------------------------------\n",
    "            def loss_closure():\n",
    "                if torch.is_grad_enabled():\n",
    "                    optimizer.zero_grad()\n",
    "                loss_inner = euclidean_loss(t,inputs)\n",
    "                #if loss_inner.requires_grad:\n",
    "                    #loss_inner.backward(retain_graph=True)\n",
    "                    #loss_inner.backward()\n",
    "                loss_inner.backward(retain_graph=True)\n",
    "                return loss_inner\n",
    "            # -------------------------------------------\n",
    "            loss = loss_closure()\n",
    "            # best_loss is trick for better scaling laws\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_epoch = epoch\n",
    "                def loss_closure_test():\n",
    "                    if torch.is_grad_enabled():\n",
    "                        optimizer.zero_grad()\n",
    "                    loss_inner = euclidean_loss(t,input_test_)\n",
    "                    return loss_inner\n",
    "                loss_test = loss_closure_test()\n",
    "            optimizer.step(loss_closure)  # get loss, use to update wts\n",
    "\n",
    "            losses.append(loss.detach().numpy())\n",
    "            losses_all.append(loss.detach().numpy())\n",
    "            '''loss = euclidean_loss(g,t,inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()'''\n",
    "            \n",
    "\n",
    "            if epoch%log == 0:\n",
    "                print('Epoch:  %d | loss: %.12f ' %(epoch, loss))\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    print(\"time={}\".format(duration))\n",
    "    times.append(duration)\n",
    "\n",
    "\n",
    "                \n",
    "    w_old = w\n",
    "    losses_w.append(best_loss.detach().numpy())\n",
    "    losses_w_test.append(loss_test.detach().numpy())\n",
    "    print(\"best_train_loss={}\".format(best_loss.detach().numpy()))\n",
    "    print(\"test_loss={}\".format(loss_test.detach().numpy()))\n",
    "    print(\"best_epoch={}\".format(best_epoch))\n",
    "    \n",
    "np.save('./results_nn/grow_relu2last_bfgs_nolrdecay',np.array([ws, losses_w, times, losses_w_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.00000000e+00, 1.00000000e+01, 1.50000000e+01, 2.00000000e+01,\n",
       "        2.50000000e+01, 3.00000000e+01, 3.50000000e+01, 4.00000000e+01,\n",
       "        4.50000000e+01, 5.00000000e+01],\n",
       "       [2.72356886e-02, 2.72120032e-02, 2.71987878e-02, 2.71986239e-02,\n",
       "        2.71983277e-02, 2.71982979e-02, 5.09168813e-03, 3.97670129e-03,\n",
       "        3.97669477e-03, 3.97669198e-03],\n",
       "       [2.51594722e+01, 2.13177153e+02, 1.31376787e+02, 2.52303760e+01,\n",
       "        2.56082580e+01, 2.76582470e+01, 4.86841600e+01, 4.46619358e+01,\n",
       "        3.75990210e+01, 3.88420911e+01],\n",
       "       [2.61764061e-02, 2.61589494e-02, 2.61494778e-02, 2.61493586e-02,\n",
       "        2.61491332e-02, 2.61491071e-02, 5.19300997e-03, 4.24406584e-03,\n",
       "        4.24405839e-03, 4.24405513e-03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./results_nn/grow_relu2last_bfgs_nolrdecay.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next try: relu2 (not just last layer)\n",
    "\n",
    "plt.plot(ws, losses_w, marker=\"o\")\n",
    "#plt.plot(ws, losses_w_test, marker=\"o\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('NN width',fontsize=15)\n",
    "plt.ylabel('MSE',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "# Doubt: NN may have bad landscapes. BFGS may perform worse than Adam at high loss.\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Define Transformer\n",
    "\n",
    "\n",
    "# (t,rho,z) -> (t',rho',z')\n",
    "class T(nn.Module):\n",
    "    def __init__(self,w=256,a=0.,M=1.):\n",
    "        super(T, self).__init__()\n",
    "        self.l1 = nn.Linear(2,w)\n",
    "        self.l2 = nn.Linear(w,w)\n",
    "        self.l3 = nn.Linear(w,4)\n",
    "        self.a = a\n",
    "        self.M = torch.nn.Parameter(torch.ones(1,)*1., requires_grad=False)\n",
    "        self.eps = torch.nn.Parameter(torch.ones(1,)*0.01, requires_grad=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        # These non-polynomial activation function may not lead to power laws\n",
    "        #f = nn.Tanh()\n",
    "        #f = nn.SiLU()\n",
    "        #f = Rational()\n",
    "        f = nn.ReLU()\n",
    "        self.t = x[:,[0]]\n",
    "        self.x = x[:,[1]]\n",
    "        self.y = x[:,[2]]\n",
    "        self.z = x[:,[3]]\n",
    "        self.r = torch.sqrt(self.x**2+self.y**2+self.z**2)\n",
    "        self.u = torch.sqrt(self.r/(2*self.M))\n",
    "\n",
    "        self.rho = torch.unsqueeze(torch.sqrt(x[:,1]**2+x[:,2]**2),dim=1)\n",
    "        self.rhoz = torch.transpose(torch.stack([self.rho,self.z]),0,1)[:,:,0]\n",
    "        \n",
    "        self.x1 = f(self.l1(self.rhoz))\n",
    "        self.x2 = f(self.l2(self.x1))**2\n",
    "        self.x3 = self.l3(self.x2)\n",
    "\n",
    "        self.dt = self.x3[:,[0]]\n",
    "        self.drho = self.x3[:,[1]]\n",
    "        self.dphi = self.x3[:,[2]]\n",
    "        self.dz = self.x3[:,[3]]\n",
    "        nn_out = torch.empty((x.shape[0], 4), requires_grad=False)\n",
    "        nn_out[:,[0]] = self.dt\n",
    "        nn_out[:,[1]] = (-self.y*self.dphi+self.x*self.drho)\n",
    "        nn_out[:,[2]] = (self.x*self.dphi+self.y*self.drho)\n",
    "        nn_out[:,[3]] = self.dz*self.z\n",
    "\n",
    "        return x + self.eps.unsqueeze(dim=0)*nn_out\n",
    "    \n",
    "    def set_a(self,a):\n",
    "        self.a = a\n",
    "        \n",
    "    def batch_jacobian(self, func, x, create_graph=False):\n",
    "        # x in shape (Batch, Length)\n",
    "        def _func_sum(x):\n",
    "            return func(x).sum(dim=0)\n",
    "        return torch.autograd.functional.jacobian(_func_sum, x, create_graph=create_graph).permute(1,0,2)\n",
    "    \n",
    "    def transform_g(self, x):\n",
    "        jac_ts = self.batch_jacobian(self.forward, x, create_graph=True)\n",
    "        jac_inv_ts = torch.inverse(jac_ts)\n",
    "        return torch.matmul(torch.matmul(jac_inv_ts.permute(0,2,1), g(x)),jac_inv_ts)\n",
    "        \n",
    "    def jac(self, x):\n",
    "        jac_ts = self.batch_jacobian(self.forward, x, create_graph=True)\n",
    "        return jac_ts\n",
    "    \n",
    "\n",
    "def grow(t1, t2, w_s, w_l):\n",
    "\n",
    "    w_mask = torch.zeros(w_l,w_l)\n",
    "    w_mask[:w_s,:w_s] = torch.ones(w_s,w_s)\n",
    "\n",
    "    b_mask = torch.zeros(w_l,)\n",
    "    b_mask[:w_s] = torch.ones(w_s,)\n",
    "\n",
    "    t2.l2.weight.data = t2.l2.weight.data*w_mask\n",
    "    t2.l2.weight.data[:w_s,:w_s] = t1.l2.weight.data\n",
    "    t2.l2.bias.data = t2.l2.bias.data*b_mask\n",
    "    t2.l2.bias.data[:w_s] = t1.l2.bias.data\n",
    "\n",
    "    t2.l1.weight.data[:w_s,:] = t1.l1.weight.data\n",
    "    t2.l1.bias.data[:w_s] = t1.l1.bias.data\n",
    "\n",
    "    t2.l3.weight.data[:,:w_s] = t1.l3.weight.data\n",
    "    t2.l3.bias.data = t1.l3.bias.data\n",
    "    return t2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "n_train = 1000\n",
    "\n",
    "W = torch.normal(0,1,size=(n_train,4),requires_grad=True)\n",
    "input_ = torch.empty(n_train,4, requires_grad=False)\n",
    "input_[:,0] = (torch.rand(n_train, requires_grad=True)-0.5)*3.0 + 1.5\n",
    "rs = torch.linspace(3,4,steps=n_train+1)[:n_train]\n",
    "input_[:,1:] = W[:,1:]/torch.norm(W[:,1:], dim=1, keepdim=True)*torch.unsqueeze(rs, dim=1)\n",
    "\n",
    "n_test = 1000\n",
    "\n",
    "W_test = torch.normal(0,1,size=(n_test,4),requires_grad=True)\n",
    "input_test_ = torch.empty(n_test,4, requires_grad=False)\n",
    "input_test_[:,0] = (torch.rand(n_test, requires_grad=True)-0.5)*3.0 + 1.5\n",
    "rs_test = torch.linspace(3,4,steps=n_test+1)[:n_test]\n",
    "input_test_[:,1:] = W_test[:,1:]/torch.norm(W_test[:,1:], dim=1, keepdim=True)*torch.unsqueeze(rs_test, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=5\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.840038895607 \n",
      "Epoch:  100 | loss: 0.220892041922 \n",
      "Epoch:  200 | loss: 0.011808759533 \n",
      "Epoch:  300 | loss: 0.007408276200 \n",
      "Epoch:  400 | loss: 0.005450650118 \n",
      "Epoch:  500 | loss: 0.004063544329 \n",
      "Epoch:  600 | loss: 0.003507145448 \n",
      "Epoch:  700 | loss: 0.003068746533 \n",
      "Epoch:  800 | loss: 0.002919696271 \n",
      "Epoch:  900 | loss: 0.002911941381 \n",
      "Epoch:  1000 | loss: 0.002808196237 \n",
      "Epoch:  1100 | loss: 0.002858462976 \n",
      "Epoch:  1200 | loss: 0.002822192619 \n",
      "Epoch:  1300 | loss: 0.003009750741 \n",
      "Epoch:  1400 | loss: 0.003038014984 \n",
      "Epoch:  1500 | loss: 0.003112118924 \n",
      "Epoch:  1600 | loss: 0.003081937321 \n",
      "Epoch:  1700 | loss: 0.003082874231 \n",
      "Epoch:  1800 | loss: 0.003016611096 \n",
      "Epoch:  1900 | loss: 0.002996519208 \n",
      "Epoch:  2000 | loss: 0.002950438531 \n",
      "Epoch:  2100 | loss: 0.003023384605 \n",
      "Epoch:  2200 | loss: 0.003028366482 \n",
      "Epoch:  2300 | loss: 0.003080296330 \n",
      "Epoch:  2400 | loss: 0.003162111389 \n",
      "Epoch:  2500 | loss: 0.003244433319 \n",
      "Epoch:  2600 | loss: 0.003256468801 \n",
      "Epoch:  2700 | loss: 0.003248866647 \n",
      "Epoch:  2800 | loss: 0.003270122223 \n",
      "Epoch:  2900 | loss: 0.003270407673 \n",
      "Epoch:  3000 | loss: 0.003317234339 \n",
      "Epoch:  3100 | loss: 0.003302074503 \n",
      "Epoch:  3200 | loss: 0.003293103538 \n",
      "Epoch:  3300 | loss: 0.003302888479 \n",
      "Epoch:  3400 | loss: 0.003324134508 \n",
      "Epoch:  3500 | loss: 0.003280750709 \n",
      "Epoch:  3600 | loss: 0.003163587069 \n",
      "Epoch:  3700 | loss: 0.003154928330 \n",
      "Epoch:  3800 | loss: 0.003184399800 \n",
      "Epoch:  3900 | loss: 0.003204510314 \n",
      "Epoch:  4000 | loss: 0.003216548124 \n",
      "Epoch:  4100 | loss: 0.003168006428 \n",
      "Epoch:  4200 | loss: 0.002998640295 \n",
      "Epoch:  4300 | loss: 0.002141318051 \n",
      "Epoch:  4400 | loss: 0.000702480029 \n",
      "Epoch:  4500 | loss: 0.000343836116 \n",
      "Epoch:  4600 | loss: 0.000244916184 \n",
      "Epoch:  4700 | loss: 0.000243314789 \n",
      "Epoch:  4800 | loss: 0.000243114890 \n",
      "Epoch:  4900 | loss: 0.000243734976 \n",
      "Epoch:  5000 | loss: 0.000247419666 \n",
      "Epoch:  5100 | loss: 0.000260179717 \n",
      "Epoch:  5200 | loss: 0.000271787925 \n",
      "Epoch:  5300 | loss: 0.000276777777 \n",
      "Epoch:  5400 | loss: 0.000280741166 \n",
      "Epoch:  5500 | loss: 0.000283645844 \n",
      "Epoch:  5600 | loss: 0.000285059679 \n",
      "Epoch:  5700 | loss: 0.000282261230 \n",
      "Epoch:  5800 | loss: 0.000281683548 \n",
      "Epoch:  5900 | loss: 0.000281171146 \n",
      "Epoch:  6000 | loss: 0.000284225825 \n",
      "Epoch:  6100 | loss: 0.000289444200 \n",
      "Epoch:  6200 | loss: 0.000289160875 \n",
      "Epoch:  6300 | loss: 0.000288922893 \n",
      "Epoch:  6400 | loss: 0.000290837401 \n",
      "Epoch:  6500 | loss: 0.000290595635 \n",
      "Epoch:  6600 | loss: 0.000294117897 \n",
      "Epoch:  6700 | loss: 0.000297057471 \n",
      "Epoch:  6800 | loss: 0.000296798768 \n",
      "Epoch:  6900 | loss: 0.000296539685 \n",
      "Epoch:  7000 | loss: 0.000302848464 \n",
      "Epoch:  7100 | loss: 0.000319362531 \n",
      "Epoch:  7200 | loss: 0.000319156679 \n",
      "Epoch:  7300 | loss: 0.000324441324 \n",
      "Epoch:  7400 | loss: 0.000334379554 \n",
      "Epoch:  7500 | loss: 0.000348931324 \n",
      "Epoch:  7600 | loss: 0.000357877318 \n",
      "Epoch:  7700 | loss: 0.000376778946 \n",
      "Epoch:  7800 | loss: 0.000387026521 \n",
      "Epoch:  7900 | loss: 0.000386335625 \n",
      "Epoch:  8000 | loss: 0.000397827796 \n",
      "Epoch:  8100 | loss: 0.000423135643 \n",
      "Epoch:  8200 | loss: 0.000360743637 \n",
      "Epoch:  8300 | loss: 0.000354594231 \n",
      "Epoch:  8400 | loss: 0.000370457012 \n",
      "Epoch:  8500 | loss: 0.000371326489 \n",
      "Epoch:  8600 | loss: 0.000385673047 \n",
      "Epoch:  8700 | loss: 0.000400037592 \n",
      "Epoch:  8800 | loss: 0.000408602325 \n",
      "Epoch:  8900 | loss: 0.000432242872 \n",
      "Epoch:  9000 | loss: 0.000487152836 \n",
      "Epoch:  9100 | loss: 0.000486775360 \n",
      "Epoch:  9200 | loss: 0.000480715069 \n",
      "Epoch:  9300 | loss: 0.000479188166 \n",
      "Epoch:  9400 | loss: 0.000479576382 \n",
      "Epoch:  9500 | loss: 0.000479150302 \n",
      "Epoch:  9600 | loss: 0.000461401360 \n",
      "Epoch:  9700 | loss: 0.000471783744 \n",
      "Epoch:  9800 | loss: 0.000471468607 \n",
      "Epoch:  9900 | loss: 0.000469029066 \n",
      "Epoch:  10000 | loss: 0.000443607394 \n",
      "Epoch:  10100 | loss: 0.000445477694 \n",
      "Epoch:  10200 | loss: 0.000445067446 \n",
      "Epoch:  10300 | loss: 0.000441080861 \n",
      "Epoch:  10400 | loss: 0.000431674416 \n",
      "Epoch:  10500 | loss: 0.000413705391 \n",
      "Epoch:  10600 | loss: 0.000405638391 \n",
      "Epoch:  10700 | loss: 0.000402626145 \n",
      "Epoch:  10800 | loss: 0.000397738913 \n",
      "Epoch:  10900 | loss: 0.000391455978 \n",
      "Epoch:  11000 | loss: 0.000385002670 \n",
      "Epoch:  11100 | loss: 0.000368374982 \n",
      "Epoch:  11200 | loss: 0.000357148383 \n",
      "Epoch:  11300 | loss: 0.000341744104 \n",
      "Epoch:  11400 | loss: 0.000326874200 \n",
      "Epoch:  11500 | loss: 0.000287301489 \n",
      "Epoch:  11600 | loss: 0.000258921471 \n",
      "Epoch:  11700 | loss: 0.000242214446 \n",
      "Epoch:  11800 | loss: 0.000223327370 \n",
      "Epoch:  11900 | loss: 0.000220966584 \n",
      "Epoch:  12000 | loss: 0.000198358262 \n",
      "Epoch:  12100 | loss: 0.000185134777 \n",
      "Epoch:  12200 | loss: 0.000171289998 \n",
      "Epoch:  12300 | loss: 0.000149321379 \n",
      "Epoch:  12400 | loss: 0.000141857628 \n",
      "Epoch:  12500 | loss: 0.000133757771 \n",
      "Epoch:  12600 | loss: 0.000130498927 \n",
      "Epoch:  12700 | loss: 0.000122277459 \n",
      "Epoch:  12800 | loss: 0.000115462542 \n",
      "Epoch:  12900 | loss: 0.000108522981 \n",
      "Epoch:  13000 | loss: 0.000107009728 \n",
      "Epoch:  13100 | loss: 0.000102670943 \n",
      "Epoch:  13200 | loss: 0.000098648074 \n",
      "Epoch:  13300 | loss: 0.000094015733 \n",
      "Epoch:  13400 | loss: 0.000092670874 \n",
      "Epoch:  13500 | loss: 0.000092276860 \n",
      "Epoch:  13600 | loss: 0.000091873779 \n",
      "Epoch:  13700 | loss: 0.000091212481 \n",
      "Epoch:  13800 | loss: 0.000090900299 \n",
      "Epoch:  13900 | loss: 0.000089841196 \n",
      "Epoch:  14000 | loss: 0.000088239140 \n",
      "Epoch:  14100 | loss: 0.000087841421 \n",
      "Epoch:  14200 | loss: 0.000087581451 \n",
      "Epoch:  14300 | loss: 0.000087431712 \n",
      "Epoch:  14400 | loss: 0.000087378627 \n",
      "Epoch:  14500 | loss: 0.000087200191 \n",
      "Epoch:  14600 | loss: 0.000086900116 \n",
      "Epoch:  14700 | loss: 0.000086713379 \n",
      "Epoch:  14800 | loss: 0.000086207074 \n",
      "Epoch:  14900 | loss: 0.000086083113 \n",
      "time=295.47178292274475\n",
      "best_train_loss=8.59807405504398e-05\n",
      "test_loss=9.117241279454902e-05\n",
      "best_epoch=14999\n",
      "w=10\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000085980006 \n",
      "Epoch:  100 | loss: 0.000081382721 \n",
      "Epoch:  200 | loss: 0.000079740574 \n",
      "Epoch:  300 | loss: 0.000076622135 \n",
      "Epoch:  400 | loss: 0.000063954089 \n",
      "Epoch:  500 | loss: 0.000063471045 \n",
      "Epoch:  600 | loss: 0.000061380299 \n",
      "Epoch:  700 | loss: 0.000054041619 \n",
      "Epoch:  800 | loss: 0.000050576455 \n",
      "Epoch:  900 | loss: 0.000061846767 \n",
      "Epoch:  1000 | loss: 0.000060792114 \n",
      "Epoch:  1100 | loss: 0.000060719569 \n",
      "Epoch:  1200 | loss: 0.000058533034 \n",
      "Epoch:  1300 | loss: 0.000057678215 \n",
      "Epoch:  1400 | loss: 0.000057516772 \n",
      "Epoch:  1500 | loss: 0.000061141494 \n",
      "Epoch:  1600 | loss: 0.000062923064 \n",
      "Epoch:  1700 | loss: 0.000064758133 \n",
      "Epoch:  1800 | loss: 0.000070602990 \n",
      "Epoch:  1900 | loss: 0.000069515874 \n",
      "Epoch:  2000 | loss: 0.000068951311 \n",
      "Epoch:  2100 | loss: 0.000085021908 \n",
      "Epoch:  2200 | loss: 0.000088502245 \n",
      "Epoch:  2300 | loss: 0.000092006165 \n",
      "Epoch:  2400 | loss: 0.000098184893 \n",
      "Epoch:  2500 | loss: 0.000098749260 \n",
      "Epoch:  2600 | loss: 0.000102378501 \n",
      "Epoch:  2700 | loss: 0.000112289876 \n",
      "Epoch:  2800 | loss: 0.000174415152 \n",
      "Epoch:  2900 | loss: 0.000171298292 \n",
      "Epoch:  3000 | loss: 0.000200497976 \n",
      "Epoch:  3100 | loss: 0.000204495780 \n",
      "Epoch:  3200 | loss: 0.000200376278 \n",
      "Epoch:  3300 | loss: 0.000182704622 \n",
      "Epoch:  3400 | loss: 0.000903119915 \n",
      "Epoch:  3500 | loss: 0.000831792539 \n",
      "Epoch:  3600 | loss: 0.000182930264 \n",
      "Epoch:  3700 | loss: 0.000092675378 \n",
      "Epoch:  3800 | loss: 0.000077383876 \n",
      "Epoch:  3900 | loss: 0.000070214868 \n",
      "Epoch:  4000 | loss: 0.000065362285 \n",
      "Epoch:  4100 | loss: 0.000059086324 \n",
      "Epoch:  4200 | loss: 0.000054158940 \n",
      "Epoch:  4300 | loss: 0.000051239767 \n",
      "Epoch:  4400 | loss: 0.000046961479 \n",
      "Epoch:  4500 | loss: 0.000043645556 \n",
      "Epoch:  4600 | loss: 0.000040800005 \n",
      "Epoch:  4700 | loss: 0.000038377595 \n",
      "Epoch:  4800 | loss: 0.000036334477 \n",
      "Epoch:  4900 | loss: 0.000034708250 \n",
      "Epoch:  5000 | loss: 0.000032670629 \n",
      "Epoch:  5100 | loss: 0.000031209162 \n",
      "Epoch:  5200 | loss: 0.000029944804 \n",
      "Epoch:  5300 | loss: 0.000028877337 \n",
      "Epoch:  5400 | loss: 0.000027727046 \n",
      "Epoch:  5500 | loss: 0.000026729416 \n",
      "Epoch:  5600 | loss: 0.000025766736 \n",
      "Epoch:  5700 | loss: 0.000024924910 \n",
      "Epoch:  5800 | loss: 0.000024258181 \n",
      "Epoch:  5900 | loss: 0.000023611483 \n",
      "Epoch:  6000 | loss: 0.000023094686 \n",
      "Epoch:  6100 | loss: 0.000022845259 \n",
      "Epoch:  6200 | loss: 0.000022591505 \n",
      "Epoch:  6300 | loss: 0.000022348930 \n",
      "Epoch:  6400 | loss: 0.000022090087 \n",
      "Epoch:  6500 | loss: 0.000021819282 \n",
      "Epoch:  6600 | loss: 0.000021585091 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6700 | loss: 0.000021385300 \n",
      "Epoch:  6800 | loss: 0.000021152799 \n",
      "Epoch:  6900 | loss: 0.000020927055 \n",
      "Epoch:  7000 | loss: 0.000020698908 \n",
      "Epoch:  7100 | loss: 0.000020461450 \n",
      "Epoch:  7200 | loss: 0.000020233094 \n",
      "Epoch:  7300 | loss: 0.000020008749 \n",
      "Epoch:  7400 | loss: 0.000019830914 \n",
      "Epoch:  7500 | loss: 0.000019549005 \n",
      "Epoch:  7600 | loss: 0.000019270170 \n",
      "Epoch:  7700 | loss: 0.000019035930 \n",
      "Epoch:  7800 | loss: 0.000018776202 \n",
      "Epoch:  7900 | loss: 0.000018495672 \n",
      "Epoch:  8000 | loss: 0.000018184659 \n",
      "Epoch:  8100 | loss: 0.000017832377 \n",
      "Epoch:  8200 | loss: 0.000017737992 \n",
      "Epoch:  8300 | loss: 0.000017596434 \n",
      "Epoch:  8400 | loss: 0.000017386295 \n",
      "Epoch:  8500 | loss: 0.000017261829 \n",
      "Epoch:  8600 | loss: 0.000017023405 \n",
      "Epoch:  8700 | loss: 0.000016916931 \n",
      "Epoch:  8800 | loss: 0.000016618293 \n",
      "Epoch:  8900 | loss: 0.000016449661 \n",
      "Epoch:  9000 | loss: 0.000016266811 \n",
      "Epoch:  9100 | loss: 0.000016167905 \n",
      "Epoch:  9200 | loss: 0.000016153132 \n",
      "Epoch:  9300 | loss: 0.000016069549 \n",
      "Epoch:  9400 | loss: 0.000015969228 \n",
      "Epoch:  9500 | loss: 0.000015893494 \n",
      "Epoch:  9600 | loss: 0.000015856045 \n",
      "Epoch:  9700 | loss: 0.000015766092 \n",
      "Epoch:  9800 | loss: 0.000015652184 \n",
      "Epoch:  9900 | loss: 0.000015597152 \n",
      "Epoch:  10000 | loss: 0.000015477170 \n",
      "Epoch:  10100 | loss: 0.000015324649 \n",
      "Epoch:  10200 | loss: 0.000015199459 \n",
      "Epoch:  10300 | loss: 0.000015172762 \n",
      "Epoch:  10400 | loss: 0.000015090483 \n",
      "Epoch:  10500 | loss: 0.000014954080 \n",
      "Epoch:  10600 | loss: 0.000014817258 \n",
      "Epoch:  10700 | loss: 0.000014687310 \n",
      "Epoch:  10800 | loss: 0.000014554375 \n",
      "Epoch:  10900 | loss: 0.000014443604 \n",
      "Epoch:  11000 | loss: 0.000014322206 \n",
      "Epoch:  11100 | loss: 0.000014198884 \n",
      "Epoch:  11200 | loss: 0.000014096944 \n",
      "Epoch:  11300 | loss: 0.000013997718 \n",
      "Epoch:  11400 | loss: 0.000013878416 \n",
      "Epoch:  11500 | loss: 0.000013798830 \n",
      "Epoch:  11600 | loss: 0.000013833532 \n",
      "Epoch:  11700 | loss: 0.000013720378 \n",
      "Epoch:  11800 | loss: 0.000013620860 \n",
      "Epoch:  11900 | loss: 0.000013527359 \n",
      "Epoch:  12000 | loss: 0.000013437103 \n",
      "Epoch:  12100 | loss: 0.000013390952 \n",
      "Epoch:  12200 | loss: 0.000013345766 \n",
      "Epoch:  12300 | loss: 0.000013299621 \n",
      "Epoch:  12400 | loss: 0.000013252393 \n",
      "Epoch:  12500 | loss: 0.000013204080 \n",
      "Epoch:  12600 | loss: 0.000013154788 \n",
      "Epoch:  12700 | loss: 0.000013100312 \n",
      "Epoch:  12800 | loss: 0.000013048836 \n",
      "Epoch:  12900 | loss: 0.000012997238 \n",
      "Epoch:  13000 | loss: 0.000012945612 \n",
      "Epoch:  13100 | loss: 0.000012894203 \n",
      "Epoch:  13200 | loss: 0.000012843275 \n",
      "Epoch:  13300 | loss: 0.000012783124 \n",
      "Epoch:  13400 | loss: 0.000012720224 \n",
      "Epoch:  13500 | loss: 0.000012669881 \n",
      "Epoch:  13600 | loss: 0.000012623060 \n",
      "Epoch:  13700 | loss: 0.000012582724 \n",
      "Epoch:  13800 | loss: 0.000012546558 \n",
      "Epoch:  13900 | loss: 0.000012513958 \n",
      "Epoch:  14000 | loss: 0.000012506940 \n",
      "Epoch:  14100 | loss: 0.000012475864 \n",
      "Epoch:  14200 | loss: 0.000012450622 \n",
      "Epoch:  14300 | loss: 0.000012428299 \n",
      "Epoch:  14400 | loss: 0.000012406583 \n",
      "Epoch:  14500 | loss: 0.000012386527 \n",
      "Epoch:  14600 | loss: 0.000012391419 \n",
      "Epoch:  14700 | loss: 0.000012372650 \n",
      "Epoch:  14800 | loss: 0.000012356621 \n",
      "Epoch:  14900 | loss: 0.000012338292 \n",
      "time=347.504851102829\n",
      "best_train_loss=1.2324113413342275e-05\n",
      "test_loss=1.434642581443768e-05\n",
      "best_epoch=14988\n",
      "w=15\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000012321785 \n",
      "Epoch:  100 | loss: 0.000012150903 \n",
      "Epoch:  200 | loss: 0.000012052205 \n",
      "Epoch:  300 | loss: 0.000011907986 \n",
      "Epoch:  400 | loss: 0.000011630889 \n",
      "Epoch:  500 | loss: 0.000011140808 \n",
      "Epoch:  600 | loss: 0.000010668453 \n",
      "Epoch:  700 | loss: 0.000010387324 \n",
      "Epoch:  800 | loss: 0.000009930245 \n",
      "Epoch:  900 | loss: 0.000010782816 \n",
      "Epoch:  1000 | loss: 0.000010318834 \n",
      "Epoch:  1100 | loss: 0.000010411925 \n",
      "Epoch:  1200 | loss: 0.000009971996 \n",
      "Epoch:  1300 | loss: 0.000009739617 \n",
      "Epoch:  1400 | loss: 0.000009383133 \n",
      "Epoch:  1500 | loss: 0.000008982930 \n",
      "Epoch:  1600 | loss: 0.000008219050 \n",
      "Epoch:  1700 | loss: 0.000008411664 \n",
      "Epoch:  1800 | loss: 0.000007618213 \n",
      "Epoch:  1900 | loss: 0.000007216554 \n",
      "Epoch:  2000 | loss: 0.000007104469 \n",
      "Epoch:  2100 | loss: 0.000007025033 \n",
      "Epoch:  2200 | loss: 0.000007714166 \n",
      "Epoch:  2300 | loss: 0.000007709188 \n",
      "Epoch:  2400 | loss: 0.000007499259 \n",
      "Epoch:  2500 | loss: 0.000007307257 \n",
      "Epoch:  2600 | loss: 0.000007049305 \n",
      "Epoch:  2700 | loss: 0.000006874765 \n",
      "Epoch:  2800 | loss: 0.000006664643 \n",
      "Epoch:  2900 | loss: 0.000006821866 \n",
      "Epoch:  3000 | loss: 0.000006415305 \n",
      "Epoch:  3100 | loss: 0.000006319595 \n",
      "Epoch:  3200 | loss: 0.000006283772 \n",
      "Epoch:  3300 | loss: 0.000006257393 \n",
      "Epoch:  3400 | loss: 0.000006222509 \n",
      "Epoch:  3500 | loss: 0.000006197550 \n",
      "Epoch:  3600 | loss: 0.000006198765 \n",
      "Epoch:  3700 | loss: 0.000006159622 \n",
      "Epoch:  3800 | loss: 0.000006104799 \n",
      "Epoch:  3900 | loss: 0.000006075108 \n",
      "Epoch:  4000 | loss: 0.000006017236 \n",
      "Epoch:  4100 | loss: 0.000005973785 \n",
      "Epoch:  4200 | loss: 0.000005941421 \n",
      "Epoch:  4300 | loss: 0.000005894847 \n",
      "Epoch:  4400 | loss: 0.000005853397 \n",
      "Epoch:  4500 | loss: 0.000005867767 \n",
      "Epoch:  4600 | loss: 0.000005960391 \n",
      "Epoch:  4700 | loss: 0.000005804991 \n",
      "Epoch:  4800 | loss: 0.000005769041 \n",
      "Epoch:  4900 | loss: 0.000005762703 \n",
      "Epoch:  5000 | loss: 0.000005724614 \n",
      "Epoch:  5100 | loss: 0.000005691058 \n",
      "Epoch:  5200 | loss: 0.000005707092 \n",
      "Epoch:  5300 | loss: 0.000005616724 \n",
      "Epoch:  5400 | loss: 0.000005612323 \n",
      "Epoch:  5500 | loss: 0.000005592990 \n",
      "Epoch:  5600 | loss: 0.000005566739 \n",
      "Epoch:  5700 | loss: 0.000005557245 \n",
      "Epoch:  5800 | loss: 0.000005532972 \n",
      "Epoch:  5900 | loss: 0.000005499885 \n",
      "Epoch:  6000 | loss: 0.000005466673 \n",
      "Epoch:  6100 | loss: 0.000005455912 \n",
      "Epoch:  6200 | loss: 0.000005467349 \n",
      "Epoch:  6300 | loss: 0.000005427213 \n",
      "Epoch:  6400 | loss: 0.000005414479 \n",
      "Epoch:  6500 | loss: 0.000005402251 \n",
      "Epoch:  6600 | loss: 0.000005411171 \n",
      "Epoch:  6700 | loss: 0.000005398388 \n",
      "Epoch:  6800 | loss: 0.000005384159 \n",
      "Epoch:  6900 | loss: 0.000005352476 \n",
      "Epoch:  7000 | loss: 0.000005339019 \n",
      "Epoch:  7100 | loss: 0.000005356670 \n",
      "Epoch:  7200 | loss: 0.000005337931 \n",
      "Epoch:  7300 | loss: 0.000005324964 \n",
      "Epoch:  7400 | loss: 0.000005308043 \n",
      "Epoch:  7500 | loss: 0.000005297220 \n",
      "Epoch:  7600 | loss: 0.000005279467 \n",
      "Epoch:  7700 | loss: 0.000005269669 \n",
      "Epoch:  7800 | loss: 0.000005301237 \n",
      "Epoch:  7900 | loss: 0.000005290112 \n",
      "Epoch:  8000 | loss: 0.000005374206 \n",
      "Epoch:  8100 | loss: 0.000005247705 \n",
      "Epoch:  8200 | loss: 0.000005218941 \n",
      "Epoch:  8300 | loss: 0.000005202533 \n",
      "Epoch:  8400 | loss: 0.000005148604 \n",
      "Epoch:  8500 | loss: 0.000005140795 \n",
      "Epoch:  8600 | loss: 0.000005128248 \n",
      "Epoch:  8700 | loss: 0.000005117689 \n",
      "Epoch:  8800 | loss: 0.000005100342 \n",
      "Epoch:  8900 | loss: 0.000005086084 \n",
      "Epoch:  9000 | loss: 0.000005074869 \n",
      "Epoch:  9100 | loss: 0.000005069191 \n",
      "Epoch:  9200 | loss: 0.000005059200 \n",
      "Epoch:  9300 | loss: 0.000005053160 \n",
      "Epoch:  9400 | loss: 0.000005046777 \n",
      "Epoch:  9500 | loss: 0.000005039131 \n",
      "Epoch:  9600 | loss: 0.000005034337 \n",
      "Epoch:  9700 | loss: 0.000005028857 \n",
      "Epoch:  9800 | loss: 0.000005020465 \n",
      "Epoch:  9900 | loss: 0.000005013264 \n",
      "Epoch:  10000 | loss: 0.000005015396 \n",
      "Epoch:  10100 | loss: 0.000005006343 \n",
      "Epoch:  10200 | loss: 0.000004997234 \n",
      "Epoch:  10300 | loss: 0.000005007334 \n",
      "Epoch:  10400 | loss: 0.000004986749 \n",
      "Epoch:  10500 | loss: 0.000004977209 \n",
      "Epoch:  10600 | loss: 0.000004967527 \n",
      "Epoch:  10700 | loss: 0.000004970475 \n",
      "Epoch:  10800 | loss: 0.000004961227 \n",
      "Epoch:  10900 | loss: 0.000004961775 \n",
      "Epoch:  11000 | loss: 0.000004941485 \n",
      "Epoch:  11100 | loss: 0.000004932389 \n",
      "Epoch:  11200 | loss: 0.000004923094 \n",
      "Epoch:  11300 | loss: 0.000004910751 \n",
      "Epoch:  11400 | loss: 0.000004900277 \n",
      "Epoch:  11500 | loss: 0.000004890981 \n",
      "Epoch:  11600 | loss: 0.000004903070 \n",
      "Epoch:  11700 | loss: 0.000004893305 \n",
      "Epoch:  11800 | loss: 0.000004871796 \n",
      "Epoch:  11900 | loss: 0.000004865189 \n",
      "Epoch:  12000 | loss: 0.000004857328 \n",
      "Epoch:  12100 | loss: 0.000004853359 \n",
      "Epoch:  12200 | loss: 0.000004857010 \n",
      "Epoch:  12300 | loss: 0.000004855604 \n",
      "Epoch:  12400 | loss: 0.000004849565 \n",
      "Epoch:  12500 | loss: 0.000004843419 \n",
      "Epoch:  12600 | loss: 0.000004837848 \n",
      "Epoch:  12700 | loss: 0.000004833027 \n",
      "Epoch:  12800 | loss: 0.000004825521 \n",
      "Epoch:  12900 | loss: 0.000004841445 \n",
      "Epoch:  13000 | loss: 0.000004837864 \n",
      "Epoch:  13100 | loss: 0.000004827688 \n",
      "Epoch:  13200 | loss: 0.000004823025 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13300 | loss: 0.000004814908 \n",
      "Epoch:  13400 | loss: 0.000004802288 \n",
      "Epoch:  13500 | loss: 0.000004810734 \n",
      "Epoch:  13600 | loss: 0.000004804950 \n",
      "Epoch:  13700 | loss: 0.000004789918 \n",
      "Epoch:  13800 | loss: 0.000004784312 \n",
      "Epoch:  13900 | loss: 0.000004785756 \n",
      "Epoch:  14000 | loss: 0.000004758072 \n",
      "Epoch:  14100 | loss: 0.000004745974 \n",
      "Epoch:  14200 | loss: 0.000004744781 \n",
      "Epoch:  14300 | loss: 0.000004738508 \n",
      "Epoch:  14400 | loss: 0.000004732447 \n",
      "Epoch:  14500 | loss: 0.000004728794 \n",
      "Epoch:  14600 | loss: 0.000004723400 \n",
      "Epoch:  14700 | loss: 0.000004721242 \n",
      "Epoch:  14800 | loss: 0.000004714394 \n",
      "Epoch:  14900 | loss: 0.000004712446 \n",
      "time=353.53910303115845\n",
      "best_train_loss=4.693003575084731e-06\n",
      "test_loss=6.634071723965462e-06\n",
      "best_epoch=14999\n",
      "w=20\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000004692957 \n",
      "Epoch:  100 | loss: 0.000004547941 \n",
      "Epoch:  200 | loss: 0.000004439959 \n",
      "Epoch:  300 | loss: 0.000004259837 \n",
      "Epoch:  400 | loss: 0.000004058591 \n",
      "Epoch:  500 | loss: 0.000003907874 \n",
      "Epoch:  600 | loss: 0.000003834037 \n",
      "Epoch:  700 | loss: 0.000003631272 \n",
      "Epoch:  800 | loss: 0.000003519322 \n",
      "Epoch:  900 | loss: 0.000003445351 \n",
      "Epoch:  1000 | loss: 0.000003366659 \n",
      "Epoch:  1100 | loss: 0.000003268752 \n",
      "Epoch:  1200 | loss: 0.000003211999 \n",
      "Epoch:  1300 | loss: 0.000003199278 \n",
      "Epoch:  1400 | loss: 0.000003132441 \n",
      "Epoch:  1500 | loss: 0.000003076563 \n",
      "Epoch:  1600 | loss: 0.000003062550 \n",
      "Epoch:  1700 | loss: 0.000002987046 \n",
      "Epoch:  1800 | loss: 0.000002957918 \n",
      "Epoch:  1900 | loss: 0.000002938114 \n",
      "Epoch:  2000 | loss: 0.000002886628 \n",
      "Epoch:  2100 | loss: 0.000002858775 \n",
      "Epoch:  2200 | loss: 0.000002926420 \n",
      "Epoch:  2300 | loss: 0.000002806725 \n",
      "Epoch:  2400 | loss: 0.000002788187 \n",
      "Epoch:  2500 | loss: 0.000003140034 \n",
      "Epoch:  2600 | loss: 0.000002736349 \n",
      "Epoch:  2700 | loss: 0.000002730284 \n",
      "Epoch:  2800 | loss: 0.000002703097 \n",
      "Epoch:  2900 | loss: 0.000002686352 \n",
      "Epoch:  3000 | loss: 0.000002670145 \n",
      "Epoch:  3100 | loss: 0.000002667943 \n",
      "Epoch:  3200 | loss: 0.000002659065 \n",
      "Epoch:  3300 | loss: 0.000002648253 \n",
      "Epoch:  3400 | loss: 0.000002642260 \n",
      "Epoch:  3500 | loss: 0.000002633039 \n",
      "Epoch:  3600 | loss: 0.000002627172 \n",
      "Epoch:  3700 | loss: 0.000002618342 \n",
      "Epoch:  3800 | loss: 0.000002613237 \n",
      "Epoch:  3900 | loss: 0.000002595758 \n",
      "Epoch:  4000 | loss: 0.000002589577 \n",
      "Epoch:  4100 | loss: 0.000002580094 \n",
      "Epoch:  4200 | loss: 0.000002572642 \n",
      "Epoch:  4300 | loss: 0.000002560608 \n",
      "Epoch:  4400 | loss: 0.000002550134 \n",
      "Epoch:  4500 | loss: 0.000002540619 \n",
      "Epoch:  4600 | loss: 0.000002549303 \n",
      "Epoch:  4700 | loss: 0.000002520489 \n",
      "Epoch:  4800 | loss: 0.000002513399 \n",
      "Epoch:  4900 | loss: 0.000002501845 \n",
      "Epoch:  5000 | loss: 0.000002530444 \n",
      "Epoch:  5100 | loss: 0.000002516862 \n",
      "Epoch:  5200 | loss: 0.000002480337 \n",
      "Epoch:  5300 | loss: 0.000002470211 \n",
      "Epoch:  5400 | loss: 0.000002464866 \n",
      "Epoch:  5500 | loss: 0.000002466860 \n",
      "Epoch:  5600 | loss: 0.000002448048 \n",
      "Epoch:  5700 | loss: 0.000002441907 \n",
      "Epoch:  5800 | loss: 0.000002439712 \n",
      "Epoch:  5900 | loss: 0.000002428581 \n",
      "Epoch:  6000 | loss: 0.000002415353 \n",
      "Epoch:  6100 | loss: 0.000002410937 \n",
      "Epoch:  6200 | loss: 0.000002405241 \n",
      "Epoch:  6300 | loss: 0.000002395619 \n",
      "Epoch:  6400 | loss: 0.000002394451 \n",
      "Epoch:  6500 | loss: 0.000002387978 \n",
      "Epoch:  6600 | loss: 0.000002384298 \n",
      "Epoch:  6700 | loss: 0.000002373818 \n",
      "Epoch:  6800 | loss: 0.000002361033 \n",
      "Epoch:  6900 | loss: 0.000002355041 \n",
      "Epoch:  7000 | loss: 0.000002346276 \n",
      "Epoch:  7100 | loss: 0.000002341831 \n",
      "Epoch:  7200 | loss: 0.000002349032 \n",
      "Epoch:  7300 | loss: 0.000002338337 \n",
      "Epoch:  7400 | loss: 0.000002331985 \n",
      "Epoch:  7500 | loss: 0.000002333740 \n",
      "Epoch:  7600 | loss: 0.000002333400 \n",
      "Epoch:  7700 | loss: 0.000002327893 \n",
      "Epoch:  7800 | loss: 0.000002323875 \n",
      "Epoch:  7900 | loss: 0.000002325625 \n",
      "Epoch:  8000 | loss: 0.000002322681 \n",
      "Epoch:  8100 | loss: 0.000002318371 \n",
      "Epoch:  8200 | loss: 0.000002314991 \n",
      "Epoch:  8300 | loss: 0.000002310824 \n",
      "Epoch:  8400 | loss: 0.000002303975 \n",
      "Epoch:  8500 | loss: 0.000002300137 \n",
      "Epoch:  8600 | loss: 0.000002298050 \n",
      "Epoch:  8700 | loss: 0.000002293583 \n",
      "Epoch:  8800 | loss: 0.000002290888 \n",
      "Epoch:  8900 | loss: 0.000002287349 \n",
      "Epoch:  9000 | loss: 0.000002281882 \n",
      "Epoch:  9100 | loss: 0.000002276659 \n",
      "Epoch:  9200 | loss: 0.000002274093 \n",
      "Epoch:  9300 | loss: 0.000002271250 \n",
      "Epoch:  9400 | loss: 0.000002269685 \n",
      "Epoch:  9500 | loss: 0.000002267762 \n",
      "Epoch:  9600 | loss: 0.000002265017 \n",
      "Epoch:  9700 | loss: 0.000002262917 \n",
      "Epoch:  9800 | loss: 0.000002260044 \n",
      "Epoch:  9900 | loss: 0.000002256759 \n",
      "Epoch:  10000 | loss: 0.000002253685 \n",
      "Epoch:  10100 | loss: 0.000002250507 \n",
      "Epoch:  10200 | loss: 0.000002247214 \n",
      "Epoch:  10300 | loss: 0.000002243806 \n",
      "Epoch:  10400 | loss: 0.000002240268 \n",
      "Epoch:  10500 | loss: 0.000002236928 \n",
      "Epoch:  10600 | loss: 0.000002233179 \n",
      "Epoch:  10700 | loss: 0.000002230124 \n",
      "Epoch:  10800 | loss: 0.000002226649 \n",
      "Epoch:  10900 | loss: 0.000002223393 \n",
      "Epoch:  11000 | loss: 0.000002220306 \n",
      "Epoch:  11100 | loss: 0.000002220132 \n",
      "Epoch:  11200 | loss: 0.000002217803 \n",
      "Epoch:  11300 | loss: 0.000002210604 \n",
      "Epoch:  11400 | loss: 0.000002207424 \n",
      "Epoch:  11500 | loss: 0.000002204762 \n",
      "Epoch:  11600 | loss: 0.000002201700 \n",
      "Epoch:  11700 | loss: 0.000002199019 \n",
      "Epoch:  11800 | loss: 0.000002195331 \n",
      "Epoch:  11900 | loss: 0.000002192246 \n",
      "Epoch:  12000 | loss: 0.000002189113 \n",
      "Epoch:  12100 | loss: 0.000002187623 \n",
      "Epoch:  12200 | loss: 0.000002186074 \n",
      "Epoch:  12300 | loss: 0.000002188064 \n",
      "Epoch:  12400 | loss: 0.000002186233 \n",
      "Epoch:  12500 | loss: 0.000002184416 \n",
      "Epoch:  12600 | loss: 0.000002182966 \n",
      "Epoch:  12700 | loss: 0.000002181013 \n",
      "Epoch:  12800 | loss: 0.000002179065 \n",
      "Epoch:  12900 | loss: 0.000002176946 \n",
      "Epoch:  13000 | loss: 0.000002174729 \n",
      "Epoch:  13100 | loss: 0.000002172493 \n",
      "Epoch:  13200 | loss: 0.000002170106 \n",
      "Epoch:  13300 | loss: 0.000002167626 \n",
      "Epoch:  13400 | loss: 0.000002165455 \n",
      "Epoch:  13500 | loss: 0.000002162759 \n",
      "Epoch:  13600 | loss: 0.000002160036 \n",
      "Epoch:  13700 | loss: 0.000002157350 \n",
      "Epoch:  13800 | loss: 0.000002161355 \n",
      "Epoch:  13900 | loss: 0.000002158559 \n",
      "Epoch:  14000 | loss: 0.000002155852 \n",
      "Epoch:  14100 | loss: 0.000002153226 \n",
      "Epoch:  14200 | loss: 0.000002150605 \n",
      "Epoch:  14300 | loss: 0.000002149040 \n",
      "Epoch:  14400 | loss: 0.000002146269 \n",
      "Epoch:  14500 | loss: 0.000002143592 \n",
      "Epoch:  14600 | loss: 0.000002140939 \n",
      "Epoch:  14700 | loss: 0.000002139145 \n",
      "Epoch:  14800 | loss: 0.000002135748 \n",
      "Epoch:  14900 | loss: 0.000002133207 \n",
      "time=383.1546950340271\n",
      "best_train_loss=2.1306827875378076e-06\n",
      "test_loss=4.243826424499275e-06\n",
      "best_epoch=14999\n",
      "w=25\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000002130669 \n",
      "Epoch:  100 | loss: 0.000002124630 \n",
      "Epoch:  200 | loss: 0.000002119767 \n",
      "Epoch:  300 | loss: 0.000002111148 \n",
      "Epoch:  400 | loss: 0.000002210563 \n",
      "Epoch:  500 | loss: 0.000002011584 \n",
      "Epoch:  600 | loss: 0.000001960423 \n",
      "Epoch:  700 | loss: 0.000001883174 \n",
      "Epoch:  800 | loss: 0.000001844486 \n",
      "Epoch:  900 | loss: 0.000001806371 \n",
      "Epoch:  1000 | loss: 0.000001768368 \n",
      "Epoch:  1100 | loss: 0.000001748394 \n",
      "Epoch:  1200 | loss: 0.000001727013 \n",
      "Epoch:  1300 | loss: 0.000001693433 \n",
      "Epoch:  1400 | loss: 0.000001692328 \n",
      "Epoch:  1500 | loss: 0.000001654498 \n",
      "Epoch:  1600 | loss: 0.000001637339 \n",
      "Epoch:  1700 | loss: 0.000001617183 \n",
      "Epoch:  1800 | loss: 0.000001641137 \n",
      "Epoch:  1900 | loss: 0.000001597735 \n",
      "Epoch:  2000 | loss: 0.000001574271 \n",
      "Epoch:  2100 | loss: 0.000001564149 \n",
      "Epoch:  2200 | loss: 0.000001556118 \n",
      "Epoch:  2300 | loss: 0.000001591577 \n",
      "Epoch:  2400 | loss: 0.000001540506 \n",
      "Epoch:  2500 | loss: 0.000001714734 \n",
      "Epoch:  2600 | loss: 0.000001527077 \n",
      "Epoch:  2700 | loss: 0.000001519340 \n",
      "Epoch:  2800 | loss: 0.000001524855 \n",
      "Epoch:  2900 | loss: 0.000001495355 \n",
      "Epoch:  3000 | loss: 0.000001489154 \n",
      "Epoch:  3100 | loss: 0.000001484536 \n",
      "Epoch:  3200 | loss: 0.000001478665 \n",
      "Epoch:  3300 | loss: 0.000001474455 \n",
      "Epoch:  3400 | loss: 0.000001471103 \n",
      "Epoch:  3500 | loss: 0.000001464278 \n",
      "Epoch:  3600 | loss: 0.000001459073 \n",
      "Epoch:  3700 | loss: 0.000001451079 \n",
      "Epoch:  3800 | loss: 0.000001440224 \n",
      "Epoch:  3900 | loss: 0.000001426540 \n",
      "Epoch:  4000 | loss: 0.000001415393 \n",
      "Epoch:  4100 | loss: 0.000001405153 \n",
      "Epoch:  4200 | loss: 0.000001395372 \n",
      "Epoch:  4300 | loss: 0.000001388863 \n",
      "Epoch:  4400 | loss: 0.000001377205 \n",
      "Epoch:  4500 | loss: 0.000001368109 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4600 | loss: 0.000001364904 \n",
      "Epoch:  4700 | loss: 0.000001349484 \n",
      "Epoch:  4800 | loss: 0.000001341861 \n",
      "Epoch:  4900 | loss: 0.000001347864 \n",
      "Epoch:  5000 | loss: 0.000001356462 \n",
      "Epoch:  5100 | loss: 0.000001335850 \n",
      "Epoch:  5200 | loss: 0.000001328503 \n",
      "Epoch:  5300 | loss: 0.000001328187 \n",
      "Epoch:  5400 | loss: 0.000001321353 \n",
      "Epoch:  5500 | loss: 0.000001317446 \n",
      "Epoch:  5600 | loss: 0.000001309163 \n",
      "Epoch:  5700 | loss: 0.000001307571 \n",
      "Epoch:  5800 | loss: 0.000001301334 \n",
      "Epoch:  5900 | loss: 0.000001297597 \n",
      "Epoch:  6000 | loss: 0.000001290033 \n",
      "Epoch:  6100 | loss: 0.000001286694 \n",
      "Epoch:  6200 | loss: 0.000001283460 \n",
      "Epoch:  6300 | loss: 0.000001278422 \n",
      "Epoch:  6400 | loss: 0.000001274586 \n",
      "Epoch:  6500 | loss: 0.000001270802 \n",
      "Epoch:  6600 | loss: 0.000001267393 \n",
      "Epoch:  6700 | loss: 0.000001273941 \n",
      "Epoch:  6800 | loss: 0.000001266322 \n",
      "Epoch:  6900 | loss: 0.000001272225 \n",
      "Epoch:  7000 | loss: 0.000001267800 \n",
      "Epoch:  7100 | loss: 0.000001262694 \n",
      "Epoch:  7200 | loss: 0.000001257716 \n",
      "Epoch:  7300 | loss: 0.000001245337 \n",
      "Epoch:  7400 | loss: 0.000001226996 \n",
      "Epoch:  7500 | loss: 0.000001231216 \n",
      "Epoch:  7600 | loss: 0.000001233816 \n",
      "Epoch:  7700 | loss: 0.000001219288 \n",
      "Epoch:  7800 | loss: 0.000001209094 \n",
      "Epoch:  7900 | loss: 0.000001208651 \n",
      "Epoch:  8000 | loss: 0.000001223609 \n",
      "Epoch:  8100 | loss: 0.000001215506 \n",
      "Epoch:  8200 | loss: 0.000001211319 \n",
      "Epoch:  8300 | loss: 0.000001192373 \n",
      "Epoch:  8400 | loss: 0.000001182185 \n",
      "Epoch:  8500 | loss: 0.000001188411 \n",
      "Epoch:  8600 | loss: 0.000001183007 \n",
      "Epoch:  8700 | loss: 0.000001179728 \n",
      "Epoch:  8800 | loss: 0.000001160757 \n",
      "Epoch:  8900 | loss: 0.000001156699 \n",
      "Epoch:  9000 | loss: 0.000001165000 \n",
      "Epoch:  9100 | loss: 0.000001148623 \n",
      "Epoch:  9200 | loss: 0.000001160353 \n",
      "Epoch:  9300 | loss: 0.000001143222 \n",
      "Epoch:  9400 | loss: 0.000001140467 \n",
      "Epoch:  9500 | loss: 0.000001148871 \n",
      "Epoch:  9600 | loss: 0.000001140808 \n",
      "Epoch:  9700 | loss: 0.000001139577 \n",
      "Epoch:  9800 | loss: 0.000001127852 \n",
      "Epoch:  9900 | loss: 0.000001113590 \n",
      "Epoch:  10000 | loss: 0.000001106952 \n",
      "Epoch:  10100 | loss: 0.000001098672 \n",
      "Epoch:  10200 | loss: 0.000001094063 \n",
      "Epoch:  10300 | loss: 0.000001089615 \n",
      "Epoch:  10400 | loss: 0.000001082980 \n",
      "Epoch:  10500 | loss: 0.000001072850 \n",
      "Epoch:  10600 | loss: 0.000001077236 \n",
      "Epoch:  10700 | loss: 0.000001061137 \n",
      "Epoch:  10800 | loss: 0.000001068209 \n",
      "Epoch:  10900 | loss: 0.000001052992 \n",
      "Epoch:  11000 | loss: 0.000001061450 \n",
      "Epoch:  11100 | loss: 0.000001046796 \n",
      "Epoch:  11200 | loss: 0.000001058359 \n",
      "Epoch:  11300 | loss: 0.000001043835 \n",
      "Epoch:  11400 | loss: 0.000001051400 \n",
      "Epoch:  11500 | loss: 0.000001037063 \n",
      "Epoch:  11600 | loss: 0.000001044376 \n",
      "Epoch:  11700 | loss: 0.000001030753 \n",
      "Epoch:  11800 | loss: 0.000001027999 \n",
      "Epoch:  11900 | loss: 0.000001037721 \n",
      "Epoch:  12000 | loss: 0.000001022552 \n",
      "Epoch:  12100 | loss: 0.000001030717 \n",
      "Epoch:  12200 | loss: 0.000001018360 \n",
      "Epoch:  12300 | loss: 0.000001018690 \n",
      "Epoch:  12400 | loss: 0.000001017838 \n",
      "Epoch:  12500 | loss: 0.000001026075 \n",
      "Epoch:  12600 | loss: 0.000001014489 \n",
      "Epoch:  12700 | loss: 0.000001022904 \n",
      "Epoch:  12800 | loss: 0.000001010150 \n",
      "Epoch:  12900 | loss: 0.000001018556 \n",
      "Epoch:  13000 | loss: 0.000001009204 \n",
      "Epoch:  13100 | loss: 0.000001007407 \n",
      "Epoch:  13200 | loss: 0.000001004808 \n",
      "Epoch:  13300 | loss: 0.000001000999 \n",
      "Epoch:  13400 | loss: 0.000000988968 \n",
      "Epoch:  13500 | loss: 0.000000993894 \n",
      "Epoch:  13600 | loss: 0.000000980142 \n",
      "Epoch:  13700 | loss: 0.000000976352 \n",
      "Epoch:  13800 | loss: 0.000000977176 \n",
      "Epoch:  13900 | loss: 0.000000974107 \n",
      "Epoch:  14000 | loss: 0.000000965280 \n",
      "Epoch:  14100 | loss: 0.000000961285 \n",
      "Epoch:  14200 | loss: 0.000000957979 \n",
      "Epoch:  14300 | loss: 0.000000952613 \n",
      "Epoch:  14400 | loss: 0.000000949964 \n",
      "Epoch:  14500 | loss: 0.000000946501 \n",
      "Epoch:  14600 | loss: 0.000000944360 \n",
      "Epoch:  14700 | loss: 0.000000951163 \n",
      "Epoch:  14800 | loss: 0.000000938753 \n",
      "Epoch:  14900 | loss: 0.000000945719 \n",
      "time=395.2348589897156\n",
      "best_train_loss=9.310804216511315e-07\n",
      "test_loss=3.0381413580471417e-06\n",
      "best_epoch=14999\n",
      "w=30\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000930998 \n",
      "Epoch:  100 | loss: 0.000000928057 \n",
      "Epoch:  200 | loss: 0.000000926304 \n",
      "Epoch:  300 | loss: 0.000000905107 \n",
      "Epoch:  400 | loss: 0.000000881207 \n",
      "Epoch:  500 | loss: 0.000000862656 \n",
      "Epoch:  600 | loss: 0.000000851953 \n",
      "Epoch:  700 | loss: 0.000000843356 \n",
      "Epoch:  800 | loss: 0.000000827563 \n",
      "Epoch:  900 | loss: 0.000000816606 \n",
      "Epoch:  1000 | loss: 0.000000814632 \n",
      "Epoch:  1100 | loss: 0.000000809132 \n",
      "Epoch:  1200 | loss: 0.000000829130 \n",
      "Epoch:  1300 | loss: 0.000000799270 \n",
      "Epoch:  1400 | loss: 0.000000787772 \n",
      "Epoch:  1500 | loss: 0.000000944419 \n",
      "Epoch:  1600 | loss: 0.000000787948 \n",
      "Epoch:  1700 | loss: 0.000000782270 \n",
      "Epoch:  1800 | loss: 0.000000777402 \n",
      "Epoch:  1900 | loss: 0.000000772520 \n",
      "Epoch:  2000 | loss: 0.000000767311 \n",
      "Epoch:  2100 | loss: 0.000000761163 \n",
      "Epoch:  2200 | loss: 0.000000754600 \n",
      "Epoch:  2300 | loss: 0.000000751236 \n",
      "Epoch:  2400 | loss: 0.000000747911 \n",
      "Epoch:  2500 | loss: 0.000000746517 \n",
      "Epoch:  2600 | loss: 0.000000743551 \n",
      "Epoch:  2700 | loss: 0.000000743843 \n",
      "Epoch:  2800 | loss: 0.000000741950 \n",
      "Epoch:  2900 | loss: 0.000000738055 \n",
      "Epoch:  3000 | loss: 0.000000735565 \n",
      "Epoch:  3100 | loss: 0.000000734000 \n",
      "Epoch:  3200 | loss: 0.000000732463 \n",
      "Epoch:  3300 | loss: 0.000000731331 \n",
      "Epoch:  3400 | loss: 0.000000729512 \n",
      "Epoch:  3500 | loss: 0.000000725646 \n",
      "Epoch:  3600 | loss: 0.000000722866 \n",
      "Epoch:  3700 | loss: 0.000000721097 \n",
      "Epoch:  3800 | loss: 0.000000719021 \n",
      "Epoch:  3900 | loss: 0.000000716498 \n",
      "Epoch:  4000 | loss: 0.000000714571 \n",
      "Epoch:  4100 | loss: 0.000000712998 \n",
      "Epoch:  4200 | loss: 0.000000712986 \n",
      "Epoch:  4300 | loss: 0.000000711346 \n",
      "Epoch:  4400 | loss: 0.000000709335 \n",
      "Epoch:  4500 | loss: 0.000000706821 \n",
      "Epoch:  4600 | loss: 0.000000703961 \n",
      "Epoch:  4700 | loss: 0.000000700392 \n",
      "Epoch:  4800 | loss: 0.000000714001 \n",
      "Epoch:  4900 | loss: 0.000000711249 \n",
      "Epoch:  5000 | loss: 0.000000694370 \n",
      "Epoch:  5100 | loss: 0.000000692815 \n",
      "Epoch:  5200 | loss: 0.000000693828 \n",
      "Epoch:  5300 | loss: 0.000000689294 \n",
      "Epoch:  5400 | loss: 0.000000703066 \n",
      "Epoch:  5500 | loss: 0.000000713470 \n",
      "Epoch:  5600 | loss: 0.000000698823 \n",
      "Epoch:  5700 | loss: 0.000000685237 \n",
      "Epoch:  5800 | loss: 0.000000683181 \n",
      "Epoch:  5900 | loss: 0.000000682657 \n",
      "Epoch:  6000 | loss: 0.000000679555 \n",
      "Epoch:  6100 | loss: 0.000000678658 \n",
      "Epoch:  6200 | loss: 0.000000677598 \n",
      "Epoch:  6300 | loss: 0.000000676641 \n",
      "Epoch:  6400 | loss: 0.000000675690 \n",
      "Epoch:  6500 | loss: 0.000000687978 \n",
      "Epoch:  6600 | loss: 0.000000686972 \n",
      "Epoch:  6700 | loss: 0.000000685769 \n",
      "Epoch:  6800 | loss: 0.000000671783 \n",
      "Epoch:  6900 | loss: 0.000000670688 \n",
      "Epoch:  7000 | loss: 0.000000669543 \n",
      "Epoch:  7100 | loss: 0.000000668407 \n",
      "Epoch:  7200 | loss: 0.000000678935 \n",
      "Epoch:  7300 | loss: 0.000000665261 \n",
      "Epoch:  7400 | loss: 0.000000663919 \n",
      "Epoch:  7500 | loss: 0.000000675344 \n",
      "Epoch:  7600 | loss: 0.000000663607 \n",
      "Epoch:  7700 | loss: 0.000000673362 \n",
      "Epoch:  7800 | loss: 0.000000662869 \n",
      "Epoch:  7900 | loss: 0.000000662990 \n",
      "Epoch:  8000 | loss: 0.000000671375 \n",
      "Epoch:  8100 | loss: 0.000000661684 \n",
      "Epoch:  8200 | loss: 0.000000668643 \n",
      "Epoch:  8300 | loss: 0.000000668185 \n",
      "Epoch:  8400 | loss: 0.000000667035 \n",
      "Epoch:  8500 | loss: 0.000000664905 \n",
      "Epoch:  8600 | loss: 0.000000664472 \n",
      "Epoch:  8700 | loss: 0.000000663052 \n",
      "Epoch:  8800 | loss: 0.000000667473 \n",
      "Epoch:  8900 | loss: 0.000000659575 \n",
      "Epoch:  9000 | loss: 0.000000657111 \n",
      "Epoch:  9100 | loss: 0.000000656486 \n",
      "Epoch:  9200 | loss: 0.000000655774 \n",
      "Epoch:  9300 | loss: 0.000000655114 \n",
      "Epoch:  9400 | loss: 0.000000654489 \n",
      "Epoch:  9500 | loss: 0.000000653789 \n",
      "Epoch:  9600 | loss: 0.000000653082 \n",
      "Epoch:  9700 | loss: 0.000000652306 \n",
      "Epoch:  9800 | loss: 0.000000651867 \n",
      "Epoch:  9900 | loss: 0.000000651136 \n",
      "Epoch:  10000 | loss: 0.000000650340 \n",
      "Epoch:  10100 | loss: 0.000000649497 \n",
      "Epoch:  10200 | loss: 0.000000648644 \n",
      "Epoch:  10300 | loss: 0.000000647815 \n",
      "Epoch:  10400 | loss: 0.000000646885 \n",
      "Epoch:  10500 | loss: 0.000000645964 \n",
      "Epoch:  10600 | loss: 0.000000645073 \n",
      "Epoch:  10700 | loss: 0.000000644129 \n",
      "Epoch:  10800 | loss: 0.000000643179 \n",
      "Epoch:  10900 | loss: 0.000000642418 \n",
      "Epoch:  11000 | loss: 0.000000641738 \n",
      "Epoch:  11100 | loss: 0.000000640684 \n",
      "Epoch:  11200 | loss: 0.000000639848 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11300 | loss: 0.000000639125 \n",
      "Epoch:  11400 | loss: 0.000000638111 \n",
      "Epoch:  11500 | loss: 0.000000637300 \n",
      "Epoch:  11600 | loss: 0.000000636852 \n",
      "Epoch:  11700 | loss: 0.000000635740 \n",
      "Epoch:  11800 | loss: 0.000000635316 \n",
      "Epoch:  11900 | loss: 0.000000634424 \n",
      "Epoch:  12000 | loss: 0.000000633667 \n",
      "Epoch:  12100 | loss: 0.000000633391 \n",
      "Epoch:  12200 | loss: 0.000000632938 \n",
      "Epoch:  12300 | loss: 0.000000632616 \n",
      "Epoch:  12400 | loss: 0.000000633438 \n",
      "Epoch:  12500 | loss: 0.000000632965 \n",
      "Epoch:  12600 | loss: 0.000000632491 \n",
      "Epoch:  12700 | loss: 0.000000631995 \n",
      "Epoch:  12800 | loss: 0.000000631478 \n",
      "Epoch:  12900 | loss: 0.000000630954 \n",
      "Epoch:  13000 | loss: 0.000000630266 \n",
      "Epoch:  13100 | loss: 0.000000629521 \n",
      "Epoch:  13200 | loss: 0.000000628830 \n",
      "Epoch:  13300 | loss: 0.000000628150 \n",
      "Epoch:  13400 | loss: 0.000000627457 \n",
      "Epoch:  13500 | loss: 0.000000627336 \n",
      "Epoch:  13600 | loss: 0.000000626579 \n",
      "Epoch:  13700 | loss: 0.000000626179 \n",
      "Epoch:  13800 | loss: 0.000000625501 \n",
      "Epoch:  13900 | loss: 0.000000624808 \n",
      "Epoch:  14000 | loss: 0.000000623679 \n",
      "Epoch:  14100 | loss: 0.000000622880 \n",
      "Epoch:  14200 | loss: 0.000000622356 \n",
      "Epoch:  14300 | loss: 0.000000621560 \n",
      "Epoch:  14400 | loss: 0.000000620815 \n",
      "Epoch:  14500 | loss: 0.000000619663 \n",
      "Epoch:  14600 | loss: 0.000000619060 \n",
      "Epoch:  14700 | loss: 0.000000618408 \n",
      "Epoch:  14800 | loss: 0.000000617607 \n",
      "Epoch:  14900 | loss: 0.000000616885 \n",
      "time=412.60690999031067\n",
      "best_train_loss=6.160786938380625e-07\n",
      "test_loss=2.9968080070830183e-06\n",
      "best_epoch=14999\n",
      "w=35\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000616149 \n",
      "Epoch:  100 | loss: 0.000000612965 \n",
      "Epoch:  200 | loss: 0.000000611280 \n",
      "Epoch:  300 | loss: 0.000000609655 \n",
      "Epoch:  400 | loss: 0.000000608796 \n",
      "Epoch:  500 | loss: 0.000000606521 \n",
      "Epoch:  600 | loss: 0.000000604888 \n",
      "Epoch:  700 | loss: 0.000000602069 \n",
      "Epoch:  800 | loss: 0.000000600302 \n",
      "Epoch:  900 | loss: 0.000000597950 \n",
      "Epoch:  1000 | loss: 0.000000597221 \n",
      "Epoch:  1100 | loss: 0.000000595033 \n",
      "Epoch:  1200 | loss: 0.000000593168 \n",
      "Epoch:  1300 | loss: 0.000000590571 \n",
      "Epoch:  1400 | loss: 0.000000588407 \n",
      "Epoch:  1500 | loss: 0.000000586882 \n",
      "Epoch:  1600 | loss: 0.000000584856 \n",
      "Epoch:  1700 | loss: 0.000000586297 \n",
      "Epoch:  1800 | loss: 0.000000580751 \n",
      "Epoch:  1900 | loss: 0.000000590791 \n",
      "Epoch:  2000 | loss: 0.000000582193 \n",
      "Epoch:  2100 | loss: 0.000000580331 \n",
      "Epoch:  2200 | loss: 0.000000578680 \n",
      "Epoch:  2300 | loss: 0.000000591010 \n",
      "Epoch:  2400 | loss: 0.000000580832 \n",
      "Epoch:  2500 | loss: 0.000000576282 \n",
      "Epoch:  2600 | loss: 0.000000578143 \n",
      "Epoch:  2700 | loss: 0.000000573725 \n",
      "Epoch:  2800 | loss: 0.000000572969 \n",
      "Epoch:  2900 | loss: 0.000000591124 \n",
      "Epoch:  3000 | loss: 0.000000572043 \n",
      "Epoch:  3100 | loss: 0.000000572334 \n",
      "Epoch:  3200 | loss: 0.000000570470 \n",
      "Epoch:  3300 | loss: 0.000000569983 \n",
      "Epoch:  3400 | loss: 0.000000570506 \n",
      "Epoch:  3500 | loss: 0.000000569133 \n",
      "Epoch:  3600 | loss: 0.000000568621 \n",
      "Epoch:  3700 | loss: 0.000000565477 \n",
      "Epoch:  3800 | loss: 0.000000565652 \n",
      "Epoch:  3900 | loss: 0.000000564606 \n",
      "Epoch:  4000 | loss: 0.000000562190 \n",
      "Epoch:  4100 | loss: 0.000000559238 \n",
      "Epoch:  4200 | loss: 0.000000557524 \n",
      "Epoch:  4300 | loss: 0.000000554056 \n",
      "Epoch:  4400 | loss: 0.000000554240 \n",
      "Epoch:  4500 | loss: 0.000000553656 \n",
      "Epoch:  4600 | loss: 0.000000551721 \n",
      "Epoch:  4700 | loss: 0.000000545589 \n",
      "Epoch:  4800 | loss: 0.000000555870 \n",
      "Epoch:  4900 | loss: 0.000000541810 \n",
      "Epoch:  5000 | loss: 0.000000539069 \n",
      "Epoch:  5100 | loss: 0.000000538727 \n",
      "Epoch:  5200 | loss: 0.000000537996 \n",
      "Epoch:  5300 | loss: 0.000000536365 \n",
      "Epoch:  5400 | loss: 0.000000534879 \n",
      "Epoch:  5500 | loss: 0.000000532804 \n",
      "Epoch:  5600 | loss: 0.000000535838 \n",
      "Epoch:  5700 | loss: 0.000000533452 \n",
      "Epoch:  5800 | loss: 0.000000529015 \n",
      "Epoch:  5900 | loss: 0.000000526413 \n",
      "Epoch:  6000 | loss: 0.000000531749 \n",
      "Epoch:  6100 | loss: 0.000000530670 \n",
      "Epoch:  6200 | loss: 0.000000529858 \n",
      "Epoch:  6300 | loss: 0.000000529070 \n",
      "Epoch:  6400 | loss: 0.000000528246 \n",
      "Epoch:  6500 | loss: 0.000000527544 \n",
      "Epoch:  6600 | loss: 0.000000526732 \n",
      "Epoch:  6700 | loss: 0.000000525924 \n",
      "Epoch:  6800 | loss: 0.000000525120 \n",
      "Epoch:  6900 | loss: 0.000000524321 \n",
      "Epoch:  7000 | loss: 0.000000523512 \n",
      "Epoch:  7100 | loss: 0.000000522727 \n",
      "Epoch:  7200 | loss: 0.000000521962 \n",
      "Epoch:  7300 | loss: 0.000000521177 \n",
      "Epoch:  7400 | loss: 0.000000520308 \n",
      "Epoch:  7500 | loss: 0.000000519447 \n",
      "Epoch:  7600 | loss: 0.000000518658 \n",
      "Epoch:  7700 | loss: 0.000000522719 \n",
      "Epoch:  7800 | loss: 0.000000517070 \n",
      "Epoch:  7900 | loss: 0.000000516325 \n",
      "Epoch:  8000 | loss: 0.000000517386 \n",
      "Epoch:  8100 | loss: 0.000000515125 \n",
      "Epoch:  8200 | loss: 0.000000514279 \n",
      "Epoch:  8300 | loss: 0.000000513544 \n",
      "Epoch:  8400 | loss: 0.000000512860 \n",
      "Epoch:  8500 | loss: 0.000000511652 \n",
      "Epoch:  8600 | loss: 0.000000510791 \n",
      "Epoch:  8700 | loss: 0.000000510120 \n",
      "Epoch:  8800 | loss: 0.000000509895 \n",
      "Epoch:  8900 | loss: 0.000000509052 \n",
      "Epoch:  9000 | loss: 0.000000508268 \n",
      "Epoch:  9100 | loss: 0.000000507922 \n",
      "Epoch:  9200 | loss: 0.000000507566 \n",
      "Epoch:  9300 | loss: 0.000000507192 \n",
      "Epoch:  9400 | loss: 0.000000506810 \n",
      "Epoch:  9500 | loss: 0.000000506455 \n",
      "Epoch:  9600 | loss: 0.000000506051 \n",
      "Epoch:  9700 | loss: 0.000000505588 \n",
      "Epoch:  9800 | loss: 0.000000505151 \n",
      "Epoch:  9900 | loss: 0.000000504699 \n",
      "Epoch:  10000 | loss: 0.000000504236 \n",
      "Epoch:  10100 | loss: 0.000000503783 \n",
      "Epoch:  10200 | loss: 0.000000503255 \n",
      "Epoch:  10300 | loss: 0.000000502738 \n",
      "Epoch:  10400 | loss: 0.000000502085 \n",
      "Epoch:  10500 | loss: 0.000000501645 \n",
      "Epoch:  10600 | loss: 0.000000501727 \n",
      "Epoch:  10700 | loss: 0.000000501063 \n",
      "Epoch:  10800 | loss: 0.000000500541 \n",
      "Epoch:  10900 | loss: 0.000000500039 \n",
      "Epoch:  11000 | loss: 0.000000499530 \n",
      "Epoch:  11100 | loss: 0.000000499036 \n",
      "Epoch:  11200 | loss: 0.000000498551 \n",
      "Epoch:  11300 | loss: 0.000000498171 \n",
      "Epoch:  11400 | loss: 0.000000497669 \n",
      "Epoch:  11500 | loss: 0.000000497554 \n",
      "Epoch:  11600 | loss: 0.000000494986 \n",
      "Epoch:  11700 | loss: 0.000000494384 \n",
      "Epoch:  11800 | loss: 0.000000496148 \n",
      "Epoch:  11900 | loss: 0.000000495935 \n",
      "Epoch:  12000 | loss: 0.000000494341 \n",
      "Epoch:  12100 | loss: 0.000000496084 \n",
      "Epoch:  12200 | loss: 0.000000495721 \n",
      "Epoch:  12300 | loss: 0.000000495380 \n",
      "Epoch:  12400 | loss: 0.000000495038 \n",
      "Epoch:  12500 | loss: 0.000000494639 \n",
      "Epoch:  12600 | loss: 0.000000494290 \n",
      "Epoch:  12700 | loss: 0.000000493935 \n",
      "Epoch:  12800 | loss: 0.000000493631 \n",
      "Epoch:  12900 | loss: 0.000000493262 \n",
      "Epoch:  13000 | loss: 0.000000492882 \n",
      "Epoch:  13100 | loss: 0.000000492490 \n",
      "Epoch:  13200 | loss: 0.000000492430 \n",
      "Epoch:  13300 | loss: 0.000000492082 \n",
      "Epoch:  13400 | loss: 0.000000491622 \n",
      "Epoch:  13500 | loss: 0.000000491579 \n",
      "Epoch:  13600 | loss: 0.000000490951 \n",
      "Epoch:  13700 | loss: 0.000000490700 \n",
      "Epoch:  13800 | loss: 0.000000488566 \n",
      "Epoch:  13900 | loss: 0.000000488312 \n",
      "Epoch:  14000 | loss: 0.000000487509 \n",
      "Epoch:  14100 | loss: 0.000000486638 \n",
      "Epoch:  14200 | loss: 0.000000485342 \n",
      "Epoch:  14300 | loss: 0.000000486186 \n",
      "Epoch:  14400 | loss: 0.000000485735 \n",
      "Epoch:  14500 | loss: 0.000000483341 \n",
      "Epoch:  14600 | loss: 0.000000482445 \n",
      "Epoch:  14700 | loss: 0.000000482081 \n",
      "Epoch:  14800 | loss: 0.000000480780 \n",
      "Epoch:  14900 | loss: 0.000000481892 \n",
      "time=488.23354721069336\n",
      "best_train_loss=4.800297688234423e-07\n",
      "test_loss=2.8084900804969948e-06\n",
      "best_epoch=14999\n",
      "w=40\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000480183 \n",
      "Epoch:  100 | loss: 0.000000480921 \n",
      "Epoch:  200 | loss: 0.000000480032 \n",
      "Epoch:  300 | loss: 0.000000480683 \n",
      "Epoch:  400 | loss: 0.000000474401 \n",
      "Epoch:  500 | loss: 0.000000479783 \n",
      "Epoch:  600 | loss: 0.000000477530 \n",
      "Epoch:  700 | loss: 0.000000477723 \n",
      "Epoch:  800 | loss: 0.000000474297 \n",
      "Epoch:  900 | loss: 0.000000473564 \n",
      "Epoch:  1000 | loss: 0.000000473779 \n",
      "Epoch:  1100 | loss: 0.000000476003 \n",
      "Epoch:  1200 | loss: 0.000000473853 \n",
      "Epoch:  1300 | loss: 0.000000471860 \n",
      "Epoch:  1400 | loss: 0.000000472319 \n",
      "Epoch:  1500 | loss: 0.000000469290 \n",
      "Epoch:  1600 | loss: 0.000000465904 \n",
      "Epoch:  1700 | loss: 0.000000462948 \n",
      "Epoch:  1800 | loss: 0.000000462859 \n",
      "Epoch:  1900 | loss: 0.000000461798 \n",
      "Epoch:  2000 | loss: 0.000000456804 \n",
      "Epoch:  2100 | loss: 0.000000455204 \n",
      "Epoch:  2200 | loss: 0.000000453495 \n",
      "Epoch:  2300 | loss: 0.000000451862 \n",
      "Epoch:  2400 | loss: 0.000000460612 \n",
      "Epoch:  2500 | loss: 0.000000448079 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2600 | loss: 0.000000447731 \n",
      "Epoch:  2700 | loss: 0.000000444650 \n",
      "Epoch:  2800 | loss: 0.000000444026 \n",
      "Epoch:  2900 | loss: 0.000000446112 \n",
      "Epoch:  3000 | loss: 0.000000444793 \n",
      "Epoch:  3100 | loss: 0.000000441244 \n",
      "Epoch:  3200 | loss: 0.000000438289 \n",
      "Epoch:  3300 | loss: 0.000000437661 \n",
      "Epoch:  3400 | loss: 0.000000437156 \n",
      "Epoch:  3500 | loss: 0.000000437557 \n",
      "Epoch:  3600 | loss: 0.000000435978 \n",
      "Epoch:  3700 | loss: 0.000000437317 \n",
      "Epoch:  3800 | loss: 0.000000436593 \n",
      "Epoch:  3900 | loss: 0.000000435984 \n",
      "Epoch:  4000 | loss: 0.000000435420 \n",
      "Epoch:  4100 | loss: 0.000000434743 \n",
      "Epoch:  4200 | loss: 0.000000439269 \n",
      "Epoch:  4300 | loss: 0.000000434738 \n",
      "Epoch:  4400 | loss: 0.000000434590 \n",
      "Epoch:  4500 | loss: 0.000000435459 \n",
      "Epoch:  4600 | loss: 0.000000433651 \n",
      "Epoch:  4700 | loss: 0.000000434621 \n",
      "Epoch:  4800 | loss: 0.000000431087 \n",
      "Epoch:  4900 | loss: 0.000000429484 \n",
      "Epoch:  5000 | loss: 0.000000434760 \n",
      "Epoch:  5100 | loss: 0.000000435281 \n",
      "Epoch:  5200 | loss: 0.000000436618 \n",
      "Epoch:  5300 | loss: 0.000000427968 \n",
      "Epoch:  5400 | loss: 0.000000428216 \n",
      "Epoch:  5500 | loss: 0.000000426198 \n",
      "Epoch:  5600 | loss: 0.000000426425 \n",
      "Epoch:  5700 | loss: 0.000000424493 \n",
      "Epoch:  5800 | loss: 0.000000432276 \n",
      "Epoch:  5900 | loss: 0.000000430877 \n",
      "Epoch:  6000 | loss: 0.000000430401 \n",
      "Epoch:  6100 | loss: 0.000000425609 \n",
      "Epoch:  6200 | loss: 0.000000424384 \n",
      "Epoch:  6300 | loss: 0.000000428526 \n",
      "Epoch:  6400 | loss: 0.000000424678 \n",
      "Epoch:  6500 | loss: 0.000000422659 \n",
      "Epoch:  6600 | loss: 0.000000422275 \n",
      "Epoch:  6700 | loss: 0.000000423455 \n",
      "Epoch:  6800 | loss: 0.000000421868 \n",
      "Epoch:  6900 | loss: 0.000000421560 \n",
      "Epoch:  7000 | loss: 0.000000420581 \n",
      "Epoch:  7100 | loss: 0.000000425078 \n",
      "Epoch:  7200 | loss: 0.000000426546 \n",
      "Epoch:  7300 | loss: 0.000000424988 \n",
      "Epoch:  7400 | loss: 0.000000425011 \n",
      "Epoch:  7500 | loss: 0.000000419293 \n",
      "Epoch:  7600 | loss: 0.000000423678 \n",
      "Epoch:  7700 | loss: 0.000000424541 \n",
      "Epoch:  7800 | loss: 0.000000417428 \n",
      "Epoch:  7900 | loss: 0.000000418349 \n",
      "Epoch:  8000 | loss: 0.000000423666 \n",
      "Epoch:  8100 | loss: 0.000000417019 \n",
      "Epoch:  8200 | loss: 0.000000415659 \n",
      "Epoch:  8300 | loss: 0.000000422170 \n",
      "Epoch:  8400 | loss: 0.000000421283 \n",
      "Epoch:  8500 | loss: 0.000000418623 \n",
      "Epoch:  8600 | loss: 0.000000419545 \n",
      "Epoch:  8700 | loss: 0.000000418904 \n",
      "Epoch:  8800 | loss: 0.000000419015 \n",
      "Epoch:  8900 | loss: 0.000000419053 \n",
      "Epoch:  9000 | loss: 0.000000416823 \n",
      "Epoch:  9100 | loss: 0.000000416545 \n",
      "Epoch:  9200 | loss: 0.000000417200 \n",
      "Epoch:  9300 | loss: 0.000000418294 \n",
      "Epoch:  9400 | loss: 0.000000415771 \n",
      "Epoch:  9500 | loss: 0.000000416839 \n",
      "Epoch:  9600 | loss: 0.000000415197 \n",
      "Epoch:  9700 | loss: 0.000000414966 \n",
      "Epoch:  9800 | loss: 0.000000414794 \n",
      "Epoch:  9900 | loss: 0.000000414637 \n",
      "Epoch:  10000 | loss: 0.000000412711 \n",
      "Epoch:  10100 | loss: 0.000000412534 \n",
      "Epoch:  10200 | loss: 0.000000412138 \n",
      "Epoch:  10300 | loss: 0.000000413385 \n",
      "Epoch:  10400 | loss: 0.000000413895 \n",
      "Epoch:  10500 | loss: 0.000000414103 \n",
      "Epoch:  10600 | loss: 0.000000412382 \n",
      "Epoch:  10700 | loss: 0.000000410648 \n",
      "Epoch:  10800 | loss: 0.000000409986 \n",
      "Epoch:  10900 | loss: 0.000000410393 \n",
      "Epoch:  11000 | loss: 0.000000410507 \n",
      "Epoch:  11100 | loss: 0.000000411210 \n",
      "Epoch:  11200 | loss: 0.000000409025 \n",
      "Epoch:  11300 | loss: 0.000000411635 \n",
      "Epoch:  11400 | loss: 0.000000408339 \n",
      "Epoch:  11500 | loss: 0.000000411589 \n",
      "Epoch:  11600 | loss: 0.000000408605 \n",
      "Epoch:  11700 | loss: 0.000000411026 \n",
      "Epoch:  11800 | loss: 0.000000408125 \n",
      "Epoch:  11900 | loss: 0.000000410433 \n",
      "Epoch:  12000 | loss: 0.000000407518 \n",
      "Epoch:  12100 | loss: 0.000000409568 \n",
      "Epoch:  12200 | loss: 0.000000409612 \n",
      "Epoch:  12300 | loss: 0.000000409246 \n",
      "Epoch:  12400 | loss: 0.000000406842 \n",
      "Epoch:  12500 | loss: 0.000000407999 \n",
      "Epoch:  12600 | loss: 0.000000406269 \n",
      "Epoch:  12700 | loss: 0.000000406895 \n",
      "Epoch:  12800 | loss: 0.000000408189 \n",
      "Epoch:  12900 | loss: 0.000000406952 \n",
      "Epoch:  13000 | loss: 0.000000405367 \n",
      "Epoch:  13100 | loss: 0.000000406231 \n",
      "Epoch:  13200 | loss: 0.000000405914 \n",
      "Epoch:  13300 | loss: 0.000000404741 \n",
      "Epoch:  13400 | loss: 0.000000404437 \n",
      "Epoch:  13500 | loss: 0.000000404067 \n",
      "Epoch:  13600 | loss: 0.000000403641 \n",
      "Epoch:  13700 | loss: 0.000000403540 \n",
      "Epoch:  13800 | loss: 0.000000403884 \n",
      "Epoch:  13900 | loss: 0.000000404031 \n",
      "Epoch:  14000 | loss: 0.000000403224 \n",
      "Epoch:  14100 | loss: 0.000000401782 \n",
      "Epoch:  14200 | loss: 0.000000402269 \n",
      "Epoch:  14300 | loss: 0.000000400994 \n",
      "Epoch:  14400 | loss: 0.000000401444 \n",
      "Epoch:  14500 | loss: 0.000000400669 \n",
      "Epoch:  14600 | loss: 0.000000402508 \n",
      "Epoch:  14700 | loss: 0.000000402161 \n",
      "Epoch:  14800 | loss: 0.000000401664 \n",
      "Epoch:  14900 | loss: 0.000000400013 \n",
      "time=459.63375902175903\n",
      "best_train_loss=3.9922323935570603e-07\n",
      "test_loss=2.727041191974422e-06\n",
      "best_epoch=14925\n",
      "w=45\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000400197 \n",
      "Epoch:  100 | loss: 0.000000395818 \n",
      "Epoch:  200 | loss: 0.000000396113 \n",
      "Epoch:  300 | loss: 0.000000395686 \n",
      "Epoch:  400 | loss: 0.000000393140 \n",
      "Epoch:  500 | loss: 0.000000391829 \n",
      "Epoch:  600 | loss: 0.000000393542 \n",
      "Epoch:  700 | loss: 0.000000430727 \n",
      "Epoch:  800 | loss: 0.000000390551 \n",
      "Epoch:  900 | loss: 0.000000390965 \n",
      "Epoch:  1000 | loss: 0.000000393933 \n",
      "Epoch:  1100 | loss: 0.000000392107 \n",
      "Epoch:  1200 | loss: 0.000000393026 \n",
      "Epoch:  1300 | loss: 0.000000389612 \n",
      "Epoch:  1400 | loss: 0.000000393164 \n",
      "Epoch:  1500 | loss: 0.000000388143 \n",
      "Epoch:  1600 | loss: 0.000000386428 \n",
      "Epoch:  1700 | loss: 0.000000398608 \n",
      "Epoch:  1800 | loss: 0.000000381339 \n",
      "Epoch:  1900 | loss: 0.000000381019 \n",
      "Epoch:  2000 | loss: 0.000000379575 \n",
      "Epoch:  2100 | loss: 0.000000379414 \n",
      "Epoch:  2200 | loss: 0.000000388205 \n",
      "Epoch:  2300 | loss: 0.000000376114 \n",
      "Epoch:  2400 | loss: 0.000000373854 \n",
      "Epoch:  2500 | loss: 0.000000375595 \n",
      "Epoch:  2600 | loss: 0.000000373317 \n",
      "Epoch:  2700 | loss: 0.000000373419 \n",
      "Epoch:  2800 | loss: 0.000000371832 \n",
      "Epoch:  2900 | loss: 0.000000371136 \n",
      "Epoch:  3000 | loss: 0.000000370760 \n",
      "Epoch:  3100 | loss: 0.000000370249 \n",
      "Epoch:  3200 | loss: 0.000000369753 \n",
      "Epoch:  3300 | loss: 0.000000369258 \n",
      "Epoch:  3400 | loss: 0.000000367751 \n",
      "Epoch:  3500 | loss: 0.000000367259 \n",
      "Epoch:  3600 | loss: 0.000000366682 \n",
      "Epoch:  3700 | loss: 0.000000366294 \n",
      "Epoch:  3800 | loss: 0.000000366083 \n",
      "Epoch:  3900 | loss: 0.000000364807 \n",
      "Epoch:  4000 | loss: 0.000000364765 \n",
      "Epoch:  4100 | loss: 0.000000363835 \n",
      "Epoch:  4200 | loss: 0.000000363322 \n",
      "Epoch:  4300 | loss: 0.000000363152 \n",
      "Epoch:  4400 | loss: 0.000000362455 \n",
      "Epoch:  4500 | loss: 0.000000366910 \n",
      "Epoch:  4600 | loss: 0.000000373877 \n",
      "Epoch:  4700 | loss: 0.000000369920 \n",
      "Epoch:  4800 | loss: 0.000000367275 \n",
      "Epoch:  4900 | loss: 0.000000368283 \n",
      "Epoch:  5000 | loss: 0.000000366970 \n",
      "Epoch:  5100 | loss: 0.000000363015 \n",
      "Epoch:  5200 | loss: 0.000000359735 \n",
      "Epoch:  5300 | loss: 0.000000357408 \n",
      "Epoch:  5400 | loss: 0.000000356397 \n",
      "Epoch:  5500 | loss: 0.000000355602 \n",
      "Epoch:  5600 | loss: 0.000000355067 \n",
      "Epoch:  5700 | loss: 0.000000354516 \n",
      "Epoch:  5800 | loss: 0.000000353841 \n",
      "Epoch:  5900 | loss: 0.000000354624 \n",
      "Epoch:  6000 | loss: 0.000000352614 \n",
      "Epoch:  6100 | loss: 0.000000352854 \n",
      "Epoch:  6200 | loss: 0.000000351812 \n",
      "Epoch:  6300 | loss: 0.000000351203 \n",
      "Epoch:  6400 | loss: 0.000000351076 \n",
      "Epoch:  6500 | loss: 0.000000351214 \n",
      "Epoch:  6600 | loss: 0.000000355262 \n",
      "Epoch:  6700 | loss: 0.000000353975 \n",
      "Epoch:  6800 | loss: 0.000000357247 \n",
      "Epoch:  6900 | loss: 0.000000359620 \n",
      "Epoch:  7000 | loss: 0.000000357242 \n",
      "Epoch:  7100 | loss: 0.000000356725 \n",
      "Epoch:  7200 | loss: 0.000000356674 \n",
      "Epoch:  7300 | loss: 0.000000357926 \n",
      "Epoch:  7400 | loss: 0.000000353431 \n",
      "Epoch:  7500 | loss: 0.000000353504 \n",
      "Epoch:  7600 | loss: 0.000000349626 \n",
      "Epoch:  7700 | loss: 0.000000351469 \n",
      "Epoch:  7800 | loss: 0.000000349584 \n",
      "Epoch:  7900 | loss: 0.000000350534 \n",
      "Epoch:  8000 | loss: 0.000000348452 \n",
      "Epoch:  8100 | loss: 0.000000346399 \n",
      "Epoch:  8200 | loss: 0.000000348522 \n",
      "Epoch:  8300 | loss: 0.000000348498 \n",
      "Epoch:  8400 | loss: 0.000000347696 \n",
      "Epoch:  8500 | loss: 0.000000350515 \n",
      "Epoch:  8600 | loss: 0.000000351556 \n",
      "Epoch:  8700 | loss: 0.000000350512 \n",
      "Epoch:  8800 | loss: 0.000000352605 \n",
      "Epoch:  8900 | loss: 0.000000348505 \n",
      "Epoch:  9000 | loss: 0.000000347376 \n",
      "Epoch:  9100 | loss: 0.000000348636 \n",
      "Epoch:  9200 | loss: 0.000000345902 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9300 | loss: 0.000000344530 \n",
      "Epoch:  9400 | loss: 0.000000346353 \n",
      "Epoch:  9500 | loss: 0.000000347225 \n",
      "Epoch:  9600 | loss: 0.000000346248 \n",
      "Epoch:  9700 | loss: 0.000000345981 \n",
      "Epoch:  9800 | loss: 0.000000345391 \n",
      "Epoch:  9900 | loss: 0.000000345314 \n",
      "Epoch:  10000 | loss: 0.000000344935 \n",
      "Epoch:  10100 | loss: 0.000000347001 \n",
      "Epoch:  10200 | loss: 0.000000347710 \n",
      "Epoch:  10300 | loss: 0.000000347083 \n",
      "Epoch:  10400 | loss: 0.000000345115 \n",
      "Epoch:  10500 | loss: 0.000000346465 \n",
      "Epoch:  10600 | loss: 0.000000344552 \n",
      "Epoch:  10700 | loss: 0.000000344042 \n",
      "Epoch:  10800 | loss: 0.000000344538 \n",
      "Epoch:  10900 | loss: 0.000000342385 \n",
      "Epoch:  11000 | loss: 0.000000342024 \n",
      "Epoch:  11100 | loss: 0.000000341781 \n",
      "Epoch:  11200 | loss: 0.000000341270 \n",
      "Epoch:  11300 | loss: 0.000000340901 \n",
      "Epoch:  11400 | loss: 0.000000340584 \n",
      "Epoch:  11500 | loss: 0.000000340111 \n",
      "Epoch:  11600 | loss: 0.000000338834 \n",
      "Epoch:  11700 | loss: 0.000000341006 \n",
      "Epoch:  11800 | loss: 0.000000338193 \n",
      "Epoch:  11900 | loss: 0.000000345806 \n",
      "Epoch:  12000 | loss: 0.000000338196 \n",
      "Epoch:  12100 | loss: 0.000000339968 \n",
      "Epoch:  12200 | loss: 0.000000347365 \n",
      "Epoch:  12300 | loss: 0.000000336912 \n",
      "Epoch:  12400 | loss: 0.000000336696 \n",
      "Epoch:  12500 | loss: 0.000000336144 \n",
      "Epoch:  12600 | loss: 0.000000335850 \n",
      "Epoch:  12700 | loss: 0.000000336808 \n",
      "Epoch:  12800 | loss: 0.000000337659 \n",
      "Epoch:  12900 | loss: 0.000000338173 \n",
      "Epoch:  13000 | loss: 0.000000345602 \n",
      "Epoch:  13100 | loss: 0.000000339537 \n",
      "Epoch:  13200 | loss: 0.000000339150 \n",
      "Epoch:  13300 | loss: 0.000000338889 \n",
      "Epoch:  13400 | loss: 0.000000344390 \n",
      "Epoch:  13500 | loss: 0.000000344006 \n",
      "Epoch:  13600 | loss: 0.000000343391 \n",
      "Epoch:  13700 | loss: 0.000000342930 \n",
      "Epoch:  13800 | loss: 0.000000343859 \n",
      "Epoch:  13900 | loss: 0.000000338975 \n",
      "Epoch:  14000 | loss: 0.000000345057 \n",
      "Epoch:  14100 | loss: 0.000000344547 \n",
      "Epoch:  14200 | loss: 0.000000344403 \n",
      "Epoch:  14300 | loss: 0.000000341739 \n",
      "Epoch:  14400 | loss: 0.000000341314 \n",
      "Epoch:  14500 | loss: 0.000000340941 \n",
      "Epoch:  14600 | loss: 0.000000339637 \n",
      "Epoch:  14700 | loss: 0.000000339339 \n",
      "Epoch:  14800 | loss: 0.000000336520 \n",
      "Epoch:  14900 | loss: 0.000000336155 \n",
      "time=495.318776845932\n",
      "best_train_loss=3.3565592616469075e-07\n",
      "test_loss=2.7100661554868566e-06\n",
      "best_epoch=14990\n",
      "w=50\n",
      "a_kerr=0.0\n",
      "M=1.0\n",
      "r_c=2.0\n",
      "Epoch:  0 | loss: 0.000000335897 \n",
      "Epoch:  100 | loss: 0.000000332931 \n",
      "Epoch:  200 | loss: 0.000000332552 \n",
      "Epoch:  300 | loss: 0.000000328481 \n",
      "Epoch:  400 | loss: 0.000000327703 \n",
      "Epoch:  500 | loss: 0.000000322714 \n",
      "Epoch:  600 | loss: 0.000000322199 \n",
      "Epoch:  700 | loss: 0.000000318217 \n",
      "Epoch:  800 | loss: 0.000000315868 \n",
      "Epoch:  900 | loss: 0.000000313958 \n",
      "Epoch:  1000 | loss: 0.000000315084 \n",
      "Epoch:  1100 | loss: 0.000000313896 \n",
      "Epoch:  1200 | loss: 0.000000312952 \n",
      "Epoch:  1300 | loss: 0.000000312799 \n",
      "Epoch:  1400 | loss: 0.000000309698 \n",
      "Epoch:  1500 | loss: 0.000000313209 \n",
      "Epoch:  1600 | loss: 0.000000321466 \n",
      "Epoch:  1700 | loss: 0.000000305780 \n",
      "Epoch:  1800 | loss: 0.000000306603 \n",
      "Epoch:  1900 | loss: 0.000000304335 \n",
      "Epoch:  2000 | loss: 0.000000305360 \n",
      "Epoch:  2100 | loss: 0.000000303840 \n",
      "Epoch:  2200 | loss: 0.000000299172 \n",
      "Epoch:  2300 | loss: 0.000000302481 \n",
      "Epoch:  2400 | loss: 0.000000303885 \n",
      "Epoch:  2500 | loss: 0.000000301205 \n",
      "Epoch:  2600 | loss: 0.000000294654 \n",
      "Epoch:  2700 | loss: 0.000000307949 \n",
      "Epoch:  2800 | loss: 0.000000295323 \n",
      "Epoch:  2900 | loss: 0.000000291875 \n",
      "Epoch:  3000 | loss: 0.000000290550 \n",
      "Epoch:  3100 | loss: 0.000000292811 \n",
      "Epoch:  3200 | loss: 0.000000289289 \n",
      "Epoch:  3300 | loss: 0.000000289414 \n",
      "Epoch:  3400 | loss: 0.000000291973 \n",
      "Epoch:  3500 | loss: 0.000000288252 \n",
      "Epoch:  3600 | loss: 0.000000289432 \n",
      "Epoch:  3700 | loss: 0.000000287924 \n",
      "Epoch:  3800 | loss: 0.000000291085 \n",
      "Epoch:  3900 | loss: 0.000000287220 \n",
      "Epoch:  4000 | loss: 0.000000286930 \n",
      "Epoch:  4100 | loss: 0.000000286153 \n",
      "Epoch:  4200 | loss: 0.000000285457 \n",
      "Epoch:  4300 | loss: 0.000000285015 \n",
      "Epoch:  4400 | loss: 0.000000284192 \n",
      "Epoch:  4500 | loss: 0.000000286960 \n",
      "Epoch:  4600 | loss: 0.000000286467 \n",
      "Epoch:  4700 | loss: 0.000000282519 \n",
      "Epoch:  4800 | loss: 0.000000281979 \n",
      "Epoch:  4900 | loss: 0.000000282055 \n",
      "Epoch:  5000 | loss: 0.000000280501 \n",
      "Epoch:  5100 | loss: 0.000000280172 \n",
      "Epoch:  5200 | loss: 0.000000280212 \n",
      "Epoch:  5300 | loss: 0.000000278367 \n",
      "Epoch:  5400 | loss: 0.000000281824 \n",
      "Epoch:  5500 | loss: 0.000000282857 \n",
      "Epoch:  5600 | loss: 0.000000277744 \n",
      "Epoch:  5700 | loss: 0.000000277443 \n",
      "Epoch:  5800 | loss: 0.000000278151 \n",
      "Epoch:  5900 | loss: 0.000000283694 \n",
      "Epoch:  6000 | loss: 0.000000276913 \n",
      "Epoch:  6100 | loss: 0.000000276842 \n",
      "Epoch:  6200 | loss: 0.000000275480 \n",
      "Epoch:  6300 | loss: 0.000000275421 \n",
      "Epoch:  6400 | loss: 0.000000275366 \n",
      "Epoch:  6500 | loss: 0.000000275690 \n",
      "Epoch:  6600 | loss: 0.000000275389 \n",
      "Epoch:  6700 | loss: 0.000000274568 \n",
      "Epoch:  6800 | loss: 0.000000275028 \n",
      "Epoch:  6900 | loss: 0.000000274290 \n",
      "Epoch:  7000 | loss: 0.000000274148 \n",
      "Epoch:  7100 | loss: 0.000000273806 \n",
      "Epoch:  7200 | loss: 0.000000274253 \n",
      "Epoch:  7300 | loss: 0.000000273280 \n",
      "Epoch:  7400 | loss: 0.000000271185 \n",
      "Epoch:  7500 | loss: 0.000000270833 \n",
      "Epoch:  7600 | loss: 0.000000270185 \n",
      "Epoch:  7700 | loss: 0.000000269801 \n",
      "Epoch:  7800 | loss: 0.000000267922 \n",
      "Epoch:  7900 | loss: 0.000000269302 \n",
      "Epoch:  8000 | loss: 0.000000268900 \n",
      "Epoch:  8100 | loss: 0.000000266821 \n",
      "Epoch:  8200 | loss: 0.000000268273 \n",
      "Epoch:  8300 | loss: 0.000000268657 \n",
      "Epoch:  8400 | loss: 0.000000267604 \n",
      "Epoch:  8500 | loss: 0.000000267866 \n",
      "Epoch:  8600 | loss: 0.000000267171 \n",
      "Epoch:  8700 | loss: 0.000000266560 \n",
      "Epoch:  8800 | loss: 0.000000266888 \n",
      "Epoch:  8900 | loss: 0.000000265803 \n",
      "Epoch:  9000 | loss: 0.000000264077 \n",
      "Epoch:  9100 | loss: 0.000000265341 \n",
      "Epoch:  9200 | loss: 0.000000266377 \n",
      "Epoch:  9300 | loss: 0.000000265325 \n",
      "Epoch:  9400 | loss: 0.000000265105 \n",
      "Epoch:  9500 | loss: 0.000000265778 \n",
      "Epoch:  9600 | loss: 0.000000266155 \n",
      "Epoch:  9700 | loss: 0.000000265003 \n",
      "Epoch:  9800 | loss: 0.000000264876 \n",
      "Epoch:  9900 | loss: 0.000000265163 \n",
      "Epoch:  10000 | loss: 0.000000265493 \n",
      "Epoch:  10100 | loss: 0.000000263736 \n",
      "Epoch:  10200 | loss: 0.000000262869 \n",
      "Epoch:  10300 | loss: 0.000000263050 \n",
      "Epoch:  10400 | loss: 0.000000262012 \n",
      "Epoch:  10500 | loss: 0.000000261607 \n",
      "Epoch:  10600 | loss: 0.000000262424 \n",
      "Epoch:  10700 | loss: 0.000000262886 \n",
      "Epoch:  10800 | loss: 0.000000261849 \n",
      "Epoch:  10900 | loss: 0.000000260879 \n",
      "Epoch:  11000 | loss: 0.000000260617 \n",
      "Epoch:  11100 | loss: 0.000000260275 \n",
      "Epoch:  11200 | loss: 0.000000260655 \n",
      "Epoch:  11300 | loss: 0.000000259709 \n",
      "Epoch:  11400 | loss: 0.000000259422 \n",
      "Epoch:  11500 | loss: 0.000000259216 \n",
      "Epoch:  11600 | loss: 0.000000259004 \n",
      "Epoch:  11700 | loss: 0.000000258843 \n",
      "Epoch:  11800 | loss: 0.000000259095 \n",
      "Epoch:  11900 | loss: 0.000000259006 \n",
      "Epoch:  12000 | loss: 0.000000256292 \n",
      "Epoch:  12100 | loss: 0.000000258590 \n",
      "Epoch:  12200 | loss: 0.000000257567 \n",
      "Epoch:  12300 | loss: 0.000000258305 \n",
      "Epoch:  12400 | loss: 0.000000257254 \n",
      "Epoch:  12500 | loss: 0.000000258267 \n",
      "Epoch:  12600 | loss: 0.000000257840 \n",
      "Epoch:  12700 | loss: 0.000000256085 \n",
      "Epoch:  12800 | loss: 0.000000256840 \n",
      "Epoch:  12900 | loss: 0.000000256217 \n",
      "Epoch:  13000 | loss: 0.000000255546 \n",
      "Epoch:  13100 | loss: 0.000000256245 \n",
      "Epoch:  13200 | loss: 0.000000256598 \n",
      "Epoch:  13300 | loss: 0.000000254306 \n",
      "Epoch:  13400 | loss: 0.000000256711 \n",
      "Epoch:  13500 | loss: 0.000000255425 \n",
      "Epoch:  13600 | loss: 0.000000256044 \n",
      "Epoch:  13700 | loss: 0.000000255215 \n",
      "Epoch:  13800 | loss: 0.000000254997 \n",
      "Epoch:  13900 | loss: 0.000000255090 \n",
      "Epoch:  14000 | loss: 0.000000255583 \n",
      "Epoch:  14100 | loss: 0.000000254411 \n",
      "Epoch:  14200 | loss: 0.000000254323 \n",
      "Epoch:  14300 | loss: 0.000000254019 \n",
      "Epoch:  14400 | loss: 0.000000253089 \n",
      "Epoch:  14500 | loss: 0.000000253849 \n",
      "Epoch:  14600 | loss: 0.000000252147 \n",
      "Epoch:  14700 | loss: 0.000000254274 \n",
      "Epoch:  14800 | loss: 0.000000252137 \n",
      "Epoch:  14900 | loss: 0.000000252212 \n",
      "time=503.6872789859772\n",
      "best_train_loss=2.503450673430052e-07\n",
      "test_loss=2.598987066448899e-06\n",
      "best_epoch=14867\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# w/wo growing network\n",
    "# Tanh, Relu, Relu2 activation, last-layer act(other relu). Even: Should we use spline networks?\n",
    "# Hybrid: Adam + LBFGS\n",
    "# Possible overfitting: train & test gap\n",
    "# LBFGS usage\n",
    "\n",
    "#ws = [50,60,70,80,90,100,120,140,160,180,200,250,300,350,400]\n",
    "ws = [5,10,15,20,25,30,35,40,45,50]\n",
    "#ws = [14]\n",
    "#ws = [2,4]\n",
    "losses_w = []\n",
    "losses_w_test = []\n",
    "times = []\n",
    "\n",
    "a_s = [0.0]\n",
    "\n",
    "w_i = 0\n",
    "\n",
    "for w in ws:\n",
    "    \n",
    "    print(\"w={}\".format(w))\n",
    "    if w_i == 0:\n",
    "        t = T(w=w, a=0.0, M=1.0)\n",
    "    else:\n",
    "        sd = t.state_dict()\n",
    "        t_old = T(w=w_old, a=0.0, M=1.0)\n",
    "        t_old.load_state_dict(sd)\n",
    "        t = T(w=w, a=0.0, M=1.0)\n",
    "        t = grow(t_old, t, w_old, w)\n",
    "    w_i = w_i + 1\n",
    "\n",
    "\n",
    "    losses_a = []\n",
    "    losses_all = []\n",
    "    a_i = 0\n",
    "\n",
    "\n",
    "\n",
    "    for a_kerr in a_s:\n",
    "        M = 1.0\n",
    "        r_c = M + np.sqrt(M**2-a_kerr**2)\n",
    "        print(\"a_kerr={}\".format(a_kerr))\n",
    "        print(\"M={}\".format(M))\n",
    "        print(\"r_c={}\".format(r_c))\n",
    "        #t = T(w=400, a=a_kerr, M=M)\n",
    "        t.set_a(a_kerr)\n",
    "        a_i += 1\n",
    "\n",
    "\n",
    "        # Kerr Metric\n",
    "        def g(x_):\n",
    "            a = a_kerr\n",
    "            bs = x_.shape[0]\n",
    "            t = x_[:,0]\n",
    "            x = x_[:,1]\n",
    "            y = x_[:,2]\n",
    "            z = x_[:,3]\n",
    "            rho = torch.sqrt(x**2+y**2)\n",
    "            r = torch.sqrt(x**2+y**2+z**2)\n",
    "            costheta = z/r\n",
    "            sintheta = rho/r\n",
    "            sin2theta = 2*sintheta*costheta\n",
    "            cos2theta = 2*costheta**2 - 1\n",
    "            cosphi = x/rho\n",
    "            sinphi = y/rho\n",
    "            sigma = r**2 + a**2*costheta**2\n",
    "            zeta = torch.sqrt(r**2+a**2)\n",
    "            sq2 = torch.sqrt(torch.tensor(2., dtype=torch.float, requires_grad=False))\n",
    "\n",
    "            u1 = a**2 + 2*r**2 + a**2*cos2theta\n",
    "            zeta = torch.sqrt(a**2+r**2)\n",
    "            u2 = u1/(zeta*torch.sqrt(M*r))\n",
    "            u3 = 8*a*M/sigma\n",
    "            u4 = zeta**2 + 2*a**2*M*r*sintheta**2/sigma\n",
    "\n",
    "            g00 = -1 + 2*M*r/sigma\n",
    "            g01 = g10 = 1/4*sintheta*(sq2*u2*cosphi+u3*sinphi)\n",
    "            g02 = g20 = 1/4*sintheta*(-u3*cosphi+sq2*u2*sinphi)\n",
    "            g03 = g30 = costheta*u2/sq2**3\n",
    "            g11 = (8*costheta**2*cosphi**2*sigma-u2**2*r**2*cosphi**2*sintheta**2+8*u4*sinphi**2)/(8*r**2)\n",
    "            g12 = g21 = cosphi*(8*costheta**2*sigma-u2**2*r**2*sintheta**2-8*u4)*sinphi/(8*r**2)\n",
    "            g13 = g31 = costheta*(-8*sigma-u2**2*r**2)*cosphi*sintheta/(8*r**2)\n",
    "            g22 = (8*cosphi**2*u4+8*costheta**2*sigma*sinphi**2-u2**2*r**2*sintheta**2*sinphi**2)/(8*r**2)\n",
    "            g23 = g32 = costheta*(-8*sigma-u2**2*r**2)*sintheta*sinphi/(8*r**2)\n",
    "            g33 = sintheta**2 + costheta**2*(-u2**2*r**2+8*a**2*sintheta**2)/(8*r**2)\n",
    "\n",
    "            stack1 = torch.stack([g00, g01, g02, g03])\n",
    "            stack2 = torch.stack([g10, g11, g12, g13])\n",
    "            stack3 = torch.stack([g20, g21, g22, g23])\n",
    "            stack4 = torch.stack([g30, g31, g32, g33])\n",
    "\n",
    "            gs = - torch.stack([stack1, stack2, stack3, stack4]).permute(2,0,1)\n",
    "            return gs\n",
    "        \n",
    "        def euclidean_loss(t,inputs):\n",
    "            gp = t.transform_g(inputs)\n",
    "            bs = gp.shape[0]\n",
    "            minkowski_metric = torch.unsqueeze(torch.unsqueeze(torch.ones(bs,),dim=1),dim=2) * torch.unsqueeze(torch.diag(torch.tensor([-1.,-1.,-1.], dtype=torch.float, requires_grad=True)), dim=0)\n",
    "            return torch.mean((gp[:,1:,1:]-minkowski_metric)**2)\n",
    "\n",
    "\n",
    "\n",
    "        lr = 1e-2*(5/w)**2\n",
    "        '''if w_i == 0:\n",
    "            epochs = 2500\n",
    "            BFGS_epoch = 2000\n",
    "        else:\n",
    "            epochs = 500\n",
    "            BFGS_epoch = 0'''\n",
    "        \n",
    "        # We need to understand LBFGS better\n",
    "        epochs = 15000\n",
    "        switch_epoch = 3000\n",
    "        BFGS_epoch = 1000000\n",
    "\n",
    "        optimizer = optim.Adam(t.parameters(), lr=lr, eps=1e-8)\n",
    "        #optimizer = optim.SGD(t.parameters(),lr=lr)\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=0.1, max_iter=1e10, max_eval=1e10, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn='strong_wolfe')\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=0.1, max_iter=100, max_eval=1e10, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100)\n",
    "\n",
    "\n",
    "\n",
    "        #epochs = 100\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=1, max_iter=100, max_eval=None, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn=\"strong_wolfe\")\n",
    "        #optimizer = optim.LBFGS(t.parameters(), lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n",
    "\n",
    "        log_save = 100000\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        n_train = 1000\n",
    "        \n",
    "        best_loss = 10000\n",
    "        \n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            if (epoch+1) % switch_epoch == 0:\n",
    "                for opt_param in optimizer.param_groups:\n",
    "                    lr = lr * 0.5\n",
    "                    opt_param['lr'] = lr\n",
    "\n",
    "            if epoch == BFGS_epoch:\n",
    "                # BFGS learning rate. How to set?\n",
    "                optimizer = optim.LBFGS(t.parameters(), lr=0.1, max_iter=1e10, max_eval=1e10, tolerance_grad=1e-30, tolerance_change=1e-30, history_size=100, line_search_fn='strong_wolfe')\n",
    "\n",
    "            if epoch < BFGS_epoch:\n",
    "                log = 100\n",
    "                batch_size = n_train\n",
    "            else:\n",
    "                log = 1\n",
    "                batch_size = n_train\n",
    "            t.train()\n",
    "\n",
    "\n",
    "            choices = np.random.choice(n_train, batch_size, replace=False)\n",
    "            inputs = input_[choices]\n",
    "\n",
    "            # -------------------------------------------\n",
    "            def loss_closure():\n",
    "                if torch.is_grad_enabled():\n",
    "                    optimizer.zero_grad()\n",
    "                loss_inner = euclidean_loss(t,inputs)\n",
    "                #if loss_inner.requires_grad:\n",
    "                    #loss_inner.backward(retain_graph=True)\n",
    "                    #loss_inner.backward()\n",
    "                loss_inner.backward(retain_graph=True)\n",
    "                return loss_inner\n",
    "            # -------------------------------------------\n",
    "            loss = loss_closure()\n",
    "            # best_loss is trick for better scaling laws\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_epoch = epoch\n",
    "                def loss_closure_test():\n",
    "                    if torch.is_grad_enabled():\n",
    "                        optimizer.zero_grad()\n",
    "                    loss_inner = euclidean_loss(t,input_test_)\n",
    "                    return loss_inner\n",
    "                loss_test = loss_closure_test()\n",
    "            optimizer.step(loss_closure)  # get loss, use to update wts\n",
    "\n",
    "            losses.append(loss.detach().numpy())\n",
    "            losses_all.append(loss.detach().numpy())\n",
    "            '''loss = euclidean_loss(g,t,inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()'''\n",
    "            \n",
    "\n",
    "            if epoch%log == 0:\n",
    "                print('Epoch:  %d | loss: %.12f ' %(epoch, loss))\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "    print(\"time={}\".format(duration))\n",
    "    times.append(duration)\n",
    "\n",
    "\n",
    "                \n",
    "    w_old = w\n",
    "    losses_w.append(best_loss.detach().numpy())\n",
    "    losses_w_test.append(loss_test.detach().numpy())\n",
    "    print(\"best_train_loss={}\".format(best_loss.detach().numpy()))\n",
    "    print(\"test_loss={}\".format(loss_test.detach().numpy()))\n",
    "    print(\"best_epoch={}\".format(best_epoch))\n",
    "    \n",
    "np.save('./results_nn/grow_relu2last_adam_lrdecay',np.array([ws, losses_w, times, losses_w_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.00000000e+00, 1.00000000e+01, 1.50000000e+01, 2.00000000e+01,\n",
       "        2.50000000e+01, 3.00000000e+01, 3.50000000e+01, 4.00000000e+01,\n",
       "        4.50000000e+01, 5.00000000e+01],\n",
       "       [8.59807406e-05, 1.23241134e-05, 4.69300358e-06, 2.13068279e-06,\n",
       "        9.31080422e-07, 6.16078694e-07, 4.80029769e-07, 3.99223239e-07,\n",
       "        3.35655926e-07, 2.50345067e-07],\n",
       "       [2.95471783e+02, 3.47504851e+02, 3.53539103e+02, 3.83154695e+02,\n",
       "        3.95234859e+02, 4.12606910e+02, 4.88233547e+02, 4.59633759e+02,\n",
       "        4.95318777e+02, 5.03687279e+02],\n",
       "       [9.11724128e-05, 1.43464258e-05, 6.63407172e-06, 4.24382642e-06,\n",
       "        3.03814136e-06, 2.99680801e-06, 2.80849008e-06, 2.72704119e-06,\n",
       "        2.71006616e-06, 2.59898707e-06]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./results_nn/grow_relu2last_adam_lrdecay.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next try: relu2 (not just last layer)\n",
    "\n",
    "plt.plot(ws, losses_w, marker=\"o\")\n",
    "#plt.plot(ws, losses_w_test, marker=\"o\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('NN width',fontsize=15)\n",
    "plt.ylabel('MSE',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
